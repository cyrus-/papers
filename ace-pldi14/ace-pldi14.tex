%\documentclass[12pt]{article}
\documentclass[9pt,preprint]{sigplanconf}
% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.
\usepackage{listings}
\usepackage[usenames,dvipsnames]{color}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amssymb} 
\usepackage{amsthm}
\usepackage{ stmaryrd }
\usepackage{verbatimbox}

\usepackage{alltt}
\renewcommand{\ttdefault}{txtt}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{light-gray}{gray}{0.75}
\usepackage{listings}

    \makeatletter
%
% \btIfInRange{number}{range list}{TRUE}{FALSE}
%
% Test if int number <number> is element of a (comma separated) list of ranges
% (such as: {1,3-5,7,10-12,14}) and processes <TRUE> or <FALSE> respectively
%
        \newcount\bt@rangea
        \newcount\bt@rangeb

        \newcommand\btIfInRange[2]{%
            \global\let\bt@inrange\@secondoftwo%
            \edef\bt@rangelist{#2}%
            \foreach \range in \bt@rangelist {%
                \afterassignment\bt@getrangeb%
                \bt@rangea=0\range\relax%
                \pgfmathtruncatemacro\result{ ( #1 >= \bt@rangea) && (#1 <= \bt@rangeb) }%
                \ifnum\result=1\relax%
                    \breakforeach%
                    \global\let\bt@inrange\@firstoftwo%
                \fi%
            }%
            \bt@inrange%
        }

        \newcommand\bt@getrangeb{%
            \@ifnextchar\relax%
            {\bt@rangeb=\bt@rangea}%
            {\@getrangeb}%
        }

        \def\@getrangeb-#1\relax{%
            \ifx\relax#1\relax%
                \bt@rangeb=100000%   \maxdimen is too large for pgfmath
            \else%
                \bt@rangeb=#1\relax%
            \fi%
        }

%
% \btLstHL{range list}
%
        \newcommand{\btLstHL}[1]{%
            \btIfInRange{\value{lstnumber}}{#1}%
            {\color{black!10}}%
            {\def\lst@linebgrd}%
        }%

%
% \btInputEmph[listing options]{range list}{file name}
%
        \newcommand{\btLstInputEmph}[3][\empty]{%
            \lstset{%
                linebackgroundcolor=\btLstHL{#2}%
                \lstinputlisting{#3}%
            }% \only
        }

% Patch line number key to call line background macro
        \lst@Key{numbers}{none}{%
            \def\lst@PlaceNumber{\lst@linebgrd}%
            \lstKV@SwitchCases{#1}{%
                none&\\%
                left&\def\lst@PlaceNumber{\llap{\normalfont
                \lst@numberstyle{\thelstnumber}\kern\lst@numbersep}\lst@linebgrd}\\%
                right&\def\lst@PlaceNumber{\rlap{\normalfont
                \kern\linewidth \kern\lst@numbersep
                \lst@numberstyle{\thelstnumber}}\lst@linebgrd}%
            }{%
                \PackageError{Listings}{Numbers #1 unknown}\@ehc%
            }%
        }

% New keys
        \lst@Key{linebackgroundcolor}{}{%
            \def\lst@linebgrdcolor{#1}%
        }
        \lst@Key{linebackgroundsep}{0pt}{%
            \def\lst@linebgrdsep{#1}%
        }
        \lst@Key{linebackgroundwidth}{\linewidth}{%
            \def\lst@linebgrdwidth{#1}%
        }
        \lst@Key{linebackgroundheight}{\ht\strutbox}{%
            \def\lst@linebgrdheight{#1}%
        }
        \lst@Key{linebackgrounddepth}{\dp\strutbox}{%
            \def\lst@linebgrddepth{#1}%
        }
        \lst@Key{linebackgroundcmd}{\color@block}{%
            \def\lst@linebgrdcmd{#1}%
        }

% Line Background macro
        \newcommand{\lst@linebgrd}{%
            \ifx\lst@linebgrdcolor\empty\else
                \rlap{%
                    \lst@basicstyle
                    \color{-.}% By default use the opposite (`-`) of the current color (`.`) as background
                    \lst@linebgrdcolor{%
                        \kern-\dimexpr\lst@linebgrdsep\relax%
                        \lst@linebgrdcmd{\lst@linebgrdwidth}{\lst@linebgrdheight}{\lst@linebgrddepth}%
                    }%
                }%
            \fi
        }

 % Heather-added packages for the fancy table
 \usepackage{longtable}
 \usepackage{booktabs}
 \usepackage{pdflscape}
 \usepackage{colortbl}%
 \newcommand{\myrowcolour}{\rowcolor[gray]{0.925}}
 \usepackage{wasysym}
 
    \makeatother

\lstset{
  language=Python,
  showstringspaces=false,
  formfeed=\newpage,
  tabsize=4,
  commentstyle=\itshape,
  basicstyle=\ttfamily\scriptsize,
  morekeywords={lambda, self, assert, as},
  numbers=left,
  numberstyle=\scriptsize\color{light-gray}\textsf,
  xleftmargin=2em,
  stringstyle=\color{mauve}
}
\lstdefinestyle{Bash}{
    language={}, 
    numbers=left,
    numberstyle=\scriptsize\color{light-gray}\textsf,
    moredelim=**[is][\color{blue}\bf\ttfamily]{`}{`},
}
\lstdefinestyle{OpenCL}{
	language=C++,
	morekeywords={kernel, __kernel, global, __global, size_t, get_global_id, sin, printf, int2}
}

\usepackage{float}
\floatstyle{ruled}
\newfloat{codelisting}{tp}{lop}
\floatname{codelisting}{Listing}
\setlength{\floatsep}{10pt}
\setlength{\textfloatsep}{10pt}

\usepackage{url}

\usepackage{todonotes}

\usepackage{placeins}

\usepackage{textpos}

\renewcommand\topfraction{0.85}
\renewcommand\bottomfraction{0.85}
\renewcommand\textfraction{0.1}
\renewcommand\floatpagefraction{0.85}

\begin{document}

\conferenceinfo{-}{-} 
\copyrightyear{-} 
\copyrightdata{[to be supplied]} 

%\titlebanner{{\tt \textcolor{Red}{{\small Under Review -- distribute within CMU only.}}}}        % These are ignored unless
%\preprintfooter{Distribute within CMU only.}   % 'preprint' option specified.

\newcommand{\Ace}{\textsf{Ace}}

\title{\Ace: Growing a Statically-Typed Language Inside a Python}

\authorinfo{~}{~}{~}
%\authorinfo{Cyrus Omar\and Jonathan Aldrich}
 %          {School of Computer Science\\
  %          Carnegie Mellon University}
   %        {\{comar, jonathan.aldrich\}@cs.cmu.edu}   

\maketitle
\begin{abstract}
%Evidence suggests that programmers are reluctant to adopt new languages to
%gain access to new abstractions, even when they agree that these abstractions
%could be valuable. This suggests a need for languages that satisfy two key
%growth criteria: compatibility with existing programming ecosystems; and
%internal extensibility, so that new abstractions do not require new
%languages.
%
%We introduce Ace, a language compatible with the popular Python ecosystem.
%While Python, like other similar languages, is satisfactory for simple
%scripting, Ace is designed for more complex situations where static
%typechecking is beneficial. Unlike most statically-typed languages, Ace's type
%system can be extended from within, by associating compile-time functions with
%type definitions. The compiler selectively invokes these according to a
%type-directed protocol, avoiding interference problems. Despite these design
%constraints, active types in Ace can express the static and dynamic semantics
%of a range of functional, object-oriented, parallel and domain-specific
%abstractions, all within libraries.

Evidence suggests that programmers are reluctant to adopt new programming languages to gain access to new abstractions, even when they agree that these abstractions would be valuable to them. This suggests a need for languages that are  \emph{compatible} with existing languages, tools and infrastructure and \emph{internally extensible}, so that adopting a new  primitive abstraction requires only importing a library in the usual way.

In this paper, we introduce Ace, a language compatible with tools and infrastructure developed for Python, one of the most  widely-adopted dynamically-typed languages today. While Python, like other similar languages, was designed for simple scripting tasks, Ace is designed for more complex situations where static typechecking and programmatic control over compilation may be beneficial. Unlike most statically-typed languages, however, Ace's type system and semantics can be extended from within by novel mechanisms that avoid key interference issues faced by previous mechanisms.  
We show that these can be used to implement a range of statically-typed functional, object-oriented, parallel, low-level and domain-specific abstractions, as well as safe interoperability layers with existing languages, as orthogonal libraries. 
%Ace can be used from the shell or interactively from within Python\todo{take this sentence out?}.
%Researchers developing languages and abstractions for high-performance computing must consider a number of design criteria, including performance, verifiability, portability and ease-of-use. Despite the deficiencies of legacy tools and the availability of seemingly superior options, end-users have been reluctant to adopt new language-based abstractions. We argue that this can be largely attributed to a failure to consider three additional criteria: continuity, extensibility\- and interoperability. This paper introduces Ace, a language that aims to satisfy this more comprehensive set of design criteria. To do so, Ace introduces several novel compile-time mechanisms, makes principled design choices, and builds upon existing standards in HPC, particularly Python and OpenCL. OpenCL support, rather than being built into the language, is implemented atop an extensibility mechanism that also admits abstractions drawn from other seemingly disparate paradigms. The core innovation underlying this and other features of Ace is a novel reification of types as first-class objects at compile-time, representing a refinement to the concept of active libraries that we call \emph{active types}. We validate our overall design by considering a case study of a simulation framework enabling the modular specification and efficient execution of ensembles of neural simulations across a cluster of GPUs.
\end{abstract}

%\category{D.3.2}{Programming Languages}{Language Classifications}[Extensible Languages]
%\category{D.3.4}{Programming Languages}{Processors}[Compilers]
%\category{F.3.1}{Logics \& Meanings of Programs}{Specifying and Verifying and Reasoning about Programs}[Specification Techniques]
%\keywords
%type-level computation, typed compilation
\section{Introduction}
Asking programmers to import a new library is far more practical than asking them to  adopt a new programming language. Indeed, recent empirical studies underscore  the difficulties of driving new languages into adoption, finding that extrinsic factors like compatibility with existing codebases and libraries, team familiarity and tool support are at least as important as intrinsic factors \cite{Meyerovich:2013:EAP:2509136.2509515,chen05,nguyen2010survey}. As a result, many developers cannot use  abstractions they might prefer because these abstractions are only available in languages they cannot adopt \cite{Meyerovich:2012:SDR:2414721.2414724,Meyerovich:2013:EAP:2509136.2509515}. This issue was perhaps most succinctly expressed by a participant in a recent study by Basili et al. \cite{basili2008understanding} who stated ``I hate MPI, I hate C++. [But] if I had to choose again, I would probably choose the same.''

Unfortunately, researchers and domain experts who design and develop potentially useful new abstractions can find it difficult to implement them in terms of the general-purpose abstraction mechanisms available in mainstream languages. This is particularly salient for abstractions that require support from the typechecker or compiler, such as those focused on correctness and performance, as well as those that  introduce more concise or natural notations for existing abstractions. For example, a recent controlled study comparing a new language, Habanero-Java (HJ), with a comparable library, \verb|java.util.concurrent|, found that the language-based approach was more concise, correct and easy-to-use, but concluded that the library-based approach was more practical outside the classroom because HJ introduced new constructs and keywords into Java, requiring the adoption of a new toolchain, which could lead to compatibility issues with plain Java code \cite{cave2010comparing}.

Internally-extensible languages promise to reduce the need for new standalone languages by giving abstraction providers more direct control over a base language's syntax and semantics from within libraries. By using such a language, programmers  gain the ability to granularly import the primitive abstractions best suited to each part of their application or library. The research community thus gains the ability to more easily develop, deploy and evaluate new abstractions in the context of existing codebases, narrowing one of the gaps between research and practice \cite{basili2008understanding}. 

%Indeed, abstractions could compete on their individual merit, rather than  by the serious adoption barriers mentioned above.

Unfortunately, internally-extensible languages available today have several problems. First, an extension mechanism itself may require modifying a base language with constructs for defining, importing and using extensions. The extension mechanism is not itself a library, so it faces many of the same extrinsic issues as other new languages like HJ, leading to a ``bootstrapping'' problem. The extension mechanisms available today also have several intrinsic problems related to safety and expressiveness that require technical solutions before it would be appropriate to widely rely on them. We evaluate related work in Section \ref{related}.

This paper describes the design and implementation of Ace, an internally-extensible language designed considering both extrinsic and intrinsic criteria. To solve the bootstrapping problem, Ace is implemented entirely as a library within the popular Python programming language. Ace and Python share a common syntax and package system, allowing Ace to leverage its well-established tools and infrastructure directly. Python serves as the compile-time metalanguage for Ace, but Ace functions themselves do not operate according to Python's fixed dynamically-typed semantics  (cf. \cite{Politz:2013:PFM:2509136.2509536,python}). Instead, Ace has a statically-typed semantics that can be extended by users from within libraries. 

More specifically, each Ace function can be annotated with a base semantics that determines the meaning of simple expressions like literals and certain statements. The semantics of the remaining expressions and statements are governed by logic associated with the type of a designated subexpression. We call the user-defined base semantics \emph{active bases} and the types in Ace \emph{active types}, borrowing terminology from \emph{active libraries} (\cite{activelibraries}, see Sec. \ref{related}). Both are objects that can be defined and manipulated at compile-time using Python. An important consequence of this mechanism is that it permits \emph{compositional} reasoning -- active bases and active types govern only specific non-overlapping portions of a program. As a result, clients are able to import any combination of extensions with the confidence that link-time ambiguities cannot occur (unlike many previous approaches, as we discuss in Sec. \ref{related}).

The \emph{target} of compilation is also user-defined. We will show examples of Ace targeting Python as well as OpenCL and CUDA, lower-level languages often used to program graphics hardware. An active base or type can support multiple \emph{active targets}, which mediate translation of Ace code to code in a target language. Ace functions targeting a language with Python bindings can be called directly from Python scripts, with compilation occurring implicitly. For some data structures, types can propagate from Python into Ace. We show how this can be used to streamline the kinds of interactive workflows that Python is often used for. Ace can also be used non-interactively from the shell, producing source files that can be further compiled and executed by external means.

The remainder of the paper is organized as follows: in Sec. \ref{usage}, we describe the basic structure and usage of Ace with an example library that internalizes and extends the OpenCL language. Then in Sec. \ref{att}, we show how this and other libraries are implemented by detailing the extension mechanisms within Ace. To explain and demonstrate the expressiveness of these mechanisms (in particular, active types) further, we continue in Sec.  \ref{examples} by showing a diverse collection of abstractions drawn from different language paradigms that can be implemented as orthogonal libraries in Ace. We include functional datatypes, objects, macros, and typesafe format strings and regular expressions. In Sec.  \ref{related}, we compare Ace to related work on language extensibility and metaprogramming. We conclude in Sec. \ref{discussion} by summarizing our contributions, discussing the essential features needed by a host language to support these mechanisms, and describing their limitations and potential future work. 

\section{Language Design and Usage}\label{usage}
Listing \ref{map} shows an example of an Ace file. As promised, the top level of an Ace file is written directly in Python, requiring no modifications to the language (versions 2.6+ or 3.3+) nor features specific to CPython (so Ace supports alternative implementations like Jython and IronPython). This choice pays immediate dividends on line 1: Ace's package system is Python's package system, so Python's build tools (e.g. \verb|pip|) and package repostories (e.g. \verb|PyPI|) are directly available for distributing Ace libraries. 

The top-level statements in an Ace file, like the \verb|print| statement on line 10, are executed to control the compile-time behavior, rather than the run-time behavior, of the program. That is, Python serves as the \emph{compile-time metalanguage} (and, as we will see shortly, the \emph{type-level language}) of Ace. %For readers familiar with C/C++, Python can be thought of as serving a role similar to (but more general than) its preprocessor and template system (as we will see).
Functions containing run-time behavior, like \verb|map|, are governed by a semantics that can differ from Python's (in ways that we will describe below), but they share Python's syntax. As a consequence, users of Ace  immediately benefit from an ecosystem of well-developed tools that work with Python syntax, including parsers, code highlighters, editor modes, style checkers and documentation generators. 

\subsection{OpenCL as an Active Library}
The code in this section uses \verb|clx|, an example library implementing the semantics of the OpenCL programming language and extending it with some additional useful types, which we will discuss shortly. Ace itself has no built-in support for OpenCL.

To briefly review, OpenCL provides a data-parallel SPMD programming model where developers define functions, called {\em kernels}, for execution on \emph{compute devices} like GPUs or multi-core CPUs \cite{opencl11}. Each thread executes the same kernel but has access to a unique index, called its \emph{global ID}. Kernel code is written in a variant of C99 extended with some new primitive types and operators, which we will introduce  as needed in our examples below.

\subsection{Generic Functions}\label{genfn}
\begin{codelisting}
\lstinputlisting[linebackgroundcolor={\btLstHL{5-8}}]{listing3.py}
\caption{[\texttt{listing\ref{map}.py}] A generic data-parallel higher-order map function targeting OpenCL.}
\label{map}
\end{codelisting}
\begin{codelisting}[t]
\lstinputlisting[commentstyle=\color{mauve}]{listing7.py}
\caption{[\texttt{listing\ref{metaprogramming}.py}] Metaprogramming with Ace, showing how to construct generic functions from abstract syntax trees.}
\label{metaprogramming}
\end{codelisting}
Lines 3-4 introduce \verb|map|, an Ace function of three arguments that is governed by the \emph{active base} referred to by \verb|clx.base| and targeting the \emph{active target} referred to by \verb|clx.opencl|. The active target determines which language the function will compile to (here, the OpenCL kernel language) and mediates code generation. 

The body of this function, highlighted in grey for emphasis, does not have Python's semantics. Instead, it will be governed by the active base together with the active types used within it. No such types have been provided explicitly, however. Because our type system is extensible, the code inside could be meaningful for many different assignments of types to the arguments. We call functions awaiting types \emph{generic functions}. Once types have been assigned, they are called \emph{concrete functions}.

Generic functions are represented at compile-time as instances of \verb|ace.GenericFn| and consist of an abstract syntax tree, an {active base} and an {active target}. The purpose of the \emph{decorator} on line 3 is to replace the Python function on lines 4-8 with an Ace generic function having the same syntax tree and the provided active base and active target. 
Decorators in Python are simply syntactic sugar for applying the decorator function directly to the function  being decorated \cite{python}. In other words, line 3 could be replaced by inserting the following  statement on line 9:
\vspace{-0.28cm}
\begin{verbbox}
map = ace.fn(clx.base, clx.opencl)(map)
\end{verbbox}
\begin{figure}[h!]
\centering
\theverbbox
\end{figure}
\vspace{-0.28cm}

The abstract syntax tree for \verb|map| is extracted using the Python standard  library packages  \verb|inspect| (to retrieve its source code) and \verb|ast| (to parse it into a syntax tree). 

\subsection{Metaprogramming in Ace}
Generic functions can be generated directly from ASTs as well, providing Ace with support for  straightforward metaprogramming. Listing \ref{metaprogramming} shows how to generate two more generic functions, \verb|scale| and \verb|negate|. The latter is derived from the former by using a library for manipulating Python syntax trees, \verb|astx|. In particular, the \verb|specialize| function replaces uses of the second argument of \verb|scale| with the literal \verb|-1| (and changes the function's name), leaving a function of one argument.
 
\subsection{Concrete Functions and Explicit Compilation}
To compile a generic function to a particular \emph{concrete function}, a type must be provided for each argument, and typechecking and translation must then succeed. Listing \ref{compscript} shows how to explicitly provide type assignments to \verb|map| using the subscript operator (implemented using Python's operator overloading mechanism). We attempt to do so three times in Listing \ref{compscript}. The first, on line \ref{compscript}.7, fails due to a type error, which we handle so that the script can proceed. The error occurred  because the ordering of the argument types was incorrect. We provide a valid ordering on line \ref{compscript}.9 to generate the concrete function \verb|map_neg_f32|. We then provide a different type assignment to generate the concrete function \verb|map_neg_ci32|.
Concrete functions are instances of \verb|ace.ConcreteFn|, consisting of an abstract syntax tree annotated with types and translations along with a reference to the original generic function. %The typing and translation process is mediated by the logic in the active base, types and target that have been provided, as we will describe in more detail below. 

To produce an output file from an Ace ``compilation script'' like \verb|listing|\texttt{\ref{compscript}}\verb|.py|, the command \verb|acec| can be invoked from the shell, as shown in Listing \ref{mapc}. The \verb|acec| compiler (a simple Python script) operates in two stages:
\begin{enumerate}
\item Executes the provided Python file (\verb|listing3.py|).
\item Extracts the translations from concrete functions and other top-level constructs (e.g. types requiring declarations, or generated imports and pragmas) in the top-level Python environment.  This may produce one or more files as mediated by the active targets that were used (here, just \verb|listing3.cl|, but a web framework built upon Ace might produce separate HTML, CSS and JavaScript files; see Sec. \ref{atargets}).
\end{enumerate}

In this case, stage 1 results in the output on lines \ref{mapc}.2-\ref{mapc}.4. The type error printed on lines \ref{mapc}.3-\ref{mapc}.4 will be explained in the next section. The compiler then enters stage 2 and concludes with the message on line \ref{mapc}.5 to indicate that one file was generated. This file is shown in Listing \ref{mapout} and can be used by any programs that consume OpenCL code (e.g. a C program that invokes the generated kernels via the OpenCL host API). 
We will show in Section \ref{backend} that for targets with Python bindings, such as OpenCL, CUDA, C, Java or Python itself, generic functions can be executed directly, without any of the explicit compilation steps in Listings \ref{compscript}-\ref{mapc}.

\subsection{Types}
\begin{codelisting}
\lstinputlisting{listing4.py}
\caption{[\texttt{listing\ref{compscript}.py}] The generic \texttt{map} function compiled to map the \texttt{negate} function over two  types of input.}
\label{compscript}
\end{codelisting}
\begin{codelisting}
\begin{lstlisting}[style=Bash]
$ `acec listing3.py`
Hello, compile-time world!
[ace] TypeError in listing1.py (line 6, col 28): 
      'GenericFnType(negate)' does not support [].
[acec] listing3.cl successfully generated.
\end{lstlisting}
\caption{Compiling \texttt{listing\ref{compscript}.py} using the \texttt{acec} compiler.}
\label{mapc}
\end{codelisting}
\begin{codelisting}
\lstinputlisting[style=OpenCL]{listing5.cl}
\caption{[\texttt{listing\ref{compscript}.cl}] The OpenCL file generated by Listing \ref{mapc}.}
\label{mapout}
\end{codelisting}
Lines \ref{compscript}.3-\ref{compscript}.5 construct the types assigned to the arguments of \verb|map| on lines \ref{compscript}.7-\ref{compscript}.10. In Ace, types are themselves values that can be manipulated at compile-time. This stands in contrast to other contemporary languages, where user-defined types (e.g. datatypes, classes, structs) are written declaratively at compile-time but cannot be constructed, inspected or passed around programmatically. More specifically, types are instances of a Python class that implements the \verb|ace.ActiveType| interface (see Sec. \ref{atypes}). 
As Python values, types can be assigned to variables when convenient (removing the need for  facilities like \verb|typedef| in C or \verb|type| in Haskell). Types, like all compile-time objects derived from Ace base classes, do not have visible state and operate in a referentially transparent manner (by constructor memoization, which we do not detail here).% These types are all implemented in the \verb|clx| library imported on line 1, none are built into Ace itself.

The type named \verb|T1| on line \ref{compscript}.3 corresponds to the OpenCL type \verb|global float*|: a pointer to a 32-bit floating point number stored in the compute device's global memory (one of four address spaces defined by OpenCL \cite{opencl11}). It is constructed by applying \verb|clx.Ptr|, which is an Ace type constructor corresponding to pointer types, to a value representing the  address space, \verb|clx.global_|, and the type being pointed to. That type, \verb|clx.float|, is in turn the Ace type corresponding to \verb|float| in OpenCL (which, unlike C99, is always 32 bits). 
The \verb|clx| library contains a full implementation of the OpenCL type system (including behaviors, like promotions, inherited from C99).
Ace is \emph{unopinionated} about issues like memory safety and the wisdom of such promotions. We will discuss how to implement, as libraries, abstractions that are higher-level than raw pointers in Sec. \ref{examples}, but Ace does not prevent users from choosing a low level of abstraction or ``interesting'' semantics if the need arises (e.g. for compatibility with existing libraries; see the discussion in Sec. \ref{discussion}). We also note that we are being more verbose than necessary for the sake of pedagogy. The \verb|clx| library includes more concise shorthand for OpenCL's types: \verb|T1| is equal to \verb|clx.gp(clx.f32)|. %Similarly, the decorators in Listings \ref{map} and \ref{metaprogramming} could have been written \verb|clx.cl_fn|.\todo{move this back there probably}

The type \verb|T2| on line \ref{compscript}.4 is a pointer to a \emph{complex integer} in global memory. It does not correspond direrctly to a type in OpenCL, because OpenCL does not include primitive support for complex numbers. Instead, it uses an active type constructor \verb|clx.Cplx|, which includes the necessary logic for typechecking operations on complex numbers and translating them to OpenCL (Sec. \ref{atypes}). This constructor is parameterized by the numeric type that should be used for the real and imaginary parts, here \verb|clx.int|, which corresponds to 32-bit OpenCL integers. Arithmetic operations with other complex numbers, as well as with plain numeric types (treated as if their imaginary part was zero), are supported. When targeting OpenCL, Ace expressions assigned type \verb|clx.Cplx(clx.int)| are compiled to OpenCL expressions of type \verb|int2|, a  \emph{vector type} of two 32-bit integers (a type that itself is not inherited from C99). This can be observed in several places on lines \ref{mapout}.14-\ref{mapout}.21. This choice is merely an implementation detail that can be kept private to \verb|clx|, however. An Ace value of type \verb|clx.int2| (that is, an actual OpenCL vector) \emph{cannot} be used when a \verb|clx.Cplx(clx.int)| is expected (and attempting to do so will result in a static type error). \verb|clx.Cplx| truly extends the type system, it is not a type alias.

The type \verb|TF| on line \ref{compscript}.5 is extracted from the generic function \verb|negate| constructed in Listing \ref{metaprogramming}. Generic functions, according to Sec. \ref{genfn}, have not yet had a type assigned to them, so it may seem perplexing that we are nevertheless extracting a type from it. Although a conventional arrow type cannot be assigned to \verb|negate|, we can give it a \emph{singleton type}: a type that simply means ``this expression is the \emph{particular} generic function \verb|negate|''. This type could also have been explicitly written as \verb|ace.GenericFnType(listing2.negate)|. During typechecking and translation of \verb|map_neg_f32| and \verb|map_neg_ci32|, the call to \verb|f| on line \ref{map}.6 operates by using the types of the provided arguments to compile the generic function that inhabits the singleton type of \verb|f| (\verb|negate| in both of these cases) to a concrete function. This is why there are two versions of \verb|negate| in the output in Listing \ref{mapout}. In other words, types \emph{propagate} into generic functions -- we didn't need to compile \verb|negate| explicitly. This also explains the error printed on line \ref{mapc}.3-\ref{mapc}.4: when this type was inadvertently assigned to the first argument \verb|input|, the indexing operation on line \ref{map}.6 resulted in an error. A generic function can only be \emph{statically} indexed by a list of types to turn it into a concrete function, not \emph{dynamically} indexed with a value of type \verb|clx.size_t| (the return type of the OpenCL primitive function \verb|get_global_id|).

In effect, this scheme enables higher-order functions even when targeting languages, like OpenCL, that have no support for higher-order functions (OpenCL, unlike C99, does not support function pointers). Interestingly, because they have a singleton type, they are higher-order but not first-class functions. That is, the type system would prevent you from creating a heterogeneous list of generic functions. Concrete functions, on the other hand, can be given both a singleton type and a true function type. For example, \verb|listing2.negate[[clx.int]]| could be given type \verb|ace.Arrow(clx.int, clx.int)|. The base determines how to convert the Ace arrow type to an arrow type in the target language (e.g. a function pointer for C99, or an integer that indexes into a jump table constructed from knowledge of available functions of the appropriate type in OpenCL).

Type assignment to generic functions is similar in some ways to template specialization in C++. In effect, both a template header and type parameters at call sites are being generated automatically by Ace. This simplifies a sophisticated feature of C++ and enables its use with other targets like OpenCL. %Other uses for C++ templates (and the preprocessor) are subsumed by the metaprogramming features discussed above\todo{cite template metaprogramming paper}.

%\subsection{Within-Function Type Resolution}
%\begin{codelisting}
%\lstinputlisting{listing6.py}
%\caption{\texttt{[listing6.py]} A function demonstrating whole-function type inference when multiple values with differing types are assigned to a single identifier, \texttt{y}.}
%\label{inference}
%\end{codelisting}
%On line 5 in the generic \verb|map| function in Listing \ref{map}, the variable \verb|gid| is initialized with the result of calling the OpenCL primitive \verb|get_global_id|.  The type for \verb|gid| is never given explicitly. This is a simple case of Ace's {\em within-function type resolution} strategy (we hesitate to call it \emph{type inference} because it does not, strictly speaking, take a constraint-solving approach). In this case, the type of \verb|gid| will resolve to \verb|size_t| because that is the return type of \verb|get_global_id| (as defined in the OpenCL specification, which the \verb|ace.OpenCL| module follows). The result can be observed on Lines 11 and 24 in Listing \ref{mapout}. 
%
%Inference is not restricted within single assignments, as in the \verb|map| example, however. Multiple assignments to the same identifier with values of differing types, or multiple return statements, can be combined if the types in each case are compatible with one another (e.g. by a subtyping relation or an implicit coercion). In Listing \ref{inference}, the \verb|threshold_scale| function assigns different values to \verb|y| in each branch of the conditional. In the first branch, the value \verb|0| is an \verb|int| literal. However, in the second branch of the loop, the type depends on the types of both arguments, \verb|x| and \verb|scale|. We show two choices for these types on Lines 11 and 12. Type inference correctly combines these two types according to OpenCL's C99-derived rules governing numeric types (defined by the user in the \verb|OpenCL| module, as we will describe in Section \ref{att}). We can verify this programmatically on Lines 12 and 13. Note that this example would also work correctly if the assignments to \verb|y| were replaced with \verb|return| statements (in other words, the return value of a function is treated as an assignable for the purpose of type inference).

\subsection{Implicit Compilation and Interactive Execution}\label{compenv}\label{backend}\label{implicit}
%Professional end-user programmers (e.g. scientists and engineers \cite{professional-end-users}) today generally use dynamically-typed high-level languages like MATLAB, Python, R or Perl for tasks that are not performance-sensitive, such as small-scale data analysis and plotting \cite{nguyen2010survey}. For portions of their analyses where the performance overhead of dynamic type checking and automatic memory management is too high, they will typically call into code written in a statically-typed, low-level language, most commonly C or Fortran, that uses low-level parallel abstractions like pthreads and MPI \cite{4222616,basili2008understanding}. Unfortunately, these low-level languages and abstractions are notoriously difficult to use and automatic verification is intractable in general.\todo{integrate this}


A common workflow for \emph{professional end-user programmers} (e.g. scientists and engineers \cite{peus}) is to use a simple scripting language for orchestration, small-scale data analysis and visualization and call into a low-level language for performance-critical sections. Python is both designed for this style of use and widely adopted for such tasks \cite{sanner1999python,nguyen2010survey}. Developers can call into native functions using Python's foreign function interface (FFI), for example. A more recent trend is to generate and compile code without leaving Python, using a Python wrapper around a compiler. For example, \verb|weave| works with C and C++, and \verb|pycuda| and \verb|pyopencl| work with CUDA and OpenCL, respectively \cite{klockner2011pycuda}. 
\begin{codelisting}
\lstinputlisting{listing8.py}
\caption{[\texttt{listing\ref{py}.py}] A full OpenCL program using the \texttt{clx} Python bindings, including data transfer to and from a device and direct invocation of a generic function, \texttt{map}.}
\label{py}
\end{codelisting}
The OpenCL language was designed for this workflow, exposing a retargetable compiler and data management  routines as an API, called the \emph{host API} \cite{opencl11}. The \verb|pyopencl| library exposes this API and supports basic interoperability with \verb|numpy|, a package for safely manipulating contiguously-allocated numeric arrays in Python \cite{klockner2011pycuda}.

Ace supports a refinement to this workflow, as an alternative to the \verb|acec| compiler described above, for targets that have wrappers like this available, including \verb|clx.opencl|. Listing \ref{py} shows an example of this workflow where the user chooses a compute device (line \ref{py}.3),  constructs a \verb|numpy| array (line \ref{py}.5), transfers it to the device (line \ref{py}.6), allocates an empty equal-sized buffer for the result of the computation (line \ref{py}.7), launches the {generic} kernel \verb|map| from Listing \ref{map} with these device arrays as well as the function \verb|negate| from Listing \ref{metaprogramming} (line \ref{py}.9) choosing a number of threads equal to the number of elements in the input array (line \ref{py}.10), and transfers the result back into main memory to check that the device computed the expected result (line \ref{py}.12).

For developers experienced with the usual OpenCL or CUDA workflow, the fact that this can be accomplished in a total of 6 statements may be surprising. This simplicity is possibly largely due to  implicit tracking of types throughout the code. First, \verb|numpy| keeps track of the type, shape and order of its arrays. The type of \verb|input|, for example, is \verb|numpy.double| by default, its shape is \verb|(1024,1024)| and its order is row-major by default. The \verb|pyopencl| library that our mechanism is built atop uses this information to automatically call the underlying OpenCL host API function for transferring byte arrays to the device without requiring the user to calculate the size. Our wrapper of \verb|pyopencl| further retains this information in the Python wrappers around the device arrays, \verb|d_input| and \verb|d_output|. The Ace active type of such wrappers can be designated to be an instance of \verb|clx.NPArray| parametermized by this metadata. This type knows how to typecheck and translate operations like indexing automatically (see Sec. \ref{atypes}).

This allows us to call the generic function \verb|map| directly on these Python data structures (as well as the generic function \verb|negate|) without first requiring an explicit type assignment, like we needed when using \verb|acec| above. In other words, dynamic types and other metadata can propagate from Python data structures into an Ace generic function as static type information, in the same manner as it propagated \emph{between} generic functions in the previous section. In both cases, typechecking and translation of \verb|map| happens the first time a particular type assignment is encountered and cached for subsequent use. When called from Python, the generated OpenCL source code is also compiled for the device we selected using the OpenCL host API's compiler infrastructure, and cached. 

The same program written using the OpenCL C API directly is an order of magnitude longer and significantly more difficult to comprehend. OpenCL not support higher-order functions nor is there any way to write \verb|map| in a type-generic manner. If we instead use the \verb|pyopencl| library and apply the techniques described in \cite{klockner2011pycuda}, the program is still twice as large and less readable than this code. Both the \verb|map| and \verb|negate| functions must be explicitly specialized with the appropriate types using string manipulation techniques. Higher order functions are still not available, and must also be simulated by string manipulation. That approach also does not permit the use any of the language extensions that Ace enables (e.g. the type for \verb|numpy| arrays, which ensures that indexing respects ordering; see Sec. \ref{examples} for more interesting possibilities).

%Not shown are several additional conveniences, such as delegated kernel sizing and \verb|In| and \verb|Out| constructs that can reduce the size and improve the clarity of this code further; due to a lack of space, the reader is referred to the language documentation.

\section{Extensibility}\label{att}
The core of Ace consists of about 1500 lines of Python code implementing its primary concepts: generic functions, concrete functions, active types, active bases and active targets.  The latter three comprise Ace's extension mechanism. Extensions provide semantics to, and govern the compilation of, Ace functions, rather than logic in Ace's core. %Indeed, the name ``Ace'' might itself be an acronym: it is an ``active compilation environment''.

\subsection{Active Types}\label{atypes}
Active types are the primary means for extending Ace with new abstractions. An active type, as mentioned previously, is an instance of a class implementing the \verb|ace.ActiveType| interface. Listing \ref{cplx} shows an example of such a class: the \verb|clx.Cplx| class used in Listing \ref{compscript}, which implements the logic of complex numbers. The constructor takes as a parameter any numeric type in \verb|clx| (line \ref{cplx}.2). 

\subsubsection{Dispatch Protocol}
\begin{codelisting}
\lstinputlisting{listing9.py}
\caption{\texttt{[}in \texttt{examples/clx.py]} The active type family \texttt{Ptr} implements the semantics of OpenCL pointer types.}
\label{cplx}
\end{codelisting}
In a compiler for a monolithic language, there would be a \emph{syntax-directed} protocol governing typechecking and translation. In a compiler written in a functional language, for example, one would declare datatypes that captured all forms of types and expressions, and the typechecker would perform exhaustive case analysis over the expression forms, so all the semantics would be implemented in one place. The visitor pattern typically used in object-oriented languages implements essentially the same protocol. This does not work for an extensible language because new cases and logic need to be added modularly, in a safely composable manner.

Instead of taking a syntax-directed approach, the Ace compiler's typechecking and translation phases take a \emph{type-directed approach}. When encountering a compound term (e.g. \verb|e1[e2]|), the compiler defers control over typechecking and translation to the active type of a designated subexpression (e.g. \verb|e1|) determined by Ace's fixed \emph{dispatch protocol}. Below are examples of these choices. Due to space constraints, we do not show the full protocol.
\begin{itemize}
\item Responsibility over {\bf attribute access} (\texttt{e.attr}), {\bf subscripting} (\texttt{e[e1]}\todo{is it n-ary?}) and \textbf{calls} (\verb|e(e1, ..., en)|) and {\bf unary operations} (e.g. \verb|-e|) is handed to the type recursively assigned to \texttt{e}.
\item Responsibility over {\bf binary operations} (e.g. \verb|e1 + e2|) is first handed to the type assigned to the left operand. If it indicates a type error, the type assigned to the right operand is handed responsibility, via a different method call. {Note that this operates like the corresponding rule in Python's \emph{dynamic} operator overloading mechanism; see Sec. \ref{related} for a discussion.}
\item Responsibility over \textbf{constructor calls} (\verb|[t](e1, ..., en)|), where \verb|t| is a \emph{compile-time Python expression} evaluating to an active type, is handed to that type. If \verb|t| evaluates to a \emph{family} of types, like \verb|clx.Cplx|, the active type is first generated via a class method, as discussed below.
%\item Responsibility over {\bf simple assignment statements}, is handed to the type of the variable on the left (which, as we will see below, is determined by the active base). If this type does not provide special assignment semantics, the base must handle it.%Destructuring assignment is also supported by a somewhat more complex protocol.\todo{clarify}
\end{itemize}

\subsubsection{Typechecking}
When typechecking a compound expression or statement, the Ace compiler temporarily hands control to the object selected by the dispatch protocol by calling the method \verb|type_|$X$, where $X$ is  the name of the syntactic form, taken from the Python grammar \cite{pythonast} (appended with a suffix in some cases). 

For example, if \verb|c| is a complex number, then \verb|c.ni| and \verb|c.i| are its non-imaginary and imaginary components, respectively. These expressions are of the form \verb|Attribute|, so the typechecker calls \verb|type_Attribute| (line \ref{cplx}.7).
This method receives the compilation context, \verb|context|, and the abstract syntax tree of the expression, \verb|node| and must return a type assignment for the node, or raise an \verb|ace.TypeError| if there is an error. In this case, a type assignment is possible if the attribute name is either \verb|"ni"| or \verb|"i"|, and an error is raised otherwise (lines \ref{cplx}.8-\ref{cplx}.10). We note that error messages are an important and sometimes overlooked facet of {ease-of-use} \cite{marceau2011measuring}. A common frustration with using general-purpose abstraction mechanisms to encode an abstraction is that they can produce  verbose and cryptic error messages that reflect the implementation details, rather than the semantics. %Active types permit direct encoding of semantics and customization of error messages.

Complex numbers also support binary arithmetic operations partnered with both other complex numbers and with non-complex numbers, treating them as if their imaginary component is zero. The typechecking rules for this logic is implemented on lines \ref{cplx}.17-\ref{cplx}.29. Because arithmetic operations are meant to be symmetric, the dispatch protocol checks both subexpressions for support, favoring the left to ensure that the semantics remain deterministic. In either position, the implementation begins by recursively assigning a type to the other operand in the current context via the \verb|context.type| method (line \ref{cplx}.24). If supported, it applies the C99 rules for arithmetic operations to determine the resulting type (\cite{c99}, not shown). 

Finally, a complex number can be constructed inside an Ace function using Ace's special constructor form: \verb|[clx.Cplx](3,4)| represents $3+4i$, for example. The term within the braces is evaluated at \emph{compile-time}. Because \verb|clx.Cplx| evaluates not to an active type, but to a class, this form is assigned a type by handing control to the class object via the \emph{class method} \verb|type_New|. It operates as expected, extracting the types of the two arguments to construct an appropriate complex number type (lines \ref{cplx}.50-\ref{cplx}.57), raising a type error if the arguments cannot be promoted to a common type according to the rules of C99 or if two arguments have not been provided (an exercise for the reader: modify this method to also allow a single argument for when the imaginary part is 0). 

%Note that in each example, subexpressions are not \emph{automatically} assigned types. Types must be requested from the context. This is useful because it allows types to reinterpret subexpressions of terms they control, to supporting more complex constructs (e.g. pattern matching on functional datatypes, see Sec. \ref{datatypes}).

\subsubsection{Translation}
Once typechecking a method is complete, the compiler enters the translation phase, where terms in the target language are generated from Ace terms. Terms in the target language are generated by calling methods of the \emph{active targets}. The translation phase operates similarly to typechecking, using the dispatch protocol to invoke methods named \verb|trans_|$X$. These methods have access to the context and node just as during typechecking, as well as the target.

As seen in Listing \ref{mapout}, we are implementing complex numbers internally using OpenCL vector types, like \verb|int2|. Let us look first at \verb|trans_New| on lines \ref{cplx}.54-\ref{cplx}.60, where new complex numbers are translated to vector literals by invoking \verb|VecLit| from the active target, which internally will generate the necessary OpenCL string for that form. The \verb|trans_type| method of the \verb|ace.ActiveType| is used to associated a type in the target language with an active type. For it to be possible to reason compositionally about the correctness of compilation, all complex numbers must translate to terms in the target language that have this target type \cite{tdc}. Ace supports a mode where this \emph{representational consistency} is dynamically checked during compilation (this requires that the active target know how to assign types to terms in the target language, which can be done only for our OpenCL target as of this writing).

The translation methods for attributes and binary operations proceed in a straightforward manner. The context provides a method, \verb|trans|, for recursively determining the translation of subexpressions as needed. Of note is that the translation methods can assume that typechecking succeeded. For example, the implementation of \verb|trans_Attribute| assumes that if \verb|node.attr| is not \verb|'ni'| then it must have been \verb|'i'| on line \ref{cplx}.14, consistent with the implementation of \verb|type_Attribute| above it. Typechecking and translation are separated into two methods to emphasize that typechecking is not target-dependent and to allow for typing rules that require generating types for hypothetical terms, where the overhead of the translation might be better avoided.

\subsection{Active Bases}\label{abases}
Each generic function is associated with an active base, which is an object implementing the \verb|ace.ActiveBase| interface. The active base specifies the \emph{base semantics} of that function. It controls the semantics of statements and expressions that do not have a clear ``primary'' subexpression for the dispatch protocol to defer to. A base is handed control over typechecking of statements and expressions in the same way as active types: via \verb|type_|$X$ and \verb|trans_|$X$ methods. It also initializes the context and governs the semantics of variables. Each function can have a distinct base semantics.

Literals are the most prominent form given their semantics by an active base. Our example active base, \verb|clx.base|, assigns integer literals the type \verb|clx.int32| while floating point literals have type \verb|clx.double|, consistent with the semantics of OpenCL and C99. The \verb|clx.base| object is an instance of \verb|clx.Base| that is pre-constructed for convenience. Alternative bases can be generated via different constructor arguments. For example, \verb|clx.Base(flit_t=clx.float)| is a base semantics where floating point literals have type \verb|clx.float|. This is useful because some OpenCL devices do not support double-precision numbers, or impose a significant performance penalty for their use. Indeed, to even use the \verb|double| type in OpenCL, a flag must be toggled by a \verb|#pragma| (The OpenCL target we have implemented inserts this automatically when needed, along with some other flags, and annotations like \verb|kernel|).  Similarly, for some applications, avoiding accidental overflows is more important than performance.  Arbitrary-precision integers can be implemented as an active type (not shown) and the base generates the constructor call form, described above, around integers to support this.

Another role that the active base can play is to provide operators that do not need to be imported. The semantics of \verb|get_global_id| and \verb|printf|, for example, are provided by \verb|clx.base|. In fact, the base provides a richer semantics for them than the underlying implementation, as we will show in the following section. It is not strictly necessary that the base provide these -- they could have been imported from \verb|clx| and used by their qualified name. A base which does not provide them without import can be generated by passing the \verb|primitives=False| flag in.

\subsection{Active Targets}\label{atargets}
An active target, which we show being used in the translation logic described above, is an instance of \verb|ace.ActiveTarget|. It has two primary roles in Ace: 1) it provides an API for code generation to a target language, providing term and type constructors for use during translation (and, to support representational consistency checks, a type system implementation); 2) it provides a bridge to the underlying interoperability API when a generic or concrete function is launched directly from Python, as described in Sec. \ref{implicit}.

An active type or active base can support multiple targets if desired by simply examining it during translation (e.g. by performing capability checks using Python's \verb|hasattr| function) and providing alternative code paths for different combinations of capabilities. Alternatively, an active backend can implement the interfaces available in a different back end and generate code for them in a different way. Our implementation of OpenCL's type system as a collection of active types and an active base does not explicitly support cross-compilation to a CUDA target (though it would be possible to modify it to do so), but our CUDA target does provide partial support for the OpenCL code generation API.


\subsection{Compositional Reasoning}\label{safety}
Every statement and expression in an Ace function is governed by exactly one active type, determined by the dispatch protocol, or by the single active base associated with the Ace function. The representational consistency check ensures that compilation is successful without requiring that types that abstract over other types (e.g. container types) know about their internal implementation details. Together, this permits compositional reasoning about the semantics of Ace functions even in the presence of many extensions. This stands on contrast to many prior approaches to extensibility, where extensions could insert themselves into the semantics in conflicting ways, making the order of imports matter (see Sec. \ref{related}). 

\section{Expressiveness}\label{examples}
Thus far, we have focused mainly on the OpenCL target and shown examples of fairly low-level active types: those that implement OpenCL's primitives (e.g. \verb|clx.Ptr|), extend them in simple but convenient ways (e.g. \verb|clx.Cplx|) and those that make interactive execution across language boundaries safe and convenient (e.g. \verb|clx.NPArray|). 
Ace was first conceived to answer the question: \emph{can we build a statically-typed language with the semantics of a C but the syntax and ease-of-use of a Python?} We submit that these examples (along with a large-scale simulator framework built using them, which we do not have space to detail here) have answered this question in the affirmative. 

But Ace has proven useful for more than low-level tasks like programming a GPU with OpenCL. We now describe several interesting extensions that implement the semantics of primitives drawn from a range of different language paradigms, to justify our claim that these mechanisms are highly expressive. 

\subsection{Growing a Statically-Typed Python Inside an Ace}
Ace comes with a target, base and type implementing Python itself: \verb|ace.python.python|, \verb|ace.python.base| and \verb|ace.python.dyn|. These can be supplemented by additional active types and used as the foundation for writing actively-typed Python functions. These functions can either be compiled ahead-of-time to an untyped Python file for execution, or be immediately executed with just-in-time compilation, just like the OpenCL examples we have shown. Many of the examples in the next section support this target in addition to the OpenCL target we have focused on thus far.

\subsection{Functional Datatypes}
\begin{codelisting}
\lstinputlisting{datatypes_t.py}
\caption{x.}
\label{datatypest}
\end{codelisting}
\begin{codelisting}
\lstinputlisting{datatypes.py}
\caption{y.}
\label{datatypes}
\end{codelisting}
HAIOADJASDASD

\subsection{Parallel Programming}
\subsubsection{OpenCL}
The development of the full OpenCL language using only the extension mechanisms described above provides evidence of the power of this approach. However, to be truly useful, the mechanism must be able to express a wide array of higher-level primitive abstractions. We briefly describe a number of other abstractions that are possible using this mechanism. Many of these are currently available in existing languages either via libraries or as primitives of some specialized language. A study comparing a language-based concurrency solution for Java with an equivalent, though less clean, library-based solution found that language support is preferable but leads to many of the issues we have described \cite{cave2010comparing}.

%\subparagraph{Annotation and Extension Inference}
%In addition to type annotations, OpenCL normally asks for additional annotations in a number of other situations.  Users can annotate functions that meet certain requirements  with the \verb|__kernel| attribute, indicating that they are callable from the host. The \verb|OpenCL| backend can check these and add this annotation automatically. Several types (notably, \verb|double|) and specialized primitive functions require that an OpenCL extension be enabled via a \verb|#pragma|. The OpenCL backend automatically detects many of these cases as well, adding the appropriate \verb|#pragma| declaration. An example of this can be seen in Listing \ref{mapout}, where the use of the \verb|double| type triggers the insertion of the \verb|cl_khr_f64| extension.
%
\subsubsection{Partitioned Global Address Spaces}
A number of recent languages designed for clusters use a partitioned global address space model, including UPC \cite{upc}, Chapel \cite{chapel} and others. These languages provide first-class support for accessing data transparently across a massively parallel cluster. Their type systems track information about \emph{data locality} so that the compiler can emit more efficient code. The extension mechanism can also track this information in a manner analogous to how address space information is tracked in the OpenCL example above, and target an existing portable run-time such as GASNet \cite{bonachea2002gasnet}.

\subsection{General-Purpose Abstractions}
\paragraph{Object Models and Message Passing}
Classes in object-oriented systems can be understood as inducing a type parameterized by a static type specification that emits code to perform dynamic dispatch by some protocol. In Ace, the object system would be a subclass of \verb|ace.Type| (e.g. \verb|JavaObject|), the specification would be a compile-time Python object (e.g. a dictionary mapping names to types, as is done with OpenCL \verb|struct|s, augmented with information about subtyping and methods in more complex systems). The code for checking field and method accesses against the specification would be be in \verb|resolve_Attribute| method and the dynamic dispatch mechanism would be emitted in \verb|translate_Attribute|. That is, Ace supports arbitrary object models, rather than fixing a single one that may not fit all needs, as in almost all other object-oriented languages.

Many parallel programming abstractions can be understood as implementing object models with complex forms of dynamic dispatch. For example, in Charm++, dynamic dispatch involves message passing over a dynamically load-balanced network \cite{kale1993charm++}. While Charm++ is a very sophisticated system, and we do not anticipate that implementing it as an Ace extension would be easy, it is entirely possible to do so using a system like Adaptive MPI that exposes its runtime system \cite{kale2009charm++}. Erlang and other message-passing based systems can also be considered in this manner -- processes can be thought of as objects, channels as methods and messages as calls.

\subsubsection{Functional Datatypes}

\subsubsection{Functional Parallelism}
Another promising approach for parallel programming is in automatic parallelization of purely functional programs. These languages express computations that do not explicitly manipulate memory. They rely instead on the composition of primitives like \verb|map| and \verb|reduce| that transform components of persistent data structures like lists, trees and maps. Data dependencies are thus directly encoded in programs, and automatic parallelization techniques have shown promise in using this information to automatically schedule these parallel programs on concurrent hardware and networks.

The Copperhead language, for example, is based on Python as well and allows users to express functional programs over lists using common functional primitives, compiling them to CUDA code \cite{catanzaro2011copperhead}. We believe that Ace can express precisely the same programming model, implemented as an extension. We have prototyped support for a number of common persistent data structures, including algebraic datatypes, in Ace. Perhaps surprisingly, Python's imperative syntax does not preclude writing programs in a reasonable functional style (due largely to its support for tuples).

\subsection{Interoperability Layers}
The design criteria of \textbf{continuity} and \textbf{interoperability} require consideration of the large body of codes written in a variety of existing languages, across a number of paradigms. Although it is often possible to call from one language to another using a foreign function interface (FFI), this is almost never natural or statically safe. In Ace, however, extensions could be written that internalize the foreign language's type system (note that dynamically-typed languages can be considered to have a single type, often called $\mathtt{dyn}$) and emit code that hides the FFI from users, achieving \textbf{verifiability} and \textbf{ease-of-use}.

%\paragraph{Specialized Optimizations}
%In many cases, specialized code optimizations requires statically tracking invariants throughout a program. Often these optimizations can be encoded as a type system for this reason. For instance, a course project using Ace  implemented substantial portions of the GPU-specific optimizations described in \cite{yang2010gpgpu} as a library, using types to track affine transformations of the global ID in order to construct a summary of the memory access patterns of the kernel. This information can be used both for single-kernel optimization (as in \cite{yang2010gpgpu}) and for future research on cross-kernel fusion and other optimizations.

\subsection{Domain-Specific Type Systems}
\subsubsection{Units of Measure}
Although not strictly related to HPC, a number of domain-specific type systems related to computational science can be implemented within Ace. For example, prior work has considered tracking units of measure (e.g. grams) statically to validate scientific code \cite{conf/cefp/Kennedy09}. This cannot easily be implemented using existing abstraction mechanisms because this information should only be maintained statically to avoid excessive run-time overhead associated with tagging. The Ace extension mechanism allows this information to be tracked in the type system, but not included during translation.


\paragraph{Instrumentation}
Several sophisticated feedback-directed optimizations and adaptive run-time protocols require instrumenting code in various ways. The extension mechanism combined with support for patching classes dynamically using Python enables granular instrumentation that can consider both the syntactic form of an operation as well as its constituent types, easing the implementation of such tools.

This ability could also be used to collect data useful for more rigorous usability and usage studies of languages and abstractions, and we plan on following up on this line of research going forward.



\section{Related Work}\label{related}
\parindent0pt
%
\begin{figure*}
\onecolumn
\begin{longtable}{l l@{}l c@{}c c@{}c c@{}c c@{}c c@{}c}
%\toprule%

&&  &&  && {\bfseries Extensible} && {\bfseries Extensible} && {\bfseries Extensions} && {\bfseries Alternative}\\

{\bfseries Approach} && {\bfseries Examples} && {\bfseries Library} && {\bfseries Syntax} && {\bfseries Type System} && {\bfseries Compositional} && {\bfseries Targets}  \\

\cmidrule(l){1-1} \cmidrule(l){2-3} \cmidrule(l){4-5} \cmidrule(l){6-7} \cmidrule(l){8-9} \cmidrule(l){10-11} \cmidrule(l){12-13}

\endhead


Active Types && Ace && \CIRCLE && \Circle && \CIRCLE && \CIRCLE && \CIRCLE \\

\myrowcolour%
Desugaring && SugarJ \cite{erdweg2011sugarj}, Sugar* \cite{sugarstar} && \Circle && \CIRCLE && \Circle && \Circle && \Circle \\

Rule Injection && Qi \cite{qi}, Typed Racket \cite{TypedScheme2008}, A? && 1+2 && \Circle && \CIRCLE && \Circle && \Circle \\

\myrowcolour%
Static macros /  && Scala \cite{ScalaMacros2013}, MorphJ \cite{MorphJ2011}, OJ \cite{OpenJava2000} && \Circle && \Circle && \Circle && \CIRCLE && \Circle \\

\myrowcolour
Metaprogramming &&  Template Haskell \cite{template-haskell} && && && && && \\

Cross-Compilation && Delite \cite{Delite2011} && \CIRCLE && \Circle && \Circle && \Circle && \CIRCLE \\

\myrowcolour%
EDSL Frameworks && ? && \CIRCLE && \CIRCLE && \CIRCLE && \Circle && \Circle \\

Type-Specific Literals && Wyvern \cite{globaldsl13} && \Circle && \CIRCLE && \Circle && \CIRCLE && \Circle \\
\end{longtable}
\caption{Comparison to related approaches}
\twocolumn
\end{figure*}
\subsection{Active Libraries}
Libraries that contain compile-time logic have been called {\it active libraries} in prior proposals \cite{activelibraries}. A number of  projects, such as Blitz++, have taken advantage of the C++ preprocessor and template-based metaprogramming system to implement domain-specific optimizations \cite{veldhuizen2000blitz++}. In Ace, we replace these brittle mini-languages with a general-purpose language and significantly expand the notion of active libraries by consideration of types as objects in the metalanguage. We thus call these types \emph{active types}.


\subsection{Structural Polymorphism}
Generic functions represent a novel strategy for achieving {\it function polymorphism} -- the ability to define functions that operate over more than a single type. In Ace, generic functions are implicitly polymorphic and can be called with arguments of {\it any type that supports the operations used by the function}. This approach is related to structural polymorphism, however \cite{malayeri2009structural}. Structural types make explicit the requirements on a function, unlike generic functions.

Structural typing can be compared to the more \emph{ad hoc} approach taken by dynamically-typed languages, sometimes called ``duck typing''. It is more flexible than the parametric polymorphism found in many functional languages and in languages like Java (which only allow polymorphic functions that are valid for {\it all} possible types), but is comparable to the C++ template system, as discussed previously.

\subsection{Run-Time Indirection}
{\it Operator overloading} \cite{vanWijngaarden:Mailloux:Peck:Koster:Sintzoff:Lindsey:Meertens:Fisker:acta:1975} and {\it metaobject dispatch} \cite{Kiczales91} are run-time protocols that translate operator invocations into function calls. The function is typically selected according to the type or value of one or more operands. These protocols share the notion of {\it inversion of control} with type-level specification. However, type-level specification is a {\it compile-time} protocol focused on enabling specialized verification and implementation strategies, rather than simply enabling run-time indirection.

\subsection{Term Rewriting Systems}
Many languages and tools allow developers to rewrite expressions according to custom rules. These can broadly be classified as {\it term rewriting systems}. Macro systems, such as those characteristic of the LISP family of languages \cite{mccarthy1978history}, are the most prominent example. Some compile-time metaprogramming systems also allow users to manipulate syntax trees (e.g. MetaML \cite{Sheard:1999:UMS}), and external rewrite systems also exist for many languages. These differ in their direct exposure to syntax trees and their difficulties with propagating type information, since it is not directly encoded in the syntax. The AT\&T mechanism is a type-based mechanism that avoids these issues.

\subsection{Language Frameworks and \\Extensible Compilers}
When the mechanisms available in an existing language prove insufficient, researchers and domain experts often design a new language. A number of tools have been developed to assist with this task, including compiler generators, language workbenches and domain-specific language frameworks (cf \cite{fowler2010domain}). Extensible compilers can be considered a form of language framework as well due to portability issues that using compiler extensions can introduce. It is difficult or impossible for these language-external approaches to achieve interoperability, as discussed above.

\subsection{Extensible Languages}
Extensible languages like SugarJ \cite{erdweg2011sugarj} afford some of the extensibility benefits of Ace, but are not targeted toward HPC. They have largely focused on syntactic extensibility, while Ace relies on a fixed syntax and emphasizes semantic extensibility. They also generally allow users to extend languages globally, which leads to conflicts when multiple extensions are used. AT\&T does not admit such conflicts.

\section{Discussion}\label{discussion}
Python does not truly prevent extensions from interfering with one another because it lacks, e.g., data hiding mechanisms. One type could change the implementation of another by replacing it's methods, for example.

Static type systems are powerful tools for programming language design and implementation. By tracking the type of a value statically, a typechecker can verify the absence of many kinds of errors over all inputs. This simplifies and increases the performance of the run-time system, as errors need not be detected dynamically using tag checks and other kinds of assertions. Many parallel programming abstractions are defined in terms of, or benefit from, a type system that enforces a communication protocol, ensures the consistency of data and simplifies the dynamics of the run-time system (see Section \ref{usecases} for examples). Because \textbf{verifiability} and \textbf{performance} are key criteria and static typing is a core technique, Ace is fundamentally statically-typed.

It is therefore a concern that most programming languages are {\em monolithic} -- a collection of primitives are given first-class treatment by the language implementation, and users can only creatively combine them to implement algorithms and abstractions of their design. Although highly-expressive general-purpose mechanisms have been developed (such as object systems or algebraic datatypes), these may not suffice when researchers or domain experts wish to evolve aspects of the type system, exert control over the representation of data, introduce specialized run-time mechanisms, or if defining an abstraction in terms of existing mechanisms is unnatural or verbose (in summary, to push the boundaries of \textbf{verifiability}, \textbf{performance} and \textbf{ease-of-use}). In these situations, it would be desirable to have the ability to modularly extend existing systems (\textbf{continuity}) with new compile-time logic (\textbf{extensibility}) and be assured that such extensions will never interfere with one another when used in the same program (\textbf{interoperability}).

OpenCL is not necessarily the best tool for every job in high-performance computing. Indeed, HPC is an area where designing a set of primitives that satisfy all users has been particularly challenging, and it appears unlikely that a broad consensus will emerge given the variety of architectures, applications, scales and user communities that it serves, and the number of seemingly promising abstractions that emerge continuously targeting various subsets of this problem space.

It is legitimate to ask, however, why dynamically-typed languages are so widely-used in HPC. Although slow and difficult to reason about, these languages generally excel at satisfying the criteria of \textbf{ease-of-use}. More specifically, Cordy identified the principle of \emph{conciseness} as elimination of
redundancy and the availability of reasonable defaults \cite{cordy1992hints}. Statically-typed languages, particularly those that HPC programmers are exposed to, are verbose, requiring explicit and often redundant type annotations on each function and variable declaration, separate header files, explicit template headers and  instantiation and other sorts of annotations.  The dynamically-typed languages used in HPC, on the other hand, avoid most of this overhead by relying on support from the run-time system. Ace was first conceived to explore the question: \emph{does conciseness require run-time mechanisms, or can one develop a statically-typed language with the same low-level memory and execution model of C but syntactic overhead comparable to a high-level scripting language? }

Rather than designing a new syntax, or modifying the syntax of C, we chose to utilize, \emph{without modification}, the syntax of an existing language, Python. This choice was not arbitrary, but rather a key means by which Ace achieves both \textbf{ease-of-use} and \textbf{continuity}. Python's whitespace-delimited syntax is widely regarded as both concise and readable, and Python is amongst the most widely-adopted languages in computational science \cite{oliphant2007python}. By directly adopting Python's syntax, Ace's syntax is immediately \emph{familiar} and \emph{acceptable} to a significant segment of the intended audience. Moreover, a key benefit of adopting it without modifications is that any {tools} that handle Python source code, including parsers, editors, style checkers and documentation generators, can be used on Ace code without modification. Researchers often dismiss the importance of syntax. By using a well-developed syntax, they no longer need to worry about the equally ``trivial'' task of implementing tools for it.

Professional end-users demand much from new languages and abstractions. In this paper, we began by generating a concrete set of design and adoption criteria that we hope will be of interest and utility to the research community. Based on these constraints, we designed a new language, Ace, making several pragmatic design decisions and introducing several novel techniques, including type propagation via generic functions, extensible type inference, active typechecking and translation and type-aware Python-Ace-OpenCL bindings to uniquely satisfy many of the criteria we discussed, particularly the three criteria that are typically overlooked in other languages. We validated the extension mechanism with a mature implementation of  the entirety of the OpenCL type system, as well as outlined a number of other use cases. Finally, we demonstrated that this language was useful in practice, drastically improving performance without negatively impacting the high-level scientific workflow of a large-scale neurobiological circuit simulation project. 



Ace has some limitations at the moment. Debugging is only supported on the generated code, so if code generation introduces significant complexity, this can be an issue. The OpenCL library we have implemented is a reasonably straightforward internalization of OpenCL itself, however, so debugging has not been a problem thusfar. We believe that active types can be useful to control debugging, and plan to explore this in the future. We will also further explore the use cases and case studies that we have described to validate the design we propose here. We hope that Ace will be developed further by the community to strengthen the foundations upon which new abstractions are implemented and deployed into the HPC professional end-user community.

We suggest three mutually-related {design criteria} that, unlike those in bold above, many languages and language-integrated abstractions have failed to adequately consider: \textbf{continuity}, \textbf{extensibility} and \textbf{interoperability}. These criteria encompass the intuitions that new abstractions will not be adopted in a vacuum, that programming systems must  support change, and that interacting components of an application or workflow should be able to make use of different abstractions naturally and without the possibility of conflict arising at their interface boundaries.


 We anticipate that coding guidelines mandating the use of abstractions that can be shown to have certain desirable properties will replace language-mandated enforcement opinions 
 
 Future work: integrate with something like scalad http://lampwww.epfl.ch/~hmiller/scala2013/resources/pdfs/paper8.pdf. \todo{fix python lang reference citation}

%\acks
%The author is grateful to Jonathan Aldrich, Robert Bocchino and anonymous referees for their useful suggestions. This work was funded by the DOE Computational Science Graduate Fellowship under grant number DE-FG02-97ER25308.
%Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrv}

% The bibliography should be embedded for final submission.

\bibliography{../research}
%\softraggedright
%P. Q. Smith, and X. Y. Jones. ...reference text...

\end{document}
