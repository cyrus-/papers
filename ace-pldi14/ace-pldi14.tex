%\documentclass[12pt]{article}
\documentclass[9pt,preprint]{sigplanconf}
% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.
\usepackage{listings}
\usepackage[usenames,dvipsnames]{color}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amssymb} 
\usepackage{amsthm}
\usepackage{ stmaryrd }

\usepackage{alltt}
\renewcommand{\ttdefault}{txtt}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{light-gray}{gray}{0.75}
\usepackage{listings}
\lstset{
  language=Python,
  showstringspaces=false,
  formfeed=\newpage,
  tabsize=4,
  commentstyle=\itshape,
  basicstyle=\ttfamily\scriptsize,
  morekeywords={lambda, self, assert, as},
  numbers=left,
  numberstyle=\scriptsize\color{light-gray}\textsf,
  xleftmargin=2em,
  stringstyle=\color{mauve}
}
\lstdefinestyle{Bash}{
    language={}, 
    moredelim=**[is][\color{blue}\bf\ttfamily]{`}{`},
}
\lstdefinestyle{OpenCL}{
	language=C++,
	morekeywords={kernel, __kernel, global, __global, size_t, get_global_id, sin}
}

\usepackage{float}
\floatstyle{ruled}
\newfloat{codelisting}{tp}{lop}
\floatname{codelisting}{Listing}

\usepackage{url}

\usepackage{placeins}

\usepackage{textpos}
\begin{document}

\conferenceinfo{-}{-} 
\copyrightyear{-} 
\copyrightdata{[to be supplied]} 

%\titlebanner{{\tt \textcolor{Red}{{\small Under Review -- distribute within CMU only.}}}}        % These are ignored unless
%\preprintfooter{Distribute within CMU only.}   % 'preprint' option specified.

\newcommand{\Ace}{\textsf{Ace}}

\title{\Ace: Growing a Statically-Typed Language Inside a Python}

\authorinfo{~}{~}{~}
%\authorinfo{Cyrus Omar\and Jonathan Aldrich}
 %          {School of Computer Science\\
  %          Carnegie Mellon University}
   %        {\{comar, jonathan.aldrich\}@cs.cmu.edu}   

\maketitle
\begin{abstract}
Evidence suggests that programmers are unwilling to adopt new languages to gain access to language-integrated abstractions, even when they agree that these abstractions might be valuable if all else were held equal. This suggests that language designers should give greater consideration to two related design criteria: \emph{compatibility} with existing languages, tools and ecosystems, and \emph{extensibility}, so that adopting a new language-integrated abstraction does not require adopting a new language.

In this paper, we introduce \Ace, a language compatible with the tools and infrastructure developed for the world's most widely-used dynamically-typed language, Python. 
%Researchers developing languages and abstractions for high-performance computing must consider a number of design criteria, including performance, verifiability, portability and ease-of-use. Despite the deficiencies of legacy tools and the availability of seemingly superior options, end-users have been reluctant to adopt new language-based abstractions. We argue that this can be largely attributed to a failure to consider three additional criteria: continuity, extensibility\- and interoperability. This paper introduces Ace, a language that aims to satisfy this more comprehensive set of design criteria. To do so, Ace introduces several novel compile-time mechanisms, makes principled design choices, and builds upon existing standards in HPC, particularly Python and OpenCL. OpenCL support, rather than being built into the language, is implemented atop an extensibility mechanism that also admits abstractions drawn from other seemingly disparate paradigms. The core innovation underlying this and other features of Ace is a novel reification of types as first-class objects at compile-time, representing a refinement to the concept of active libraries that we call \emph{active types}. We validate our overall design by considering a case study of a simulation framework enabling the modular specification and efficient execution of ensembles of neural simulations across a cluster of GPUs.
\end{abstract}

%\category{D.3.2}{Programming Languages}{Language Classifications}[Extensible Languages]
%\category{D.3.4}{Programming Languages}{Processors}[Compilers]
%\category{F.3.1}{Logics \& Meanings of Programs}{Specifying and Verifying and Reasoning about Programs}[Specification Techniques]
%\keywords
%type-level computation, typed compilation
\section{Introduction}
Computer-aided simulation and data analysis techniques have transformed science and engineering. Surveys show that scientists and engineers now spend up to 40\% of their time writing software \cite{howison2011scientific, hannay2009scientists}. Most of this software targets desktop hardware, while about 20\% of scientists also target either local clusters or super\-computers for more numerically-intensive computations \cite{hannay2009scientists}. To fully harness the power of these platforms, however, these so-called {\em professional end-user developers} \cite{segal2007some} must increasingly write parallel programs.

Professional end-users today generally use dynamically-typed high-level languages like MATLAB, Python, R or Perl for tasks that are not performance-sensitive, such as small-scale data analysis and plotting \cite{nguyen2010survey}. For portions of their analyses where the performance overhead of dynamic type checking and automatic memory management is too high, they will typically call into code written in a statically-typed, low-level language, most commonly C or Fortran, that uses low-level parallel abstractions like pthreads and MPI \cite{4222616,basili2008understanding}. Unfortunately, these low-level languages and abstractions are notoriously difficult to use and automatic verification is intractable in general.

Researchers and domain experts often respond to these challenges by proposing novel language features that aim to strike an intermediate balance between \textbf{performance}, \textbf{verifiability\-}, \textbf{portability} and \textbf{ease-of-use}.
Unfortunately, professional end-users rarely adopt new languages. Indeed, many end-users have become skeptical that novel approaches that originate in the research community can be  practical. This viewpoint was perhaps most succinctly expressed by a participant in a recent study by Basili et al. \cite{basili2008understanding} who stated ``I hate MPI, I hate C++. [But] if I had to choose again, I would probably choose the same.'' Although it may seem paradoxical, the ubiquity of this sentiment demands direct examination by researchers proposing novel abstractions and languages for eventual use by professional end-users in HPC.

We suggest three mutually-related {design criteria} that, unlike those in bold above, many languages and language-integrated abstractions have failed to adequately consider: \textbf{continuity}, \textbf{extensibility} and \textbf{interoperability}. These criteria encompass the intuitions that new abstractions will not be adopted in a vacuum, that programming systems must  support change, and that interacting components of an application or workflow should be able to make use of different abstractions naturally and without the possibility of conflict arising at their interface boundaries.
%that this is far from being a superfluous issue. These criteria can influence the core design of a language or abstraction.

In this paper, we introduce Ace, a programming language targeting professional end-users as well as researchers across high-performance computing and related domains. Ace has followed a principled design methodology guided by this more comprehensive set of design criteria in order to avoid many of the issues that have hindered previous language-based approaches in high-performance computing. These criteria, this design methodology, and the novel mechanisms and designs developed to satisfy these criteria constitute the generalizable contributions of this paper. We also hope that Ace itself will be useful to the HPC community\footnote{\small Ace is openly available at http://acelang.org/.}, and we describe several use cases and an initial case study in order to preliminarily validate it's utility. 

 We begin in Section \ref{usage} with simple examples that show how Ace can be used for low-level GPU programming and introduce the fundamental decisions made in its design. We discuss the motivations, based on the criteria above, behind key design decisions, including the use of static typing, a fixed syntax based on Python, a novel type propagation and inference scheme, and an explicit phase separation between compile-time and run-time logic. Each of these can be seen in Listings 1 and 2, which we will discuss further below.
 
The examples in Section \ref{usage} are based on an internalization of the OpenCL kernel programming language \cite{opencl11} as a library. This library is built atop a novel extensibility mechanism that we call \emph{active typechecking and translation} (AT\&T) and detail in Section \ref{att}. This mechanism relies on the core idea of representing types as first-class objects at compile-time. We refer to these objects as \emph{active types} by analogy with \emph{active libraries} \cite{activelibraries} (see Section \ref{related}). Unlike prior approaches to extensibility where users globally modify the grammar or semantics of a language, and thus introduce conflicts between extensions, AT\&T guarantees that extensions are composable by construction by pairing new rules with new types and limiting their scope to expressions of that type.

%Despite its simplicity and safety, this mechanism is flexible enough to define the entirety of the OpenCL kernel language (which is derived directly from C99) and, combined with Ace's type propagation scheme, substantially enhance it's ease-of-use. 
To demonstrate the flexibility of this mechanism beyond OpenCL, we continue in Section \ref{usecases} by outlining examples of other, higher-level parallel abstractions that can be cleanly implemented using AT\&T, including global address spaces, message passing and functional data parallelism. First-class support for each of these has required a new language in the past. AT\&T allows compile-time logic to be safely included within libraries, and thus these first-class abstractions can be coexist naturally within a single program or workflow.


Ace can be used as a standalone language via the \verb|acec| compiler and also as an interactive compilation environment. This mode of use, described in Section \ref{compenv}, uses just-in-time specialization to  integrate the widely-adopted \verb|numpy| library (including its internal type system) and OpenCL's host API (by a mechanism also available to other host APIs, such as CUDA's) with the Ace compiler itself to enable the direct invocation of Ace functions from within Python scripts with minimal overhead. Achieving this deep level of integration makes use of Ace's novel type representation as well.
 
To demonstrate the utility of Ace for scientific workloads, we describe in Section \ref{casestudy} a case study where Ace was used in this mode to develop a scientific simulation framework. This framework has been used to  specify and efficiently execute thousands of realizations of a large stochastic neural circuit model on clusters of GPUs, achieving the same performance as raw OpenCL code while being more modular and concise than was feasible before.

We conclude in Sections \ref{related} and 7 with related work and a discussion of the limitations of Ace at the time of writing, as well as a discussion of planned future work further validating Ace and building upon the concept of active typing.

% a programming language intended to be used by professional end-users as well as researchers in areas related to high-performance computing and computational science. The primary contribution of this paper consists of describing several novel language mechanisms and novel combinations of existing mechanisms that Ace uses to cohesively address the design criteria above. We anticipate that many of these mechanisms and choices will also influence other languages in the future. 
%Following a principled design methodology, we justify each design decision by appeal to this full set of design criteria and citations to relevant literature. These criteria and methodology constitute another contribution of this work that we hope  will lead to fewer \emph{ad hoc} designs and serve as a foundation for evaluating competing designs in HPC and related domains in the future.

\section{Language Design and Usage}\label{usage}
\begin{codelisting}
\lstinputlisting{hello.py}
\caption{\texttt{[hello.py]} A basic Ace program demonstrating the two-phase structure of Ace programs and libraries.}
\label{hello}
\end{codelisting}
\begin{codelisting}
\begin{lstlisting}[style=Bash]
$ `acec hello.py`
Hello, compile-time world!
Goodbye, compile-time world!
$ `cat hello.cl`
__kernel void main() {
    char* hello = "Hello, run-time world!";
    printf(hello);
}\end{lstlisting}
\caption{Compiling \texttt{hello.py} using the \texttt{acec} compiler.}
\label{helloout}
\end{codelisting}
A variant of the standard ``Hello, World!'' example written in Ace is shown in Listing \ref{hello} and its compilation to statically-typed OpenCL kernel code is demonstrated in Listing \ref{helloout}. The OpenCL kernel language is a variant of C99 with some additions and restrictions to facilitate execution on GPUs and other accelerators, in addition to conventional CPUs. We will discuss it further in subsequent examples.
We emphasize that this module, which we use throughout the paper, is simply a library like any other. The core of Ace gives no special treatment to it; it is distributed together with Ace for convenience. Aspects of its implementation will be described  in Section \ref{att}.

This example demonstrates several key design decisions that characterize Ace: static typing of run-time behavior, a Python-based syntax, a phase distinction between compile-time and run-time logic, and programmatic compilation. We discuss each of these in the next three sections. 
\subsection{Static Typing and Syntax}
Static type systems are powerful tools for programming language design and implementation. By tracking the type of a value statically, a typechecker can verify the absence of many kinds of errors over all inputs. This simplifies and increases the performance of the run-time system, as errors need not be detected dynamically using tag checks and other kinds of assertions. Many parallel programming abstractions are defined in terms of, or benefit from, a type system that enforces a communication protocol, ensures the consistency of data and simplifies the dynamics of the run-time system (see Section \ref{usecases} for examples). Because \textbf{verifiability} and \textbf{performance} are key criteria and static typing is a core technique, Ace is fundamentally statically-typed.

It is legitimate to ask, however, why dynamically-typed languages are so widely-used in HPC. Although slow and difficult to reason about, these languages generally excel at satisfying the criteria of \textbf{ease-of-use}. More specifically, Cordy identified the principle of \emph{conciseness} as elimination of
redundancy and the availability of reasonable defaults \cite{cordy1992hints}. Statically-typed languages, particularly those that HPC programmers are exposed to, are verbose, requiring explicit and often redundant type annotations on each function and variable declaration, separate header files, explicit template headers and  instantiation and other sorts of annotations.  The dynamically-typed languages used in HPC, on the other hand, avoid most of this overhead by relying on support from the run-time system. Ace was first conceived to explore the question: \emph{does conciseness require run-time mechanisms, or can one develop a statically-typed language with the same low-level memory and execution model of C but syntactic overhead comparable to a high-level scripting language? }

Rather than designing a new syntax, or modifying the syntax of C, we chose to utilize, \emph{without modification}, the syntax of an existing language, Python. This choice was not arbitrary, but rather a key means by which Ace achieves both \textbf{ease-of-use} and \textbf{continuity}. Python's whitespace-delimited syntax is widely regarded as both concise and readable, and Python is amongst the most widely-adopted languages in computational science \cite{oliphant2007python}. By directly adopting Python's syntax, Ace's syntax is immediately \emph{familiar} and \emph{acceptable} to a significant segment of the intended audience. Moreover, a key benefit of adopting it without modifications is that any {tools} that handle Python source code, including parsers, editors, style checkers and documentation generators, can be used on Ace code without modification.

\subsection{Phase Separation}
\begin{codelisting}
\lstinputlisting{listing3.py}
\caption{[\texttt{listing\ref{map}.py}] A generic data-parallel higher-order map function written using the OpenCL user module.}
\label{map}
\end{codelisting}
\begin{codelisting}
\lstinputlisting{listing4.py}
\caption{[\texttt{listing\ref{mapadd5dbl}.py}] The generic \texttt{map} function compiled to map the \texttt{add5} function over two  types of input.}
\label{mapadd5dbl}
\end{codelisting}
\begin{codelisting}
\lstinputlisting[style=OpenCL]{listing5.cl}
\caption{[\texttt{listing\ref{mapadd5dbl}.cl}] The OpenCL code generated by running \texttt{acec listing\ref{mapadd5dbl}.py}.}
\label{mapout}
\end{codelisting}


%To demonstrate the somewhat unconventional structure of Ace programs and libraries, we begin in Listing \ref{hello} with a variant of the canonical ``Hello, World!'' example written using the \verb|OpenCL| module. 


Ace's \textbf{continuity} with Python does not stop at its syntax. 
Perhaps the most immediately apparent departure from the standard ``Hello, World!'' example comes on lines 3 and 10 of Listing \ref{hello}, which contain Python \verb|print| statements that are executed at {\em compile-time}.  Ace programs and libraries are Python scripts at the top-level, rather than a list of declarations as in most conventional languages. In other words, Python is the {\em compile-time metalanguage} of Ace. 

A consequence of this choice is that Ace can leverage Python's well-developed package system and associated distribution infrastructure directly (e.g. Line 1). This serves to address another key \textbf{ease-of-use} issue often associated with C-based languages: the fragility of the preprocessor-based packaging system they historically have relied upon. 

Ace functions defining run-time logic are introduced by a decorator. The \verb|@OpenCL.fn| decorator on Line 5 indicates that the \verb|main| function is a statically-typed Ace function targeting the OpenCL backend for code generation (Section \ref{backend}). Without this decorator, the function would simply be a conventional Python function that could be called only at compile-time. Doing so would fail here: \verb|printf| is not a Python function. Rather, it is a compile-time Python object representing an OpenCL primitive residing in the \verb|OpenCL| module. It has an associated Ace type that controls what types of input it can receive and the type of its output given its input type (see Section \ref{att}).

\subsection{Programmatic Compilation}
As defined on Lines 5-7, \verb|main| is a \emph{generic function}. This terminology in Ace is used to indicate a function for which types have not yet been assigned to arguments. Invoking the \verb|compile| method on a generic function with a sequence of argument types invokes the active typechecking and translation mechanism we will describe in Section 3 to produce a \emph{concrete function} -- one with a single type for each argument, internal variable (such as \verb|hello|) and the return value. In Listing \ref{hello}, we name this concrete function \verb|main|, overwriting the generic function of the same name that it is derived from. The compiler does nothing apparently interesting: there are no arguments, the single internal variable takes the OpenCL string type \verb|char*| from its value and the return type is \verb|void|. 

Before moving on to more interesting examples, let us discuss the \verb|acec| compiler shown operating at the shell in Listing \ref{helloout}. The \verb|acec| compiler operates in two steps:
\begin{enumerate}
\item Executes the provided Python file (\verb|hello.py|) which contains Ace functions and (in future examples) types and compile-time code generation logic.
\item Produces source code for concrete functions (produced using the \verb|compile| method) in the top-level Python environment and any other concrete functions, type declarations and other program items required by or generated by these functions. This may produce one or more files (here, just \verb|hello.cl|).
\end{enumerate}

We will show in Section \ref{backend} that for backends with Python bindings, such as OpenCL, CUDA and C, generic functions can be executed directly, without this explicit compilation step to concrete functions, if desired.

\subsection{Example 2: Higher-Order Map}
The ``Hello, World!'' example demonstrates the structure of Ace programs, but it does not require working with types. Listing \ref{map} shows an imperative, data-parallel map primitive written using the OpenCL library introduced above. To review, in OpenCL users can define functions, called {\em kernels}, that execute across thousands of threads. Each kernel has access to a unique index, called its {\em global id}, which can be to ensure that each thread operates on different parts of the input data (Line 5). The \verb|map| kernel defined in Listing \ref{map} applies a transfer function, \verb|f|, to the element of the input array, \verb|input|, corresponding to its global id. It writes the result of this call into the corresponding location in the provided output array, \verb|output|.

As above, \verb|map| is a {\em generic function} (specifically, it is an instance of the class \verb|ace.GenericFn|). This means that its arguments have not been assigned types. The functionality given by the \verb|map| definition is in fact applicable to many combinations of types for \verb|input| and \verb|output| and functions, \verb|f|. In this sense, \verb|map| is actually a \emph{family} of functions defined for all types assignments for \verb|input|, \verb|output| and \verb|f| such that the operations in the function's body are well-defined.

Running \verb|acec listing3.py| would produce no output. To create a {\em concrete function} (that is, an instance of the class \verb|ace.ConcreteFn|) that can be emitted by the compiler, types must be assigned to each of the arguments. Listing \ref{mapadd5dbl} shows how to use the \verb|compile| method to specialize \verb|map| in \emph{two} different ways to apply the \verb|add5| function, defined on Lines 4-6, to arrays  that reside in global memory (OpenCL associates a memory space with pointer types). Line 9 results in a version specialized for arrays of \verb|double|s and Line 10 results in a version for arrays of \verb|int|s. The output of compilation is shown in Listing \ref{mapout}.

\subsection{Types as Metalanguage Objects}
The \verb|compile| method assigns types to the arguments of a generic function. In Listing \ref{mapadd5dbl}, the types we are using are given shorter names, for convenience, on Line 8 (that is, variables in the metalanguage can be used like \verb|typedef| is used in a C-like language). The types \verb|int| and \verb|double| imported from the \verb|OpenCL| module correspond to the OpenCL types of the same name. The types \verb|gptr(int)| and \verb|gptr(double)| correspond to \verb|__global int*| and \verb|__global double*|.

These types are \emph{objects in the metalanguage}, Python. More specifically, types are {instances} of user-defined classes that inherit from the Ace-provided \verb|ace.Type| class. For example, \verb|gptr(double)| is an instance of \verb|OpenCL.PtrType| instantiated with the target type, \verb|double|, and memory space, \verb|__global|, as constructor arguments. The types \verb|double| and \verb|int| are instances of \verb|OpenCL.FloatType| and \verb|OpenCL.IntegerType|, respectively. This notion of types as metalanguage objects is key to the Ace compilation model and also enables other mechanisms that we will discuss in subsequent sections.

\subsection{Type Propagation}
The type assigned to the third argument, \verb|f|, on both Lines 4.9 and 4.10, is \verb|add5.ace_type|. The \verb|ace_type| attribute of a generic function is an instance of \verb|ace.GenericFnType|, the type of Ace generic functions. Ace generic functions are compiled to concrete functions automatically at all internal call sites. That is, when the compiler encounters the call to \verb|f| inside \verb|map| when compiling \verb|map_add5_double|, it compiles a version of \verb|add5| specialized to the \verb|double| type (seen on Line 5.3), and similarly when compiling \verb|map_add5_int| (on Line 5.16, automatically given a unique name to avoid conflicts). This mechanism is called {\em type propagation}. We did not need to use \verb|add5.compile(double)| before compiling \verb|map_add5_dbl| because only functions that are never called in the process of compiling other functions in a module need type information explicitly provided, supporting \textbf{ease-of-use} by increasing conciseness.

In effect, this scheme allows for a form of higher-order functional programming even when targeting languages, like OpenCL, that have no support for higher-order functions (OpenCL, unlike C99, does not support function pointers). This works because the \verb|ace.GenericFnType| for one function, such as \verb|add5|, is not equal to  the \verb|ace.GenericFnType| for a superficially similar function, such as \verb|add6| (defined as one would expect). To put it in type theoretic terms, \verb|ace.GenericFnType|s are singleton types, {\em uniquely inhabited} by a single generic function. A consequence of this is that they are not useful as first-class values (i.e. they cannot be written into a collection). This is often valuable, particularly in parallel programming where compile-time specialization is valuable to avoid \textbf{performance} and \textbf{ease-of-use} issues that occur when using function pointers.

Concrete functions, on the other hand, can be given a true function type (e.g. \verb|add5| could be compiled to a concrete function with type \verb|int| $\rightarrow$ \verb|int|) if targeting a backend that supports them, such as C99, or by using an integer-indexed jump table in OpenCL (we have not implemented this mechanism using Ace as of the time of writing, but do not anticipate difficulties in doing so).

Type propagation via generic functions can be compared to template specialization in C++, where both the template headers (containing nested template parameters for function arguments) and specialization parameters at any call sites are inferred automatically from usage. This significantly simplifies a sophisticated feature of C++ and introduces it to OpenCL and C, which do not support templates. Other uses for C++ templates are subsumed by the metaprogramming features discussed in Section 5.
% Is this really any more concise than using C + templates? Etc. relation to types. Conciseness.

\subsection{Whole-Function Type Inference}
\begin{codelisting}
\lstinputlisting{listing6.py}
\caption{\texttt{[listing6.py]} A function demonstrating whole-function type inference when multiple values with differing types are assigned to a single identifier, \texttt{y}.}
\label{inference}
\end{codelisting}

On Line 5 in the generic \verb|map| function in Listing \ref{map}, the variable \verb|gid| is initialized with the result of calling the OpenCL primitive \verb|get_global_id|.  The type for \verb|gid| is never given explicitly. This is a simple case of Ace's more general {\em whole-function type inference}. In this case, \verb|gid| will be inferred to have type \verb|size_t| because that is the return type of \verb|get_global_id| (as defined in the OpenCL specification, which the \verb|ace.OpenCL| module follows). The result can be observed on Lines 11 and 24 in Listing \ref{mapout}. 

Inference is not restricted within single assignments, as in the \verb|map| example, however. Multiple assignments to the same identifier with values of differing types, or multiple return statements, can be combined if the types in each case are compatible with one another (e.g. by a subtyping relation or an implicit coercion). In Listing \ref{inference}, the \verb|threshold_scale| function assigns different values to \verb|y| in each branch of the conditional. In the first branch, the value \verb|0| is an \verb|int| literal. However, in the second branch of the loop, the type depends on the types of both arguments, \verb|x| and \verb|scale|. We show two choices for these types on Lines 11 and 12. Type inference correctly combines these two types according to OpenCL's C99-derived rules governing numeric types (defined by the user in the \verb|OpenCL| module, as we will describe in Section \ref{att}). We can verify this programmatically on Lines 12 and 13. Note that this example would also work correctly if the assignments to \verb|y| were replaced with \verb|return| statements (in other words, the return value of a function is treated as an assignable for the purpose of type inference).
\subsection{Annotation and Extension Inference}
In addition to type annotations, OpenCL normally asks for additional annotations in a number of other situations.  Users can annotate functions that meet certain requirements  with the \verb|__kernel| attribute, indicating that they are callable from the host. The \verb|OpenCL| backend can check these and add this annotation automatically. Several types (notably, \verb|double|) and specialized primitive functions require that an OpenCL extension be enabled via a \verb|#pragma|. The OpenCL backend automatically detects many of these cases as well, adding the appropriate \verb|#pragma| declaration. An example of this can be seen in Listing \ref{mapout}, where the use of the \verb|double| type triggers the insertion of the \verb|cl_khr_f64| extension.

\section{Extensibility}\label{att}
Thus far, we have been discussing the \verb|OpenCL| module in our examples. This module faithfully implements all the types and operations of the OpenCL kernel language, a portable standard for writing low-level code on multi-core processors and accelerators \cite{opencl11}. The functions we wrote have used these primitives with the \verb|OpenCL.OpenCL| backend, so the translation has been direct and no run-time overhead has been introduced. Thus, as described so far, Ace has affirmatively resolved the question it was originally conceived to address, discussed in Section 2.1. 

\subsection{Monolithic vs. Extensible Languages}
OpenCL is not necessarily the best tool for every job in high-performance computing. Indeed, HPC is an area where designing a set of primitives that satisfy all users has been particularly challenging, and it appears unlikely that a broad consensus will emerge given the variety of architectures, applications, scales and user communities that it serves, and the number of seemingly promising abstractions that emerge continuously targeting various subsets of this problem space.

It is therefore a concern that most programming languages are {\em monolithic} -- a collection of primitives are given first-class treatment by the language implementation, and users can only creatively combine them to implement algorithms and abstractions of their design. Although highly-expressive general-purpose mechanisms have been developed (such as object systems or algebraic datatypes), these may not suffice when researchers or domain experts wish to evolve aspects of the type system, exert control over the representation of data, introduce specialized run-time mechanisms, or if defining an abstraction in terms of existing mechanisms is unnatural or verbose (in summary, to push the boundaries of \textbf{verifiability}, \textbf{performance} and \textbf{ease-of-use}). In these situations, it would be desirable to have the ability to modularly extend existing systems (\textbf{continuity}) with new compile-time logic (\textbf{extensibility}) and be assured that such extensions will never interfere with one another when used in the same program (\textbf{interoperability}).

%Because Ace libraries can contain compile-time logic, written in the metalanguage as described in the previous section, these primitive definitions can be distributed as modules, rather than as extensions to particular compilers or domain-specific languages.
\subsection{Active Typechecking and Translation}
To achieve these criteria, Ace has been designed around a minimal, {extensible} core. Users introduce the compile-time logic associated with primitive types and operations from \emph{within libraries}, as opposed to by some language-external mechanism such as a domain-specific language framework or extensible compiler (see Section \ref{related}). 

The two phases of compilation that can be controlled by users are together referred to as \emph{active typechecking and translation (AT\&T)}. They are invoked the first time the \verb|compile| method of a generic function is called, or when type propagation occurs, with a particular type assignment (a cached concrete function is returned subsequently).

\subsubsection{Active Typechecking}
\begin{codelisting}
\lstinputlisting{listing9.py}
\caption{\texttt{[ace.OpenCL]} A portion of the implementation of OpenCL pointer types implementing subscripting logic using the Ace extension mechanism, AT\&T.}
\label{pointers}
\end{codelisting}

%We now explain how new primitive types and operators can be defined in Ace. 
When the compiler encounters an expression, it must first verify its validity by either assigning it a type or raising a meaningful type error. Rather than defining fixed logic for this, Ace defers control to the {type} of the \emph{primary operand} according to a {\em dispatch protocol}. Because types are metalanguage instances of user-defined types derived from \verb|ace.Type| (cf. Section 2.5), dispatch corresponds to calling a method of this base class.

Let us again consider the data-parallel map example of Section 2. When \verb|map| is compiled on Line 9 of Listing \ref{mapadd5dbl}, the first two argument types are \verb|gptr(double)|. This type is an instance of the user-defined \verb|OpenCL.PtrType| which inherits from \verb|ace.Type|. When the compiler encounters the expression \verb|input[gid]| on Line 6, the dispatch protocol is to defer control to the type of \verb|input| by invoking the method named \verb|resolve_Subscript|.

The relevant portion of \verb|OpenCL.PtrType| as well as \verb|gptr| is shown in Listing \ref{pointers}. The \verb|resolve_Subscript| method on Line 8 receives a context and the syntax tree of the node being considered. The context contains information about variables in scope and other contextual information, and also exposes a method, \verb|resolve_type|, that this method uses to recursively resolve the types of other subexpressions, here the slice which will be \verb|gid|, as needed. The context will have that \verb|gid| is the machine-dependent integer type \verb|size_t| as discussed in Section 2. On Line 10, it confirms that this type is an instance of an integer type and thus, it assigns the whole expression, \verb|input[gid]|, the target type of the pointer, \verb|double|. Had the function attempted to index \verb|input| using a non-integer expression, the method would take the other branch of the conditional and raise a type error, with a custom error message, on Line 13. We note that error messages are an important component of \textbf{ease-of-use} \cite{marceau2011measuring}. Indeed, a widely-reported frustration with C++ is that it produces overly verbose and cryptic error messages, particularly when templates are used in clever ways.

\subsubsection{Dispatch Protocol}
Below are examples of the rules that comprise the Ace dispatch protocol. Due to space constraints, we do not list the entire dispatch protocol, which contains a rule for each possible syntactic form in the language.
\begin{itemize}
\item Responsibility over {\bf unary operations} like \verb|-x| is given to the type assigned to the operand, \verb|x|.
\item Responsibility over {\bf binary operations} is first handed to the type assigned to the left operand. If it indicates that it does not understand the operation, the type assigned to the right operand is handed responsibility, via a different method call. {Note that this operates similarly to the Python run-time operator overloading protocol; see Section \ref{related}.}
\item Responsibility over {\bf attribute access} (\texttt{e.attr}), {\bf subscript access} (\texttt{e[idx]}) and \textbf{calls} (\verb|e(e1, ..., en)|) is handed to the type assigned to \texttt{e}.
\item In support of the type inference mechanism described in Section \ref{inference}, responsibility to resolve a type given multiple assignments can be taken by any of the types of the assignments, with priority given to later types.
\end{itemize}



\subsubsection{Active Translation}
Once typechecking a method is complete, the compiler must subsequently translate each Ace source expression into an expression in the target language. This has been OpenCL in the examples thus far, but we describe a generalization of this in the next section. 

It does so by again applying the dispatch protocol to call a method of the form \verb|translate_|$X$, where $X$ is the syntactic form of the expression. This method is responsible for returning a copy of the expression's ast node with an additional attribute, \verb|code|, containing the source code of the translation, represented here as a string though it may also be represented in a structured manner. In our example, it is simply a direct translation to the corresponding OpenCL attribute access (Line 20), using the recursively-determined translations of the operands (Lines 16-17).  More sophisticated abstractions may insert arbitrarily complex statements and expressions during this phase. The context also provides some support for non-local insertions, such as new top-level type declarations, imports and helper code (not shown).

\subsubsection{User-Defined Backends}\label{backends}
Thus far, we have discussed using OpenCL itself as a backend for our implementation of the OpenCL primitives. This backend is called \verb|OpenCL| in the \verb|ace.OpenCL| module. Ace supports the definition of new backends in a manner similar to the introduction of new types, by extending the \verb|ace.Backend| base class. Backends are specified for a function by using the decorator form \verb|@backend.fn|, as can be seen in the previous examples. 
Backends are responsible for some aspects of the grammar that do not admit simple dispatch to the type of a subterm, such as number and string literals or statement forms like \verb|while| (though \verb|for| is handled by an iterator-like protocol, not shown). 

In addition to the OpenCL backend, preliminary C99 and CUDA backends are available (with the caveat that they have not been as fully developed or tested as of this writing.) This allows us to use the OpenCL kernel language, which offers a simplified variant of C99, without relying on the full OpenCL stack, which may not be well-supported by  vendors with proprietary solutions such as CUDA. Backends not based on the C family are also possible, but we leave such developments for future work. During the translation phase, types can access the backend via the context and emit different code for different supported backends (not shown above due to space considerations).

\subsubsection{Composability and Interoperability}\label{safety}
Because a type can only exert control over typechecking and translation of operations where an expression of that type is the primary operand, extensions defined using AT\&T can not interfere with one another by construction. This does not imply that there are no \textbf{interoperability} issues to consider, however. A type may need to know about other types (e.g. pointer types need to know about integer types) and if this is done without consideration of future extensions, it may be difficult to integrate data produced by one type system with another. These issues cannot easily be addressed by a language design, however.

\subsection{Use Cases}\label{usecases}
The development of the full OpenCL language using only the extension mechanisms described above provides evidence of the power of this approach. However, to be truly useful, the mechanism must be able to express a wide array of higher-level primitive abstractions. We briefly describe a number of other abstractions that are possible using this mechanism. Many of these are currently available in existing languages either via libraries or as primitives of some specialized language. A study comparing a language-based concurrency solution for Java with an equivalent, though less clean, library-based solution found that language support is preferable but leads to many of the issues we have described \cite{cave2010comparing}.

\subsubsection{Parallel Programming}
\paragraph{Partitioned Global Address Spaces}
A number of recent languages designed for clusters use a partitioned global address space model, including UPC \cite{upc}, Chapel \cite{chapel} and others. These languages provide first-class support for accessing data transparently across a massively parallel cluster. Their type systems track information about \emph{data locality} so that the compiler can emit more efficient code. The extension mechanism can also track this information in a manner analogous to how address space information is tracked in the OpenCL example above, and target an existing portable run-time such as GASNet \cite{bonachea2002gasnet}.

\paragraph{Object Models and Message Passing}
Classes in object-oriented systems can be understood as inducing a type parameterized by a static type specification that emits code to perform dynamic dispatch by some protocol. In Ace, the object system would be a subclass of \verb|ace.Type| (e.g. \verb|JavaObject|), the specification would be a compile-time Python object (e.g. a dictionary mapping names to types, as is done with OpenCL \verb|struct|s, augmented with information about subtyping and methods in more complex systems). The code for checking field and method accesses against the specification would be be in \verb|resolve_Attribute| method and the dynamic dispatch mechanism would be emitted in \verb|translate_Attribute|. That is, Ace supports arbitrary object models, rather than fixing a single one that may not fit all needs, as in almost all other object-oriented languages.

Many parallel programming abstractions can be understood as implementing object models with complex forms of dynamic dispatch. For example, in Charm++, dynamic dispatch involves message passing over a dynamically load-balanced network \cite{kale1993charm++}. While Charm++ is a very sophisticated system, and we do not anticipate that implementing it as an Ace extension would be easy, it is entirely possible to do so using a system like Adaptive MPI that exposes its runtime system \cite{kale2009charm++}. Erlang and other message-passing based systems can also be considered in this manner -- processes can be thought of as objects, channels as methods and messages as calls.

\paragraph{Functional Parallelism}
Another promising approach for parallel programming is in automatic parallelization of purely functional programs. These languages express computations that do not explicitly manipulate memory. They rely instead on the composition of primitives like \verb|map| and \verb|reduce| that transform components of persistent data structures like lists, trees and maps. Data dependencies are thus directly encoded in programs, and automatic parallelization techniques have shown promise in using this information to automatically schedule these parallel programs on concurrent hardware and networks.

The Copperhead language, for example, is based on Python as well and allows users to express functional programs over lists using common functional primitives, compiling them to CUDA code \cite{catanzaro2011copperhead}. We believe that Ace can express precisely the same programming model, implemented as an extension. We have prototyped support for a number of common persistent data structures, including algebraic datatypes, in Ace. Perhaps surprisingly, Python's imperative syntax does not preclude writing programs in a reasonable functional style (due largely to its support for tuples).

\subsubsection{Other Use Cases in HPC}
\paragraph{Interoperability Layers}
The design criteria of \textbf{continuity} and \textbf{interoperability} require consideration of the large body of codes written in a variety of existing languages, across a number of paradigms. Although it is often possible to call from one language to another using a foreign function interface (FFI), this is almost never natural or statically safe. In Ace, however, extensions could be written that internalize the foreign language's type system (note that dynamically-typed languages can be considered to have a single type, often called $\mathtt{dyn}$) and emit code that hides the FFI from users, achieving \textbf{verifiability} and \textbf{ease-of-use}.

\paragraph{Specialized Optimizations}
In many cases, specialized code optimizations requires statically tracking invariants throughout a program. Often these optimizations can be encoded as a type system for this reason. For instance, a course project using Ace  implemented substantial portions of the GPU-specific optimizations described in \cite{yang2010gpgpu} as a library, using types to track affine transformations of the global ID in order to construct a summary of the memory access patterns of the kernel. This information can be used both for single-kernel optimization (as in \cite{yang2010gpgpu}) and for future research on cross-kernel fusion and other optimizations.

\paragraph{Domain-Specific Type Systems}
Although not strictly related to HPC, a number of domain-specific type systems related to computational science can be implemented within Ace. For example, prior work has considered tracking units of measure (e.g. grams) statically to validate scientific code \cite{conf/cefp/Kennedy09}. This cannot easily be implemented using existing abstraction mechanisms because this information should only be maintained statically to avoid excessive run-time overhead associated with tagging. The Ace extension mechanism allows this information to be tracked in the type system, but not included during translation.


\paragraph{Instrumentation}
Several sophisticated feedback-directed optimizations and adaptive run-time protocols require instrumenting code in various ways. The extension mechanism combined with support for patching classes dynamically using Python enables granular instrumentation that can consider both the syntactic form of an operation as well as its constituent types, easing the implementation of such tools.

This ability could also be used to collect data useful for more rigorous usability and usage studies of languages and abstractions, and we plan on following up on this line of research going forward.


\section{Ace: a Compilation Environment}\label{compenv}\label{backend}
\begin{codelisting}
\lstinputlisting{listing8.py}
\caption{[\texttt{listing\ref{py}.py}] A full OpenCL program using the \texttt{Ace.OpenCL} Python bindings, including data transfer to and from a device and direct invocation of a generic function, \texttt{map}, as a kernel without explicit compilation.}
\label{py}
\end{codelisting}

As discussed in the Introduction, a common workflow for professional end-users is to use a high-level scripting language for orchestration, small-scale data analysis and visualization and call into a low-level language for performance-critical sections. Python is designed for this style of use \cite{sanner1999python} and is widely used by professional end-users in HPC as a high-level scripting language. It features mature support for calling into code written in low-level languages. Developers can call into native libraries using its foreign function interface (FFI),  or by using a wrapper library like \verb|pycuda| for code compiled with CUDA \cite{klockner2011pycuda} or \verb|weave| for C and C++. 

Although C, C++ and CUDA's compilers are separate executables on the system, the OpenCL language was also designed for this workflow, in that it exposes the compiler and memory management directly as an API, called the \emph{host API}. The \verb|pyopencl| module exposes this API and supports basic interoperability with \verb|numpy|, the low-level linear algebra package for Python. With both \verb|pyopencl| and \verb|pycuda|, users generate OpenCL or CUDA source code as strings, compile it programmatically, then execute it using the run-time APIs that each library provides \cite{klockner2011pycuda}. This mode of use can be considered one where Python serves as an \emph{interactive compilation environment}.

Ace supports a refinement to this workflow, as an alternative to the \verb|acec| compiler described above. In other words, \verb|acec| can generate source code for kernels but it does not specify how and from what language thet will be called. This mode of use allows Python to be the calling language.

At the time of writing, this is only supported with the OpenCL backend, but other backends can implement this feature as well by satisfying a simple interface specification. The OpenCL host API wraps and is a superset of the \verb|pyopencl|, adding a simpler type-aware API. Both generic functions and concrete functions can then be called like regular Python functions, with additional keyword arguments specifying the global and local size (i.e. the number of threads and how they are grouped). Device buffers can carry type information, unlike in the basic OpenCL host API, and this type information can be propagated from Python to Ace functions directly, as if the call had been within a kernel,  eliminating the \verb|compile| step that we have been using thus far and thus all mention of types. 

An example of this for the generic \verb|map| function defined in Listing \ref{map} is shown in Listing \ref{py}, with the call itself on Lines 12-13. 
The first two arguments to \verb|map| are OpenCL buffers, generated using a simplified wrapper to the \verb|pyopencl| APIs on Lines 9-10. This wrapper associates type information with each buffer, based on the type of the \verb|numpy| array, and this is used to implicitly compile \verb|map| as appropriate the first time it is called for any given combination of input types. Notice also that \verb|add5| is passed in directly.

By way of comparison, the same program written using the OpenCL C API directly is an order of magnitude larger and significantly more difficult to read and understand. It does not support higher-order functions nor is there any way to write \verb|map| in a type-generic way. A full implementation of the logic of \verb|map| written using the \verb|pyopencl| bindings and metaprogramming techniques as described in \cite{klockner2011pycuda} is still twice as large and more difficult to comprehend than the code we have shown thus far. Not shown are several additional conveniences, such as delegated kernel sizing and \verb|In| and \verb|Out| constructs that can reduce the size and improve the clarity of this code further; due to a lack of space, the reader is referred to the language documentation.


\section{Case Study}\label{casestudy}
An important criteria that practitioners use to evaluate a language or abstraction is whether significant case studies have been conducted with it, sometimes called \textbf{social proof} \cite{basili2008understanding}. In this section, we briefly (due to space constraints) show an application of the mode of use discussed above to support a modular, high-performance scientific simulation library. This library was used to simulate  thousands of parallel realizations of a stochastic spiking neurobiological circuit. The realizations were distributed over a cluster of GPUs using an existing Python library supporting remote procedure calls. This relied critically on Ace's representation of types to determine the memory usage of each realization automatically, and thus distribute realizations and allocate memory on each node appropriately. It also used metaprogramming features of Ace to generate kernels and specialize them to each node the simulation was running on.

\subsection{Metaprogramming in Ace}
\begin{codelisting}
\lstinputlisting[commentstyle=\color{mauve}]{listing7.py}
\caption{[\texttt{listing9.py}] Metaprogramming with Ace, showing how to construct generic functions from both strings and abstract syntax trees, and how to manipulate syntax trees at compile-time.}
\label{metaprogramming}
\end{codelisting}
Metaprogramming refers to the practice of writing programs that manipulate other programs. There are a number of use cases for this technique, including domain-specific optimizations and code generation for programs with a repetitive structure that cannot easily be captured using available abstractions \cite{klockner2011pycuda}. OpenCL in particular relies on code generation as a fundamental mechanism, which is cited as justification for its lack of support for higher-order programming. Ace supports programmatic compilation, higher-order functions and a flexible language extension mechanism, so many use cases for metaprogramming have been eliminated. 

However, there are still valid uses for this feature and Ace fully supports it. On Lines 4-7 of Listing \ref{metaprogramming}, an Ace function is constructed from a string containing its source using the \verb|from_str| variant of the \verb|OpenCL.fn| method. It can also be constructed directly from an abstract syntax tree (AST), as implemented by the Python standard \verb|ast| package, using the \verb|from_ast| variant of \verb|fn|, demonstrated on Line 10. The AST here is generated programmatically by calling the \verb|specialize| function, which produces a copy of the syntax tree of the \verb|plus| function with the argument, \verb|b|, eliminated and its uses replaced with a constant, \verb|5|. This transformation as well as some others are distributed in \verb|ace.astx| for convenience.


\subsection{Background}
A neural circuit can be modeled as a network of coupled differential equations, where each node corresponds to a single neuron or a small population. Each node has temporal dynamics given by one or more ordinary differential equations. Single simulations can contain from hundreds to tens of millions of neurons each, depending on the specific problem being studied. In some cases, such as when studying the effects of noise on network dynamics or to sweep a parameter space, hundreds or thousands of realizations must be generated. In these cases, care must be taken to only probe the simulation for relevant data and process portions of it as the simulation progresses, because the amount of data generated is often too large to store in its entirety.

The problem we discuss here involved studying a problem that required running up to 1,000 realizations of a network of between 4,000 and 10,000 stochastic neurons each. An initial solution to this problem used the Brian framework, written in Python, to conduct these simulations on a CPU. Brian was selected because it allowed the structure of the  simulation to be specified in a modular and straightforward manner. This solution required between 60 and 70 minutes to conduct the simulations and up to 8 hours to analyze the data each time a parameter of the simulation was modified.

Unsatisfied with the performance of this approach, the author developed an accelerated variant of the simulation using C++ and CUDA. Although this produced significant speedups, reducing the time for a simulation by a factor of 40 and the runtime of the slowest analyses by a factor of 200, the overall workflow was also significantly disrupted. In order to support the many variants of models, parameter sets, and probing protocols, C preprocessor flags were necessary to selectively include or exclude code snippets. This quickly led to an incomprehensible and difficult to maintain file structure. Moreover, much of the subsequent data analysis and visualization was conducted using Python, so marshalling the relevant data between processes also became an issue. Doing so during a simulation was not attempted.

\subsection{The {\sf cl.egans} Simulation Library}


\begin{codelisting}
\lstinputlisting{listing10.py}
\caption{\texttt{[listing10.py]} An example of a nested simulation tree, showing that specifying a simulation is both simple and modular. The first argument to the constructor specifies each node's parent.}
\label{spec}
\end{codelisting}

\begin{codelisting}
\lstinputlisting{listing11.py}
\caption{\texttt{[listing11.py]} An example of a hook that inserts code and also inserts new, nested hooks for downstream simulation nodes  below that.}
\label{impl}
\end{codelisting}

In order to eliminate these issues while retaining the performance profile of the GPU-accelerated code, the project was ported to Ace. Rather than using preprocessor directives to control the code contained in the final GPU kernels used to execute the simulation and data analyses, the group was able to develop a more modular  library called {\sf cl.egans}\footnote{...after {\it c. elegans}, a model organism in neuroscience} based on the language's compile-time code generation mechanism and Python and OpenCL bindings.

{\sf cl.egans} leverages Python's object-oriented features to enable modular, hierarchical simulation specifications. For example, Figure \ref{spec} shows an example where a neuron model (\verb|ReducedLIF|) is added to the root of the simulation, a synapse model (\verb|ExponentialSynapse|) is then added to it, and its conductance is probed by adding a probe model as a child of the synapse model. Interleaved analyses are specified as nodes as well (not shown).

Implementations of these classes do not evaluate the simulation logic directly, but rather contain methods that generate Ace source code for insertion at various points, called {\it hooks}, in the final simulation kernel. The hook that code is inserted into is determined by the method name, and code can be inserted into any hook defined anywhere upstream in the simulation tree. New hooks can also be defined in these methods and these become available for use by child nodes. Figure \ref{impl} shows an example of a class that inserts code in the \verb|model_code| hook and defines several new hooks. This protocol is closely related to the notion of {\it frame-oriented programming}. Although highly modular, this strategy avoids the performance penalties associated with standard object-oriented methodologies via code generation.

Compared to a similar protocol targeting OpenCL directly, the required code generation logic is significantly simpler because it enables classes like \verb|StateVariable| to be written generically for all types of state variables, without carrying extra parameters and {\it ad hoc} logic to extract and compute the result types of generated expressions. Moreover, because types are first-class objects in the metalanguage, they can be examined during the memory allocation step to enable features like fully-automatic parallelization of multiple realizations across one or more devices, a major feature of {\sf cl.egans} that competing frameworks cannot easily offer. Moreover, memory allocation is significantly simplified by the availability of typing information at compile-time. The amount of memory needed by a simulation can be calculated statically and thus distributing the simulation over a cluster simply requires determining the available memory on each device in the cluster.

Once the kernel has been generated and memory has been allocated, the simulation can be executed directly  using the bindings above. The results of this simulation are available to the Python code during and following the simulation and can be visualized and further analyzed using standard tools. Once the computations is complete, the  garbage collector is able to handle deallocation of GPU memory automatically (a feature of the underlying \verb|pyopencl| library \cite{klockner2011pycuda}.)

Using this Ace-based framework, the benefits of the Brian-based workflow were recovered without the  corresponding decrease in performance relative to the previous CUDA-based solution, leading ultimately to a satisfying solution.

\section{Related Work}\label{related}
\subsection{Active Libraries}
Libraries that contain compile-time logic have been called {\it active libraries} in prior proposals \cite{activelibraries}. A number of  projects, such as Blitz++, have taken advantage of the C++ preprocessor and template-based metaprogramming system to implement domain-specific optimizations \cite{veldhuizen2000blitz++}. In Ace, we replace these brittle mini-languages with a general-purpose language and significantly expand the notion of active libraries by consideration of types as objects in the metalanguage. We thus call these types \emph{active types}.


\subsection{Structural Polymorphism}
Generic functions represent a novel strategy for achieving {\it function polymorphism} -- the ability to define functions that operate over more than a single type. In Ace, generic functions are implicitly polymorphic and can be called with arguments of {\it any type that supports the operations used by the function}. This approach is related to structural polymorphism, however \cite{malayeri2009structural}. Structural types make explicit the requirements on a function, unlike generic functions.

Structural typing can be compared to the more \emph{ad hoc} approach taken by dynamically-typed languages, sometimes called ``duck typing''. It is more flexible than the parametric polymorphism found in many functional languages and in languages like Java (which only allow polymorphic functions that are valid for {\it all} possible types), but is comparable to the C++ template system, as discussed previously.

\subsection{Run-Time Indirection}
{\it Operator overloading} \cite{vanWijngaarden:Mailloux:Peck:Koster:Sintzoff:Lindsey:Meertens:Fisker:acta:1975} and {\it metaobject dispatch} \cite{Kiczales91} are run-time protocols that translate operator invocations into function calls. The function is typically selected according to the type or value of one or more operands. These protocols share the notion of {\it inversion of control} with type-level specification. However, type-level specification is a {\it compile-time} protocol focused on enabling specialized verification and implementation strategies, rather than simply enabling run-time indirection.

\subsection{Term Rewriting Systems}
Many languages and tools allow developers to rewrite expressions according to custom rules. These can broadly be classified as {\it term rewriting systems}. Macro systems, such as those characteristic of the LISP family of languages \cite{mccarthy1978history}, are the most prominent example. Some compile-time metaprogramming systems also allow users to manipulate syntax trees (e.g. MetaML \cite{Sheard:1999:UMS}), and external rewrite systems also exist for many languages. These differ in their direct exposure to syntax trees and their difficulties with propagating type information, since it is not directly encoded in the syntax. The AT\&T mechanism is a type-based mechanism that avoids these issues.

\subsection{Language Frameworks and \\Extensible Compilers}
When the mechanisms available in an existing language prove insufficient, researchers and domain experts often design a new language. A number of tools have been developed to assist with this task, including compiler generators, language workbenches and domain-specific language frameworks (cf \cite{fowler2010domain}). Extensible compilers can be considered a form of language framework as well due to portability issues that using compiler extensions can introduce. It is difficult or impossible for these language-external approaches to achieve interoperability, as discussed above.

\subsection{Extensible Languages}
Extensible languages like SugarJ \cite{erdweg2011sugarj} afford some of the extensibility benefits of Ace, but are not targeted toward HPC. They have largely focused on syntactic extensibility, while Ace relies on a fixed syntax and emphasizes semantic extensibility. They also generally allow users to extend languages globally, which leads to conflicts when multiple extensions are used. AT\&T does not admit such conflicts.

\section{Conclusion}

Professional end-users demand much from new languages and abstractions. In this paper, we began by generating a concrete set of design and adoption criteria that we hope will be of interest and utility to the research community. Based on these constraints, we designed a new language, Ace, making several pragmatic design decisions and introducing several novel techniques, including type propagation via generic functions, extensible type inference, active typechecking and translation and type-aware Python-Ace-OpenCL bindings to uniquely satisfy many of the criteria we discussed, particularly the three criteria that are typically overlooked in other languages. We validated the extension mechanism with a mature implementation of  the entirety of the OpenCL type system, as well as outlined a number of other use cases. Finally, we demonstrated that this language was useful in practice, drastically improving performance without negatively impacting the high-level scientific workflow of a large-scale neurobiological circuit simulation project. 

Ace has some limitations at the moment. Debugging is only supported on the generated code, so if code generation introduces significant complexity, this can be an issue. The OpenCL library we have implemented is a reasonably straightforward internalization of OpenCL itself, however, so debugging has not been a problem thusfar. We believe that active types can be useful to control debugging, and plan to explore this in the future. We will also further explore the use cases and case studies that we have described to validate the design we propose here. We hope that Ace will be developed further by the community to strengthen the foundations upon which new abstractions are implemented and deployed into the HPC professional end-user community.

%\acks
%The author is grateful to Jonathan Aldrich, Robert Bocchino and anonymous referees for their useful suggestions. This work was funded by the DOE Computational Science Graduate Fellowship under grant number DE-FG02-97ER25308.
%Acknowledgments, if needed.

% We recommend abbrvnat bibliography style.

\bibliographystyle{abbrvnat}

% The bibliography should be embedded for final submission.

\bibliography{../research}
%\softraggedright
%P. Q. Smith, and X. Y. Jones. ...reference text...

\end{document}
