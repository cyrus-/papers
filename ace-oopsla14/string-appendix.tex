\documentclass[10pt,preprint]{sigplanconf}
\usepackage{bussproofs}    % Gentzen-style deduction trees *with aligned sequents!*
\usepackage{mathpartir}	% For type-settting type checking rule figures
\usepackage{syntax}		% For type-setting formal grammars.


\usepackage{hyperref}		% For links in citations

\usepackage{float}			% Make figures float if [H] option is passed.

\iffalse
\usepackage{listings}		% For typesetting code listings
\usepackage{callout}
\usepackage{titlesec}
\usepackage[T1]{fontenc}
\usepackage{upquote}
\lstset{upquote=true}
\fi

\usepackage{textcomp}		% For \textquotesingle as used in introduction
\usepackage{color}			% for box colors, like in TAPL.

\usepackage{amsmath}		% Begin Carthage default packages
\usepackage{makeidx}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{epsfig}
\usepackage{csquotes}
\usepackage{enumitem}

\newtheorem{thm}{Theorem}                                                       
\newtheorem{cor}[thm]{Corollary}                                                
\newtheorem{lem}[thm]{Lemma}                                                    
\newtheorem{prop}[thm]{Proposition}                                             
\newtheorem{ax}[thm]{Axiom}                                                     
\theoremstyle{definition}                                                       
\newtheorem{defn}[thm]{Definition}                                              
\newtheorem{exam}[thm]{Example}                                                 
\newtheorem{rem}[thm]{Remark} 

%
% For type setting inference rules with labels.
%
\newcommand{\inferlbl}[3]
			{\inferrule{#3}{#2}{\textsf{\footnotesize{\sc #1}}}}
\newcommand{\inferline}[3]
			{\inferrule{#3}{#2} & {\textsf{\footnotesize{\sc #1}}} \\ \\}

\newcommand{\Lagr}{\mathcal{L}}
\newcommand{\strin}{{\tt string\_in}}
\newcommand{\lang}[1]{\Lagr\{#1\}}
\newcommand{\stru}[2]{ {\tt string\_union}(#1,#2)}

\newcommand{\str}{ {\tt string} }
\newcommand{\istr}{ {\tt istring} }

\newcommand{\dconvert}[2]{ {\tt dconvert}(#1,#2) }
\newcommand{\filter}[2]{ {\tt filter}(#1,#2) }
\newcommand{\ifilter}[2]{ {\tt ifilter}(#1,#2) }

\newcommand{\reduces}{ \Rightarrow }
\newcommand{\ireduces}{ \leadsto }

\newcommand{\val}{ \ {\tt val} }
\newcommand{\ival}{ \ {\tt ival} }

\newcommand{\istrf}[1]{`#1\textrm'} %??
\newcommand{\strf}[1]{``#1"}

%
% Constrain the size of full-page diagrams and rule lists
%
%\newcommand{\pagewidth}{5in}
%\newcommand{\rulelistwidth}{3in}

%
% Names of type systems presented in paper
%
\newcommand{\lcs}{\lambda_{CS}}

\setlength{\grammarindent}{3em}

\begin{document}

TODO-nrf spell check.

TODO-nrf Include functions (app, abs)?

TODO-nrf Change icheck in eval rule to Python.

TODO-nrf Is it ok to make the proofs single-column? If not clean up overflows.

TODO-nrf Make sure failure of unicity isn't causing any problems and write down lemmas about
forms (e.g. $e \in \lang{r} \implies e = \strf{s}$ etc).

\section{Introduction}
In web applications and other settings, incorrect input sanitation often causes
security vulnerabilities. For this reason, frameworks often provide methods
for sanitizing user input. When these methods are insufficient or unavailable,
developers often write develop custom input sanitation algorithms. In both cases,
input sanitation techniques are ultimately implemented using the language's
regex library.

Formally, input sanitation is the problem of ensuring that an arbitrary string
is converted into a safe form before potentially unsafe use. For example, consider
SQL injection attacks. To prevent such attacks, we might ensure that any string
used as input to a query does not contain unescaped SQL common sequences. 

This appendix presents a type system called $\lcs$ for ensuring that input 
sanitation algorithms are implemented correctly with respect to use site 
specifications.

Unlike frameworks provided by general purpose languages such as Haskell and
Ruby, our type system provides a \emph{static} guarantee that input is always 
properly sanitized before use. We achieve this by moving portions of the regular
expression library into the type system. Therefore, type safety relies upon 
several closure and decidability results about regular languages.

Although Ur/Web achieves a similar safety guarantee, its type system is significantly
more complicated than the system defined below. We believe this simplicity 
demonstrates the power of extensibility. Instead of introducing new abstractions
based upon subtle analyses and requiring the adoption of new programming languages, 
extension designers may capture natural programming idioms directly. TODO-nrf this seems unsubstantiated or dangerously vague.

Finally, XDuce typechecks XML. Like our work, XDuce relies upon some properties of
regular expression to establish soundness and copmleteness results. Unlike
XDuce, our work is motivated by input sanitation and therefore considers arbitrary
strings (as opposed to tree-structured XML documents). Furthermore, our static
treatment of the ubiquitous ``filter" function for regular expression is novel.

An outline of this appendix follows:

\begin{itemize}
  \item In \S 2, we define the type system's static and dynamic semantics.
  \item Section 3 recalls some classical results about regular expressions and presents a type safety proof for $\lcs$ based upon these properties.
  \item Finally, \S 4 discusses our implemention of $\lcs$ as a type system extension  within the Ace programming language.
\end{itemize}

\section{Definition of $\lcs$}

The $\lcs$ language is characterized by a type of strings indexed by regular
expressions, together with operations on such strings which correspond to common
input sanitation patterns.

This section presents the grammar and semantics of $\lcs$.
The semantics are defined in terms of an internal language with at least strings and a regex filter function.
These constraints are captured by the internal term valuations ($\ival$).
The internal language does not necessarily need a regex filter function because
any dynamic conversion is easily definable using a combination of filters and safe
casting.

%
% Begin Grammar 
%
\begin{figure}
\begin{grammar}
<r> ::= $\epsilon$ | $.$ | $a$ | $r \cdot r$ | $r + r$ | $r*$ \hfill Regex ($a \in \Sigma$).

<t> ::= 			\hfill terms: 					\\
%$x$					\hfill variable 				\alt
%${\tt lambda} x:t$		\hfill abstraction 			\alt
%$t\ t$				\hfill application				\alt
$\filter{\strin[r]}{t}$ 		\hfill filter substrings			\alt
$[\strin[r]](t)$ \hfill safe conversion \alt
$\dconvert{\strin[r]}{t}$ \hfill unsafe conversion

<iv> ::= 			\hfill internal values:					\\
$\istrf{s}$				\hfill internal string \alt
${\tt ifilter}(r, \istr(s))$ \hfill internal filter

<v> ::= \hfill values: \\
$\strf{s}$ \hfill string

<T> ::=				\hfill	types:					\\
$\str$  \hfill Strings \alt
$\strin[r]$				\hfill Regular language strings		
%\alt
%$T \rightarrow T$	\hfill	Functions

<$\Gamma$> ::=	$\emptyset$	 | $\Gamma,x:T$ \hfill typing context
\end{grammar}
\caption{Syntax of $\lcs$}
\label{fig:lcsSyntax}
\end{figure}

The $\lcs$ language gives static semantics for common regular expression library
functions. In this treatment, we include concatenation and filtering.
The ${\tt filter}$ function removes all instances of a regular expression in a string,
while concatenation ($+$) concatenates two strings.

\onecolumn
\begin{figure}
\begin{center}
\begin{tabular}{c r}
%\inferline{T-VAR}{\Gamma \vdash x : T}{x:T \in \Gamma}
%
%\inferline{T-ABS}{\Gamma \vdash ({\tt \textbf{lambda}\ } x: t_2) : T_1 \rightarrow T_2}
%			{\Gamma, x:T_1 \vdash t_2:T_2}
%
%\inferline{T-APP}
%			{\Gamma \vdash t_1t_2 : T_{12}}
%			{\Gamma \vdash t_1 : T_{11}\rightarrow T_{12} \\ \Gamma \vdash t_2 : T_{11}}	
%
\inferline{T-Equiv-Top}
{\str \equiv \strin[.*]}
{ }

\inferline{T-Equiv-string\_in}
{\strin[r] \equiv \strin[r']}
{\lang{r} = \lang{r'}}

\inferline{T-Equiv-Include}
{\Gamma \vdash e:\strin[r]}
{e \in \lang{r}}

\inferline{T-Minimum}
{ \Gamma \vdash e : \strin[e] }
{\Gamma \vdash e : \str}

%\inferline{T-Union}
%  {\Gamma \vdash \stru[r'](e) : \strin[r \cup r']}
%  { \Gamma \vdash e : \strin[r] }

\inferline{T-Concat}
{\Gamma \vdash e_1 + e_2 : \strin[r_1 \cdot r_2]}
{ \Gamma \vdash e_1 : \strin[r_1] \\ \Gamma \vdash e_2 : \strin[r_2] }

\inferline{T-Convert}
{\Gamma \vdash [\strin[r']](e):\strin[r']}
{\Gamma \vdash e : \strin[r] \\ \lang{r'} \subseteq \lang{r}}

\inferline{T-Dconvert (optional)}
{\Gamma \vdash \dconvert{\strin[r']}{e}:\strin[r']}
{\Gamma \vdash e : \strin[r]}

\inferline{T-Filter}
{\Gamma \vdash \filter{\strin[r']}{t} : \strin[(r \backslash r') + \emptyset]}
{\Gamma \vdash t:\strin[r]}

\end{tabular}
\caption{Typing relation for $\lcs$}
\label{fig:lcsTyping}
\end{center}
\end{figure}

%
% Begin Operational Semantics
%
\begin{figure}
\begin{center}
\begin{tabular}{c r c r}
%\inferline{E-App1}{t_1t_2 \Rightarrow t_1't_2}{t_1 \Rightarrow t_2}
%\inferline{E-App2}{v_1t_2 \Rightarrow v_1t_2'}{t_2 \Rightarrow t_2'}
%\inferline{E-AppAbs}{({\tt lambda } x : t_{12})v_2 \Rightarrow [x / v_2]t_{12}}{T_{11}}

\inferline{E-strinval}
  {\strf{s}:\strin[r] \val}
  { }

%\inferline{E-strval}
%{\strf{s}:\str \val}
%  { }

\inferline{E-ival}
  {\istrf{e}:\istr \ival }
  { }

\inferline{E-ifilterval}
{ {\tt ifilter}(r,e) \ival }
{ e {\tt ival} }

\inferline{E-string}
{e : \str \ireduces \istrf{e}}
{ e \val }

\inferline{E-string\_in}
{e : \strin[r] \ireduces  \istrf{e}}
{ e \val }

\inferline{E-concat}
{e_1 + e_2 : \strin[r_1+r_2] \ireduces \istrf{e_1} + \istrf{e_2}}
{ }

\inferline{E-filterval}
{\filter{\strin[r']}{e} : \strin[r\backslash r' + \emptyset] \reduces {\tt rl\_filter}(r,e)}
{ e \val }
 
\inferline{E-filter}
{\filter{\strin[r']}{e} : \strin[r\backslash r' + \emptyset] \reduces  \filter{\strin[r]}{ e' }}     
{ e : \strin[r] \reduces e' }

\inferline{E-convertval}
{ [\strin[r']](e) : \strin[r'] \reduces [\strin[r']](e') }
{ e : \strin[r] \reduces e' }

\inferline{E-convert}
{ [\strin[r']](e) : \strin[r'] \ireduces \istrf{e} }
{ e \val }


\inferline{E-dconvertval (optional) \footnote{See definition ???} }
{\dconvert{\strin[r']}{e} : \strin[r'] \reduces {\dconvert{\strin[r']}{e'}}}
{e:\strin[r] \reduces e'}

\inferline{E-dconvert (optional) \footnote{See definition ???} }
{\dconvert{\strin[r']}{e} : \strin[r'] \ireduces \ifilter{r'}{\istrf{e}}}
{e \val }

\end{tabular}
\caption{Operational semantics for $\lcs$}
\label{fig:lcsEval}
\end{center}
\end{figure}
\twocolumn

\subsection{Typing}

The $\strin[r]$ type is parameterized by regular expressions; if $e:\strin[r]$,
then $e \in r$. Mapping from an arbitrary $\str$ to a $\strin[r]$ requires
defining a algorithm -- in terms of filter -- for converting a $\strin[.*]$
into a $\strin[r]$. The static semantics of the language defines the types of
operations on regular expressions in terms of well-understood properties about
regular lanugages; we recall these properties in section 3.

\subsection{Dynamics}

There are two evaluation judgements: $e:T \reduces e'$ and $e:T \ireduces i$.
The $\reduces$ relation is between $\lcs$ expressions, while the $\ireduces$
relation is a mapping from $\lcs$ expressions into internal language expressions
$i$ such that $i \ival$.

Safety of the evaluation relation depends upon an injective mapping from $\lcs$ types info
internal language types. This relation, $h$, is defined below.

\begin{defn}[Type Translation Function $h$]
  The type translation function $h : Type \rightarrow IType$ is defined as follows:
  \begin{itemize}
    \item $\forall r. h(\strin[r]) = \istr$
    \item $h(\str) = \istr$
  \end{itemize}
\end{defn}

\section{Type Safety}

The type safety proof relies upon some established results about regular languages.
The important definitions and theorems follow.

\subsection{Properties of Regular Languages}
 % copy from thesis

\subsection{Type Safety Proof}

Before presenting progress and preservation theorems, we establish some definitions
and lemmas necessary for the proofs.

\begin{defn}[Types of internal values]
The types of internal values are defined as follows:
\begin{itemize}
  \item If $e=\istrf{s}$ then $e:\istr$.
  \item If $e=\ifilter(r, \istrf{s})$ then $e:\istr$.
  \item If $e=\istrf{s_1}+\istrf{s_2}$ then $e:\istr$.
\end{itemize}
\end{defn}

Definition 2 is an additional assumption about
the internal language. To summarize, we assume an internal language containing 
strings together with operations for string concatentation and filtering. We
expect closure over strings for both operations.
Recall that $\ifilter$ is only needed for dynamic casts, which may be removed without
descreasing the expressivity or even usability of the language.

%\begin{lem}[Canonical Forms for $\lcs$]
%We identify only canonical forms necessary for the type safety proof.
%\begin{itemize}
%  \item If $e \val$ and $e:\str$ then $e = \strf{s}$.
%\end{itemize}
%\end{lem}

\begin{thm}[Preservation]
  Let $T$ be a type in $\lcs$ and $h(T)=\sigma$ the corresponding type in the internal language.
  For all terms $e$:
  \begin{itemize}
    \item If $e:T$ and $e:T \ireduces i$ then $i : \sigma$ for some $\sigma$.
    \item If $e:T$ and $e:T \reduces e'$ then $e':T$.
  \end{itemize}
\end{thm}
\begin{proof}
The proof is a straightforward induction on the derivation of the combined evaluation relation.
\begin{itemize}[label=$ $,itemsep=1ex]
  \item \textbf{E-Ival, E-Ifilterval}. Both cases hold since the terms at hand are not $\lcs$ terms.
  \item \textbf{E-Stringval, E-strval}. Both cases hold since no reduction is possible. 
  \item \textbf{E-String}. By the definition of typing for internal terms, $\istrf{e} : \istr$. It suffices to show that $h(\str) = \istr$, which follows from the definition of $h$.
  \item \textbf{E-String\_in}. By the definition of typing for internal terms, $\istrf{e} : \istr$. It suffices to show that $h(\strin[r]) = \istr$, which follows from the definition of $h$ for arbitrary $r$.
  \item \textbf{E-concat}. By the definition of typing for internal terms, $\istrf{e_1} + \istrf{e_2} : \istr$. So it suffices to show that $h(\strin[r_1+r_2]) = \istr$, which follows from the definition of $h$ for arbitrary $r_1$, $r_2$.
  \item \textbf{E-Filterval}. We have that $\filter{\strin[r']}{e}:\strin[r\backslash r' + \emptyset]$. By inversion of T-Filter, $e:\strin[r]$.
    By T-Equiv-string\_in (which is bidirectional), $e \in \lang{r}$.
    By the Regular Language Intersection Theorem, ${\tt rl\_filter}(r,e) \in \lang{r\backslash r' + \emptyset}$.
    By T-Equiv-string\_in,  $e \in \lang{r}$ and ${\tt rl\_filter}(r,e) \in \lang{r\backslash r' + \emptyset}$ implies ${\tt rl\_filter}(r,e):\strin[r\backslash r' + \emptyset]$.
  \item \textbf{E-Filter}. By inversion, $e : \strin[r'] \reduces e'$ so by the induction $e':\strin[r']$.
    Therefore, ${\tt filter}(\strin[r], e') : \strin[r \backslash r' + \emptyset]$ by T-Filter.
  \item \textbf{E-Convertval}. It suffices to show that $h(\strin[r]) = \istr$, which is true by definition.
  \item \textbf{E-Convert}. By inversion and induction, $e' : \strin[r]$. We know that $[\strin[r']](e) : \strin[r']$, so by inversion of T-Convert $\lang{r'} \subseteq \lang{r}$.
    It follows that $[\strin[r']](e') : \strin[r']$.
  \item \textbf{E-DConvert}. By inversion, $e : \strin[r'] \reduces e'$. By the induction hypothesis, $e' : \strin[r']$; therefore, by T-Dconvert, $\dconvert[\strin[r]](e):\strin[r]$.
  \item \textbf{E-DConvertval}. By the definition of typing for internal terms, $\ifilter(r,\istrf{e}) : \istr$. It suffices to show that $h(\strin[r_1+r_2]) = \istr$, which follows from the definition of $h$.
\end{itemize}
\end{proof}

\begin{thm}[Progress]
  If $e:T$ then $e:T \reduces^* e' \ireduces^* i$ where $i \ival$.
\end{thm}
\begin{proof}
By induction on the derivation of $e:T$.
\begin{itemize}[label=$ $,itemsep=1ex]
  \item \textbf{T-Equiv-Include}. Since $e \in \lang{r}$, $e = \strf{s}$ for some $s$; therefore, $e \val$ by E-Strinval. 
    We have that $e \val$ and $e : \strin[r]$, so $e \ireduces \istrf{e}$ by E-string\_in.
  \item \textbf{T-Minimum}. Result follows immediately by induction and E-string\_in.
  \item \textbf{T-Concat}. Result follows immediately by induction and E-concat.
  \item \textbf{T-Convert}. Result follows immeidately by induction, E-Convert and E-Convertval.
  \item \textbf{T-Dconvert}. Result follows immediately by induction, E-Dconvertval and E-Dconvert.
  \item \textbf{T-Filter}. Result follows immediately by induction and E-Filter.
\end{itemize}
\end{proof}

\section{Implementation in Ace}

\end{document}
