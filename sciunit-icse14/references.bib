
@article{jolivet_quantitative_2008,
	title = {The quantitative single-neuron modeling competition},
	volume = {99},
	url = {http://dx.doi.org/10.1007/s00422-008-0261-x},
	doi = {10.1007/s00422-008-0261-x},
	abstract = {Abstract  As large-scale, detailed network modeling projects are flourishing in the field of computational neuroscience, it is more
and more important to design single neuron models that not only capture qualitative features of real neurons but are quantitatively
accurate in silico representations of those. Recent years have seen substantial effort being put in the development of algorithms
for the systematic evaluation and optimization of neuron models with respect to electrophysiological data. It is however difficult
to compare these methods because of the lack of appropriate benchmark tests. Here, we describe one such effort of providing
the community with a standardized set of tests to quantify the performances of single neuron models. Our effort takes the
form of a yearly challenge similar to the ones which have been present in the machine learning community for some time. This
paper gives an account of the first two challenges which took place in 2007 and 2008 and discusses future directions. The
results of the competition suggest that best performance on data obtained from single or double electrode current or conductance
injection is achieved by models that combine features of standard leaky integrate-and-fire models with a second variable reflecting
adaptation, refractoriness, or a dynamic threshold.},
	number = {4},
	urldate = {2009-06-03},
	journal = {Biological Cybernetics},
	author = {Jolivet, Renaud and Schürmann, Felix and Berger, Thomas and Naud, Richard and Gerstner, Wulfram and Roth, Arnd},
	month = nov,
	year = {2008},
	pages = {417--426}
},

@article{gleeson_open_2012,
	title = {The Open Source Brain Initiative: enabling collaborative modelling in computational neuroscience},
	volume = {13},
	issn = {1471-2202},
	shorttitle = {The Open Source Brain Initiative},
	url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3403499/},
	doi = {10.1186/1471-2202-13-S1-O7},
	number = {Suppl 1},
	urldate = {2013-04-08},
	journal = {{BMC} Neuroscience},
	author = {Gleeson, Padraig and Piasini, Eugenio and Crook, Sharon and Cannon, Robert and Steuber, Volker and Jaeger, Dieter and Solinas, Sergio and {D'Angelo}, Egidio and Silver, R Angus},
	month = jul,
	year = {2012},
	note = {{PMID:} null
{PMCID:} {PMC3403499}},
	pages = {O7},
	file = {PubMed Central Full Text PDF:/Users/rgerkin/Library/Application Support/Zotero/Profiles/nr4ym5p2.default/zotero/storage/Z98XZC2P/Gleeson et al. - 2012 - The Open Source Brain Initiative enabling collabo.pdf:application/pdf}
},

@book{copernicus_revolutionibus_1543,
	title = {De revolutionibus orbium coelestium},
	author = {Copernicus, Nicolas},
	year = {1543}
},

@article{einstein_foundation_1916,
	title = {The Foundation of the General Theory of Relativity},
	volume = {49},
	number = {7},
	journal = {Annalen der Physik},
	author = {Einstein, Albert},
	year = {1916},
	pages = {769--822}
},

@book{galilei_siderius_1610,
	title = {Siderius Nuncius},
	author = {Galilei, Galileo},
	year = {1610}
},

@article{gleeson_neuroml:_2010,
	title = {{NeuroML:} a language for describing data driven models of neurons and networks with a high degree of biological detail},
	volume = {6},
	issn = {1553-7358},
	shorttitle = {{NeuroML}},
	doi = {10.1371/journal.pcbi.1000815},
	abstract = {Biologically detailed single neuron and network models are important for understanding how ion channels, synapses and anatomical connectivity underlie the complex electrical behavior of the brain. While neuronal simulators such as {NEURON}, {GENESIS}, {MOOSE}, {NEST}, and {PSICS} facilitate the development of these data-driven neuronal models, the specialized languages they employ are generally not interoperable, limiting model accessibility and preventing reuse of model components and cross-simulator validation. To overcome these problems we have used an Open Source software approach to develop {NeuroML}, a neuronal model description language based on {XML} (Extensible Markup Language). This enables these detailed models and their components to be defined in a standalone form, allowing them to be used across multiple simulators and archived in a standardized format. Here we describe the structure of {NeuroML} and demonstrate its scope by converting into {NeuroML} models of a number of different voltage- and ligand-gated conductances, models of electrical coupling, synaptic transmission and short-term plasticity, together with morphologically detailed models of individual neurons. We have also used these {NeuroML-based} components to develop an highly detailed cortical network model. {NeuroML-based} model descriptions were validated by demonstrating similar model behavior across five independently developed simulators. Although our results confirm that simulations run on different simulators converge, they reveal limits to model interoperability, by showing that for some models convergence only occurs at high levels of spatial and temporal discretisation, when the computational overhead is high. Our development of {NeuroML} as a common description language for biophysically detailed neuronal and network models enables interoperability across multiple simulation environments, thereby improving model transparency, accessibility and reuse in computational neuroscience.},
	language = {english},
	number = {6},
	journal = {{PLoS} computational biology},
	author = {Gleeson, Padraig and Crook, Sharon and Cannon, Robert C and Hines, Michael L and Billings, Guy O and Farinella, Matteo and Morse, Thomas M and Davison, Andrew P and Ray, Subhasis and Bhalla, Upinder S and Barnes, Simon R and Dimitrova, Yoana D and Silver, R Angus},
	month = jun,
	year = {2010},
	note = {{PMID:} 20585541},
	keywords = {{CA1} Region, Hippocampal, Cerebral Cortex, Computational Biology, Computer Simulation, Electrical Synapses, Humans, Models, Neurological, Nerve Net, Neurons, Reproducibility of Results, Software, Thalamus},
	pages = {e1000815}
},

@article{gleeson_neuroconstruct:_2007,
	title = {{neuroConstruct:} a tool for modeling networks of neurons in {3D} space},
	volume = {54},
	issn = {0896-6273},
	shorttitle = {{neuroConstruct}},
	doi = {10.1016/j.neuron.2007.03.025},
	abstract = {Conductance-based neuronal network models can help us understand how synaptic and cellular mechanisms underlie brain function. However, these complex models are difficult to develop and are inaccessible to most neuroscientists. Moreover, even the most biologically realistic network models disregard many {3D} anatomical features of the brain. Here, we describe a new software application, {neuroConstruct}, that facilitates the creation, visualization, and analysis of networks of multicompartmental neurons in {3D} space. A graphical user interface allows model generation and modification without programming. Models within {neuroConstruct} are based on new simulator-independent {NeuroML} standards, allowing automatic generation of code for {NEURON} or {GENESIS} simulators. {neuroConstruct} was tested by reproducing published models and its simulator independence verified by comparing the same model on two simulators. We show how more anatomically realistic network models can be created and their properties compared with experimental measurements by extending a published {1D} cerebellar granule cell layer model to {3D.}},
	language = {english},
	number = {2},
	journal = {Neuron},
	author = {Gleeson, Padraig and Steuber, Volker and Silver, R Angus},
	month = apr,
	year = {2007},
	note = {{PMID:} 17442244},
	keywords = {Algorithms, Cerebellar Cortex, Computer Simulation, Dentate Gyrus, Humans, Models, Neurological, Neural Conduction, Neural Networks (Computer), Neurons},
	pages = {219--235}
},

@article{gleeson_development_2011,
	title = {Development of {NeuroML} version 2.0: greater extensibility, support for abstract neuronal models and interaction with Systems Biology languages},
	volume = {12},
	copyright = {2011 Gleeson et al; licensee {BioMed} Central Ltd.},
	issn = {1471-2202},
	shorttitle = {Development of {NeuroML} version 2.0},
	url = {http://www.biomedcentral.com/1471-2202/12/S1/P29},
	doi = {10.1186/1471-2202-12-S1-P29},
	language = {english},
	number = {Suppl 1},
	urldate = {2013-08-04},
	journal = {{BMC} Neuroscience},
	author = {Gleeson, Padraig and Crook, Sharon and Silver, Angus and Cannon, Robert},
	month = jul,
	year = {2011},
	pages = {P29},
	file = {Snapshot:/Users/rgerkin/Library/Application Support/Zotero/Profiles/nr4ym5p2.default/zotero/storage/MCUPAWJ6/P29.html:text/html}
},

@article{hucka_systems_2003,
	title = {The systems biology markup language ({SBML):} a medium for representation and exchange of biochemical network models},
	volume = {19},
	issn = {1367-4803},
	shorttitle = {The systems biology markup language ({SBML)}},
	abstract = {{MOTIVATION:} Molecular biotechnology now makes it possible to build elaborate systems models, but the systems biology community needs information standards if models are to be shared, evaluated and developed cooperatively.
{RESULTS:} We summarize the Systems Biology Markup Language ({SBML)} Level 1, a free, open, {XML-based} format for representing biochemical reaction networks. {SBML} is a software-independent language for describing models common to research in many areas of computational biology, including cell signaling pathways, metabolic pathways, gene regulation, and others.
{AVAILABILITY:} The specification of {SBML} Level 1 is freely available from http://www.sbml.org/},
	language = {english},
	number = {4},
	journal = {Bioinformatics (Oxford, England)},
	author = {Hucka, M and Finney, A and Sauro, H M and Bolouri, H and Doyle, J C and Kitano, H and Arkin, A P and Bornstein, B J and Bray, D and Cornish-Bowden, A and Cuellar, A A and Dronov, S and Gilles, E D and Ginkel, M and Gor, V and Goryanin, I I and Hedley, W J and Hodgman, T C and Hofmeyr, J-H and Hunter, P J and Juty, N S and Kasberger, J L and Kremling, A and Kummer, U and Le Novère, N and Loew, L M and Lucio, D and Mendes, P and Minch, E and Mjolsness, E D and Nakayama, Y and Nelson, M R and Nielsen, P F and Sakurada, T and Schaff, J C and Shapiro, B E and Shimizu, T S and Spence, H D and Stelling, J and Takahashi, K and Tomita, M and Wagner, J and Wang, J and {{SBML} Forum}},
	month = mar,
	year = {2003},
	note = {{PMID:} 12611808},
	keywords = {Database Management Systems, Databases, Factual, Documentation, Gene Expression Regulation, Hypermedia, Information Storage and Retrieval, Metabolism, Models, Biological, Models, Chemical, Programming Languages, Software, Software Design, Terminology as Topic, Vocabulary, Controlled},
	pages = {524--531}
},

@book{kepler_astronomia_1609,
	title = {Astronomia Nova},
	author = {Kepler, Johannes},
	year = {1609}
},

@book{kepler_rudolphine_1627,
	title = {The Rudolphine Tables},
	author = {Kepler, Johannes},
	year = {1627}
},

@article{le_verrier_lettre_1859,
	title = {Lettre de M. Le Verrier à M. Faye sur la théorie de Mercure et sur le mouvement du périhélie de cette planète},
	volume = {49},
	journal = {Comptes rendus hebdomadaires des séances de {l'Académie} des sciences (Paris)},
	author = {Le Verrier, Urbain},
	year = {1859},
	pages = {379--383}
},

@article{mccabe_complexity_1976,
	title = {A complexity measure},
	volume = {2},
	number = {4},
	journal = {{IEEE} Transactions on Software Engineering},
	author = {{McCabe}, {TJ}},
	year = {1976},
	pages = {308--320}
},

@book{newton_philosophiae_1687,
	title = {Philosophiae Naturalis Principia Mathematica},
	author = {Newton, Isaac},
	year = {1687}
},

@book{ptolemy_almagest_150,
	title = {The Almagest},
	author = {Ptolemy, Cladius},
	year = {150}
},

@article{schmidt_distilling_2009,
	title = {Distilling free-form natural laws from experimental data},
	volume = {324},
	issn = {1095-9203},
	doi = {10.1126/science.1165893},
	abstract = {For centuries, scientists have attempted to identify and document analytical laws that underlie physical phenomena in nature. Despite the prevalence of computing power, the process of finding natural laws and their corresponding equations has resisted automation. A key challenge to finding analytic relations automatically is defining algorithmically what makes a correlation in observed data important and insightful. We propose a principle for the identification of nontriviality. We demonstrated this approach by automatically searching motion-tracking data captured from various physical systems, ranging from simple harmonic oscillators to chaotic double-pendula. Without any prior knowledge about physics, kinematics, or geometry, the algorithm discovered Hamiltonians, Lagrangians, and other laws of geometric and momentum conservation. The discovery rate accelerated as laws found for simpler systems were used to bootstrap explanations for more complex systems, gradually uncovering the "alphabet" used to describe those systems.},
	language = {english},
	number = {5923},
	journal = {Science (New York, {N.Y.)}},
	author = {Schmidt, Michael and Lipson, Hod},
	month = apr,
	year = {2009},
	note = {{PMID:} 19342586},
	keywords = {Algorithms, Artificial Intelligence, Mathematical Concepts, Nonlinear Dynamics, Physical Processes, Regression Analysis, Software},
	pages = {81--85}
},

@article{stein_sage:_2005,
	title = {{SAGE:} System for Algebra and Geometry Experimentation},
	volume = {39},
	number = {2},
	journal = {{ACM} {SIGSAM} Bulletin},
	author = {Stein, W and Joyner, D},
	year = {2005}
},

@article{carpenter_may_2011,
	title = {May the best analyst win},
	volume = {331},
	issn = {1095-9203},
	doi = {10.1126/science.331.6018.698},
	language = {english},
	number = {6018},
	journal = {Science (New York, {N.Y.)}},
	author = {Carpenter, Jennifer},
	month = feb,
	year = {2011},
	note = {{PMID:} 21311005},
	keywords = {Awards and Prizes, Data Interpretation, Statistical, Data Mining, Forecasting, Statistics as Topic},
	pages = {698--699}
},

@article{hopfield_what_2000,
	title = {What is a moment? {"Cortical"} sensory integration over a brief interval},
	volume = {97},
	issn = {0027-8424},
	shorttitle = {What is a moment?},
	doi = {10.1073/pnas.250483697},
	abstract = {Recognition of complex temporal sequences is a general sensory problem that requires integration of information over time. We describe a very simple "organism" that performs this task, exemplified here by recognition of spoken monosyllables. The network's computation can be understood through the application of simple but generally unexploited principles describing neural activity. The organism is a network of very simple neurons and synapses; the experiments are simulations. The network's recognition capabilities are robust to variations across speakers, simple masking noises, and large variations in system parameters. The network principles underlying recognition of short temporal sequences are applied here to speech, but similar ideas can be applied to aspects of vision, touch, and olfaction. In this article, we describe only properties of the system that could be measured if it were a real biological organism. We delay publication of the principles behind the network's operation as an intellectual challenge: the essential principles of operation can be deduced based on the experimental results presented here alone. An interactive web site (http://neuron.princeton.edu/ approximately moment) is available to allow readers to design and carry out their own experiments on the organism.},
	language = {english},
	number = {25},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	author = {Hopfield, J J and Brody, C D},
	month = dec,
	year = {2000},
	note = {{PMID:} 11095747},
	keywords = {Cerebral Cortex, Excitatory Postsynaptic Potentials, Female, Humans, Male},
	pages = {13919--13924}
},

@article{ram_git_2013,
	title = {Git can facilitate greater reproducibility and increased transparency in science},
	volume = {8},
	issn = {1751-0473},
	doi = {10.1186/1751-0473-8-7},
	abstract = {{BACKGROUND:} Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.
{FINDINGS:} Version control systems ({VCS)}, which have long been used to maintain code repositories in the software industry, are now finding new applications in science. One such open source {VCS}, Git, provides a lightweight yet robust framework that is ideal for managing the full suite of research outputs such as datasets, statistical code, figures, lab notes, and manuscripts. For individual researchers, Git provides a powerful way to track and compare versions, retrace errors, explore new approaches in a structured manner, while maintaining a full audit trail. For larger collaborative efforts, Git and Git hosting services make it possible for everyone to work asynchronously and merge their contributions at any time, all the while maintaining a complete authorship trail. In this paper I provide an overview of Git along with use-cases that highlight how this tool can be leveraged to make science more reproducible and transparent, foster new collaborations, and support novel uses.},
	language = {english},
	number = {1},
	journal = {Source code for biology and medicine},
	author = {Ram, Karthik},
	year = {2013},
	note = {{PMID:} 23448176},
	pages = {7}
},

@article{hines_modeldb:_2004,
	title = {{ModelDB:} A Database to Support Computational Neuroscience},
	volume = {17},
	issn = {0929-5313},
	shorttitle = {{ModelDB}},
	doi = {10.1023/B:JCNS.0000023869.22017.2e},
	abstract = {Wider dissemination and testing of computational models are crucial to the field of computational neuroscience. Databases are being developed to meet this need. {ModelDB} is a web-accessible database for convenient entry, retrieval, and running of published models on different platforms. This article provides a guide to entering a new model into {ModelDB.}},
	language = {english},
	number = {1},
	journal = {Journal of computational neuroscience},
	author = {Hines, Michael L and Morse, Thomas and Migliore, Michele and Carnevale, Nicholas T and Shepherd, Gordon M},
	month = aug,
	year = {2004},
	note = {{PMID:} 15218350},
	keywords = {Animals, Computational Biology, Computer Communication Networks, Databases, Factual, Humans, Neurosciences, Systems Integration},
	pages = {7--11}
},

@article{tripathy_neuroelectro:_2012,
	title = {{NeuroElectro:} A database describing the electrophysiology properties of different neuron types},
	journal = {Neuroinformatics Meeting},
	author = {Tripathy, {SJ} and Saviskaya, J and Gerkin, {RC} and Urban, {NN}},
	year = {2012}
},

@book{carnevale_neuron_2006,
	address = {Cambridge, {UK}},
	title = {The {NEURON} Book},
	publisher = {Cambridge University Press},
	author = {Carnevale, {NT} and Hines, {ML}},
	year = {2006}
},

@article{kriegeskorte_representational_2008,
	title = {Representational similarity analysis - connecting the branches of systems neuroscience},
	volume = {2},
	issn = {1662-5137},
	doi = {10.3389/neuro.06.004.2008},
	abstract = {A {FUNDAMENTAL} {CHALLENGE} {FOR} {SYSTEMS} {NEUROSCIENCE} {IS} {TO} {QUANTITATIVELY} {RELATE} {ITS} {THREE} {MAJOR} {BRANCHES} {OF} {RESEARCH:} brain-activity measurement, behavioral measurement, and computational modeling. Using measured brain-activity patterns to evaluate computational network models is complicated by the need to define the correspondency between the units of the model and the channels of the brain-activity data, e.g., single-cell recordings or voxels from functional magnetic resonance imaging ({fMRI).} Similar correspondency problems complicate relating activity patterns between different modalities of brain-activity measurement (e.g., {fMRI} and invasive or scalp electrophysiology), and between subjects and species. In order to bridge these divides, we suggest abstracting from the activity patterns themselves and computing representational dissimilarity matrices ({RDMs)}, which characterize the information carried by a given representation in a brain or model. Building on a rich psychological and mathematical literature on similarity analysis, we propose a new experimental and data-analytical framework called representational similarity analysis ({RSA)}, in which multi-channel measures of neural activity are quantitatively related to each other and to computational theory and behavior by comparing {RDMs.} We demonstrate {RSA} by relating representations of visual objects as measured with {fMRI} in early visual cortex and the fusiform face area to computational models spanning a wide range of complexities. The {RDMs} are simultaneously related via second-level application of multidimensional scaling and tested using randomization and bootstrap techniques. We discuss the broad potential of {RSA}, including novel approaches to experimental design, and argue that these ideas, which have deep roots in psychology and neuroscience, will allow the integrated quantitative analysis of data from all three branches, thus contributing to a more unified systems neuroscience.},
	language = {english},
	journal = {Frontiers in systems neuroscience},
	author = {Kriegeskorte, Nikolaus and Mur, Marieke and Bandettini, Peter},
	year = {2008},
	note = {{PMID:} 19104670},
	pages = {4}
},

@article{kriegeskorte_circular_2009,
	title = {Circular analysis in systems neuroscience: the dangers of double dipping},
	volume = {12},
	issn = {1546-1726},
	shorttitle = {Circular analysis in systems neuroscience},
	doi = {10.1038/nn.2303},
	abstract = {A neuroscientific experiment typically generates a large amount of data, of which only a small fraction is analyzed in detail and presented in a publication. However, selection among noisy measurements can render circular an otherwise appropriate analysis and invalidate results. Here we argue that systems neuroscience needs to adjust some widespread practices to avoid the circularity that can arise from selection. In particular, 'double dipping', the use of the same dataset for selection and selective analysis, will give distorted descriptive statistics and invalid statistical inference whenever the results statistics are not inherently independent of the selection criteria under the null hypothesis. To demonstrate the problem, we apply widely used analyses to noise data known to not contain the experimental effects in question. Spurious effects can appear in the context of both univariate activation analysis and multivariate pattern-information analysis. We suggest a policy for avoiding circularity.},
	language = {english},
	number = {5},
	journal = {Nature neuroscience},
	author = {Kriegeskorte, Nikolaus and Simmons, W Kyle and Bellgowan, Patrick S F and Baker, Chris I},
	month = may,
	year = {2009},
	note = {{PMID:} 19396166},
	keywords = {Animals, Artifacts, Data Collection, Data Interpretation, Statistical, Humans, Image Processing, Computer-Assisted, Magnetic Resonance Imaging, Neurosciences, Reproducibility of Results, Selection Bias, Systems Biology},
	pages = {535--540}
},

@article{button_power_2013,
	title = {Power failure: why small sample size undermines the reliability of neuroscience},
	volume = {14},
	issn = {1471-0048},
	shorttitle = {Power failure},
	doi = {10.1038/nrn3475},
	abstract = {A study with low statistical power has a reduced chance of detecting a true effect, but it is less well appreciated that low power also reduces the likelihood that a statistically significant result reflects a true effect. Here, we show that the average statistical power of studies in the neurosciences is very low. The consequences of this include overestimates of effect size and low reproducibility of results. There are also ethical dimensions to this problem, as unreliable research is inefficient and wasteful. Improving reproducibility in neuroscience is a key priority and requires attention to well-established but often ignored methodological principles.},
	language = {english},
	number = {5},
	journal = {Nature reviews. Neuroscience},
	author = {Button, Katherine S and Ioannidis, John P A and Mokrysz, Claire and Nosek, Brian A and Flint, Jonathan and Robinson, Emma S J and Munafò, Marcus R},
	month = may,
	year = {2013},
	note = {{PMID:} 23571845},
	keywords = {Humans, Neurosciences, Probability, Reproducibility of Results, Sample Size},
	pages = {365--376}
},

@article{galbraith_study_2010,
	title = {A Study of Clustered Data and Approaches to Its Analysis},
	volume = {30},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/content/30/32/10601},
	doi = {10.1523/JNEUROSCI.0362-10.2010},
	abstract = {Statistical analysis is critical in the interpretation of experimental data across the life sciences, including neuroscience. The nature of the data collected has a critical role in determining the best statistical approach to take. One particularly prevalent type of data is referred to as “clustered data.” Clustered data are characterized as data that can be classified into a number of distinct groups or “clusters” within a particular study. Clustered data arise most commonly in neuroscience when data are compiled across multiple experiments, for example in electrophysiological or optical recordings taken from synaptic terminals, with each experiment providing a distinct cluster of data. However, there are many other types of experimental design that can yield clustered data. Here, we provide a statistical model for intracluster correlation and systematically investigate a range of methods for analyzing clustered data. Our analysis reveals that it is critical to take data clustering into account and suggests appropriate statistical approaches that can be used to account for data clustering.},
	language = {english},
	number = {32},
	urldate = {2013-08-13},
	journal = {The Journal of Neuroscience},
	author = {Galbraith, Sally and Daniel, James A. and Vissel, Bryce},
	month = aug,
	year = {2010},
	note = {{PMID:} 20702692},
	pages = {10601--10608},
	file = {Snapshot:/Users/rgerkin/Library/Application Support/Zotero/Profiles/nr4ym5p2.default/zotero/storage/EFH56NAF/10601.html:text/html}
},

@book{fisher_statistical_1925,
	address = {Edinburgh},
	title = {Statistical Methods for Research Workers},
	publisher = {Oliver and Boyd},
	author = {Fisher, Ronald A},
	year = {1925}
}

@article{jinha_article_2010,
	title = {Article 50 million: an estimate of the number of scholarly articles in existence},
	volume = {23},
	shorttitle = {Article 50 million},
	doi = {10.1087/20100308},
	abstract = {How many scholarly research articles are there in existence? Journal articles first appeared in 1665, and the cumulative total is estimated here to have passed 50 million in 2009. This sum was arrived at based on published figures for global annual output for 2006, and analyses of annual output and growth rates published in the last decade.},
	number = {3},
	journal = {Learned Publishing},
	author = {Jinha, Arif E.},
	month = jul,
	year = {2010},
	pages = {258--263}
}

@article{bower_genesis_2007,
   Author="Bower, J. M.  and Beeman, D. ",
   Title="{{C}onstructing realistic neural simulations with {G}{E}{N}{E}{S}{I}{S}}",
   Journal="Methods Mol. Biol.",
   Year="2007",
   Volume="401",
   Pages="103--125"
}

@article{gewaltig_nest_2007,
  author = {Marc-Oliver Gewaltig and Markus Diesmann},
  title = {NEST (NEural Simulation Tool)},
  journal = {Scholarpedia},
  year = {2007},
  volume = {2},
  pages = {1430},
  number = {4}
}

@article{ray_moose_2008,
  author = {Subhasis Ray, and Raamesh Deshpande, and Niraj Dudani, and Upinder S Bhalla},
  title = {A general biological simulator: the multiscale object oriented simulation environment, MOOSE},
  journal = {BMC Neuroscience},
  year = {2008},
  volume = {9},
  pages = {93},
  number = {Suppl. 1}
}

@article{sumatra_davison_2012,
  author = {Davison A.P.},
  title = {Automated capture of experiment context for easier reproducibility in computational research environment},
  journal = {Computing in Science and Engineering},
  year = {2012},
  volume = {14},
  pages = {48-56},
}

