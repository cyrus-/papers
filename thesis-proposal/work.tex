\section{Work To Be Done}
\subsection{Completion and Evaluation of Ace}
The work done so far on the Ace language establishes the practicality of active typechecking and translation as a foundational language mechanism and begins to apply it to one realistic problem domain, high-performance scientific computing on GPUs and other coprocessors, by internalizing OpenCL. However, to more fully establish the practicality of this approach, it must be shown that Ace can support more sophisticated, higher-level language constructs as well, ideally from a variety of application domains. It must also be further shown that users who are not language design experts, and will not be utilizing the extension mechanism directly, can nevertheless use the language in practice. 

Thus, a portion of the resources allocated to this project will be dedicated to completing the implementation of Ace, documenting it and releasing it both to the research community and to practitioners in areas where a useful set of constructs have been developed, beginning with the members of the high-performance computing community. This will also support synergy with ongoing collaborations in our group with other problem domains, including front-end and back-end web development, security, functional programming and object-oriented programming.

With broader usage by the research community and in practice, we will be able to continue to conduct case studies and empirical evaluations examining the usability and usefulness of Ace and the active typing mechanisms it introduces. Indeed, because of the flexibility of active typing and our implementation strategy, we plan on instrumenting the Ace compiler to send data and direct feedback from willing users back to us for analysis. This will allow us to analyze questions like:
\begin{itemize}
\item How often are different constructs and mechanisms used in practice?
\item What kinds of errors appear most frequently in practice, and how long does it take users to resolve these errors?
\item How do users feel about the mechanisms, constructs and error messages that they encounter, as determined by direct feedback solicited at the time of occurrence.
\item How commonly do users utilize the active typing mechanism directly?
\end{itemize}

To our knowledge, no such detailed study of usage patterns of a programming language in the wild has been conducted previously, and we anticipate producing insights that are relevant to programming language design broadly.
\subsection{Active Type Theory}
The work on Ace is aimed at establishing a practical implementation of active typechecking and translation. However, because it uses a dynamically-typed language, Python, for the type-level language, it is not suitable for rigorous theoretical analysis, nor does it achieve safety in the strictest sense, due to high levels of dynamism exploitable in Python's object model. Moreover, it is a full language and so it does not necessarily distill the essential concepts that we wish to introduce to the research community in their simplest possible form or connect them to existing concepts in the theory of typed programming languages. For these reasons, we plan to develop a minimal type theoretic formulation, which we call $\lambda_{\text{A}}$.

\subsubsection{Type-Level Computation}

We have chosen to use the term \emph{type-level language}, rather than \emph{metalanguage} or, as it is called in the original work on active libraries, \emph{metacode} intentionally. This is because the concept of a type-level language is already well-established and includes a key feature necessary for active types -- the reification of types as compile-time entities that can be manipulated programmatically. We believe that this connection between type-level computation and active types will provide new insights into each mechanism individually, and provide a clean theoretical basis for active typechecking and translation as an extension to type-level computation.

\subsubsection{Active Types and Wadler's Expression Problem}
Another key insight is that in monolithic programming languages, the fixed set of base types can be written as an algebraic datatype. Indeed, in functional implementations of typecheckers, this is precisely what is done, for example for G\"{o}del's \textbf{T}:

\begin{verbatim}
    datatype Type = Arrow of Type * Type 
                  | Nat
\end{verbatim}

If we wish to allow users to introduce new base types and type families, it can then be seen that we face a variant of the expression problem, so named by Wadler \cite{wadler1998expression}. That is, we wish to add new constructors of kind \verb|Type|, but this conventional formulation of datatypes does not allow us to do so. There are competing approaches that aim to solve this problem. The most common is to use object-oriented inheritance, where subtypes of \verb|Type| represent new type families. This is the approach taken in Ace. The functional programming approach is to instead use \emph{open data types} \cite{conf/ppdp/LohH06}. We will thus aim to further explore this approach, drawing a clear connection between active types, the expression problem and type-level open data types.

\subsubsection{Rigorous Safety Proofs}
A benefit of a simple core theory for active typing is that it will allow us to formally state and prove key safety theorems, formalizing the somewhat informal notions described in Section 3.3. Based on early sketches of a theory that we have discussed, we have implemented some run-time checks into Ace that ensure some of these properties for compiled programs based on a notion borrowed from the area of verified compilation called \emph{type-directed compilation} \cite{tarditi+:til-OLD}. We would like to be able to ensure these properties for all possible programs, and a type theory will allow us to demonstrate the machinery needed to do this in a rigorous manner.

\subsubsection{Implementation With a Dependently-Typed Language}
Finally, we would like to implement a functional version of active type-checking and translation, both as a counterpoint to Ace and as a useful tool for theoretical researchers. We plan on doing so as an extension to the Coq theorem prover, which contains a dependently-typed functional programming language at its core, and is implemented in Ocaml. This will allow us to understand the challenges and opportunities of using a dependently-typed functional language at the core of an extensible programming system.
 
\subsection{Active Code Prediction}
\subsubsection{Structured, Statistical Code Prediction}

Programming languages are formal systems with rich syntactic and semantic structure. They are
also human systems, in that they are used extensively by people in patterned ways to express their
intent. Many tools are designed to help people write code more efficiently by predicting
the source code that a developer intends. For example, code completion systems for editors like Eclipse for Java display pop-up menus containing the members of the class of the variable being manipulated by the developer.

Typical code completion systems use only this sort of semantic
information about the language and the libraries being used, and do not incorporate data about how developers have written programs
in the past. Recent work by Hindle et al.~\cite{Hindle:2012:NS:2337223.2337322} demonstrated, however, that source code could be successfully predicted statistically
using a simple $n$-gram model that used a tokenized, rather than structural, representation of source code, trained on existing codebases.

Our first aim is to unite the structured and statistical approaches to source code prediction. That is, rather than using a tokenized representation of source code, we would like to do statistical prediction on a more natural representation of source code: the typed syntax tree.  We can then condition our predictions using semantic information, specifically:
\begin{itemize}
\item the \emph{type}, denoted $\tau$, of the expression being predicted (e.g. \verb|int| or \verb|Color|)
\item the \emph{syntactic context}, denoted $\sigma$, in which the expression occurs (e.g. whether the expression is an argument of a function call, the guard of an \verb|if| statement, etc.)
\item the \emph{program context}, denoted $\Gamma$, in which the expression occurs (i.e. the set of variables paired with their types that are in scope at the location that the expression occurs.)
\end{itemize}

For example, if a user has entered the code \texttt{Planet destination = }, where \verb|Planet| is an enumeration containing \verb|Mercury|, \verb|Venus|, \verb|Earth|, etc. (but not \verb|Pluto|, of course), then we have that the expected type at the cursor is \verb|Planet|, the syntactic context is \emph{assignment}, and given a program context, our prediction space should only assign non-zero probabilities to:
\begin{itemize}
\item literal members of the \verb|Planet| enumeration (e.g. \verb|Planet.EARTH|)
\item variables and fields of type \verb|Planet| available from the program context
\item calls to methods available from the program context that have return type \texttt{Planet}\footnote{We can consider  operators like $+$ and $[]$ as methods of the built-in types in Java.}
\end{itemize}
To assign a particular probability to an expression, denoted $e$, we first determine how likely it is that the expression is of each of these three \emph{syntactic forms}, where syntactic forms are denoted $\phi$. For each form, we can then assign probabilities to particular expressions of that form according to some form-specific conditional distribution. This model can be understood as a graphical model, as shown in Figure \ref{graphicalmodel}, where the syntactic form is a latent variable. The conditional distributions for both the syntactic form and expression are learned using data gathered from analyses of prior code corpuses (smoothed using a suitable method in cases where enough information is not available).
\begin{figure}
    \begin{displaymath}
    \xymatrix{
      *+[F]{\color{ForestGreen}\txt{Type ($\tau$)}} \ar[dr] \ar[drr] & & \\
      & *+[F]{\color{black} \txt{Syntactic\\Form ($\phi$)}} \ar[r] & *+[F]{\color{cyan}\txt{Expression ($e$)}}  \\
      *+[F]{\color{ForestGreen}\txt{Syntactic\\Context ($\sigma$)}} \ar[ur] \ar[urr] & & *+[F]{\color{ForestGreen}\txt{Program\\Context ($\Gamma$)}} \ar[u]  
    }
    \end{displaymath}
\caption{\small A graphical model representing our approach. Green variables are always observed (we do not assign marginal distributions to them.) The syntactic form, $\phi$, is a latent variable, and the expression, $e$, is unknown. Note that the syntactic form is a function of the expression. \label{graphicalmodel}}
\end{figure}

\subsubsection{Active Code Prediction}
Given a system for predicting expressions in the context of a type syntax tree, we can then naturally ask: what about specialized domain knowledge that cannot be readily extracted from prior code analysis? For example, consider a type representing strings in a particular language, such as English. Constructors of the \verb|EnglishString| type should be biased to accept literals that have high likelihoods according to some natural language model, but we do not wish to encode all possible natural language models in the core of our prediction system. We can instead take an active types approach by allowing users to equip a type, such as \verb|EnglishString|, with a function, $f_{\text{prob}}$, that takes on the job of predicting the probabilities of only expressions of that type. That is, given a reified representation of $\sigma$, $\Gamma$ and $\phi$, it should be able to produce $P(e | \tau, \phi, \sigma, \Gamma)$. We can then use this prediction directly as if it had been produced by a method described above.

\subsubsection{Foundations, Implementation and Analysis}
We propose developing the theoretical foundations of this idea, in terms of probability theory and type theory, equipping it with a notion of active code prediction as described above, and implementing this atop a real language, likely Java. We have sketched and prototyped a small version of this as an Eclipse extension in the context of a prior course project. We will then evaluate the accuracy of these models, develop use cases as in the related work on active code completion described in Section \ref{graphite}, and analyze the usability and usefulness of this prediction system in applied contexts. In particular, we are interested in uses within code editors to predict expressions and portions of expressions, as well as uses within programming systems for disabled and paralyzed individuals, who need predictive text entry to be able to communicate at a reasonable pace. The information theoretic foundations for this latter application, in the context of brain-computer interfaces, have been developed as prior work by one of the investigators on this proposal \cite{journals/ijhci/OmarAJBMMMC11}.

\subsection{Syntax and Visual Representation}
Thus far, we have been discussing active types within the context of languages with a fixed syntax. However, in many specialized domains, a specialized syntax or visual representation for novel constructs may be appropriate. There are several approaches that we can take to include extensible syntax support in an actively-typed programming system. We have not settled on any one of these, so our proposed research will include a rigorous examination of the pros and cons of each approach.

\subsubsection{Extensible Parsing} 
Extensible parsers have been well-studied in the literature (e.g. \cite{journals/entcs/BrabrandSV03}), and such systems could be integrated with an actively-typed language without conflict with one caveat: each new syntactic form needs to have a dispatch protocol associated with it, to assign control over its semantics to one of its subexpressions. Such a mechanism will be one avenue we will evaluate for suitability.

\subsubsection{Flexible Reinterpretation}
An approach that we have prototyped, but not extensively utilized, in Ace is to allow active types to directly observe the syntax trees of subexpressions, rather than simply their types as we have described above. This allows a highly contextualized reinterpretation of a syntax tree, similar to capabilities found in macro systems (although without a direct rewriting component.) We will further explore this approach, particularly as we begin implementing abstractions that may not naturally fit within Python's existing syntactic forms in an intuitive way.

\subsubsection{Delimited Parsing}
A related alternative approach would be to partially parse a file, leaving delimited regions either unparsed or only tokenized and dispatching to an active type to do the actual parsing. This would give more flexibility to the active type, but also a greater responsibility to fully parse and give semantics to the provided source code. Nevertheless, this may be appropriate in certain cases where a highly-specialized local syntax is desirable for convenience (and flexible reinterpretation or active code completion at edit-time does not suffice.)

\subsubsection{Actively-Typed Structured Editors}
Projects such as Citrus \cite{Ko05} and Barista \cite{Ko06} are analogs of language frameworks for structured editors -- editors where source code elements are represented directly as a tree in a visual or semi-visual form, rather than written as a string as in conventional languages. These tools demonstrate that modular construction of such editors may be possible. An actively-typed structured editor would instead allow an active type to directly control the visual representation and interaction behaviors associated with expressions of that type. This is the most direct analog of active types in this domain, but requires a somewhat radical shift in program representation. It is unlikely that this can be integrated easily into existing languages and systems, as we have largely done in our other work. Thus, we will develop a separate prototype of this approach, and believe that the long-term evolution of actively-typed programming systems will be toward such a representation.
