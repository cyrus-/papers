% !TEX root = omar-thesis-proposal.tex
\section{Active Types}\label{contributions}
The language-integrated extension mechanisms that we will introduce in this thesis are designed to be highly {expressive}, permitting library-based implementations of features comparable to the built-in features found in modern programming systems, but without the kinds of {safety} problems that have been an issue in previous mechanisms, as described above. We also aim to maintain the ability to understand and reason locally about code. %This is accomplished by organizing extension logic around types and scoping it to or around expressions of the type it is associated with, rather than applying it globally or within contiguous blocks as in previous mechanisms. 

To motivate the approach we will take in achieving these goals, let us return to our example of regular expressions. Observe that every feature described in Section \ref{regex} relates specifically to how terms  classified by a single user-defined type\footnote{We will generalize this to cover several different types within an indexed type family in later sections.} should behave. In fact, nearly all the features relate to the type representing regular expression patterns (let us call it \verb|Pattern|\footnote{We should note at the outset that to fully prevent conflicts between libraries, naming conflicts must also be avoided. Suitable namespacing mechanisms (e.g. URL-based schemes, as Java uses) are already well-developed in practice  and will be assumed.}). Feature 1 calls for specialized syntax for the introductory form of this type. Features 2a and 2b relate to its static semantics. Feature 3 relate to its elaboration semantics. Feature 4 is about its edit-time behavior. The only remaining feature, 2c, relates to the static semantics of a different type family, \verb|StringIn[r]| which classifies strings known to be in the language of the regular expression, \verb|r|. It is exclusively when editing or compiling expressions of the associated type that the logic in Section \ref{regex}  needs to be considered. 

Indeed, this is not a property unique to our chosen example, but a very commonly-seen pattern in programming language design. Types are already known to be natural entities around which the semantics of a programming language or logic can be organized. In two major textbooks about programming languages, TAPL \cite{tapl} and PFPL \cite{pfpl}, most chapters describe the semantics and metatheory of a few new types and their associated primitive operations without reference to other types. The composition of the types and associated operators from different chapters into languages is a metatheoretic (in other words, language-external) notion. For example, in PFPL, the notation $\mathcal{L}$\{$\rightarrow$ \verb|nat| \verb|dyn|\} represents a language composed of the arrow ($\rightarrow$), \verb|nat| and \verb|dyn| types and their associated operators. These are defined in separate chapters, and it is  left unstated that the semantics and metatheory developed separately will compose without trouble (justified by the fact that, upon careful examination, it is indeed the case that almost any combination of types defined separately in PFPL can be straightforwardly combined to form a language). 

This type-oriented organization suggests a principled language-integrated alternative to the mechanisms described in Section \ref{alibs} that preserves much of their expressiveness but eliminates the possibility of conflict and makes it easier to reason locally about a piece of code: associating extension logic to a single type (or type family) as it is defined and scoping it only around expressions classified by that type (or by a type in that type family).  We call types with such logic associated with them \emph{active types} and systems that support them \emph{actively-typed programming systems}. By constraining the extension logic itself by various means we will show that the system as a whole can maintain many important safety and non-interference properties that have not previously been achieved.

\subsection{Proposed Contributions}
This thesis will introduce several language-integrated extensibility mechanisms, each based on active types, that give providers control over a different aspect of the system from within libraries (that is, in a decentralized manner). In each case, we will show that the system remains fundamentally safe and that extensions cannot interfere with one another. We will also discuss factors related to extension correctness. To justify the  expressiveness of each approach, we will give a number of examples of non-trivial features that are ,or would need to be, built into other systems, but that can be expressed within libraries using our mechanisms. We will also conduct empirical studies and case studies that demonstrate the scope and applicability of our approaches in practice.

We begin in Sec. \ref{aparsing} by considering \textbf{syntax}. The availability of specialized syntax can bring numerous cognitive benefits \cite{green1996usability}, and discourage the use of problematic techniques like using strings to represent structured data \cite{Bravenboer:2007:PIA:1289971.1289975}. But allowing library providers to add arbitrary new syntactic forms to a language's grammar can lead to interference issues, as described above. We observe that many syntax extensions are motivated by the desire to add alternative syntax for the introductory forms (i.e. \emph{literal forms}) for a particular type. For example, regular expression pattern literals as described in Sec. \ref{regex} are an introductory form for the \verb|Pattern| type.  In the mechanism we introduce, syntax extensions are associated directly with a type and active only where an expression of that type is expected (shifting part of the burden of parsing into the typechecker). This avoids extension interference problems because the base grammar of the language is never extended directly. We call such an extension a \emph{type-specific language (TSL)} and introduce TSLs in the context of a new language, Wyvern. We begin by specifying a layout-sensitive base syntax for Wyvern (like Python's and Haskell's) containing a form of \emph{syntactic forward reference} that makes entering multi-line expressions simpler, and when used with TSLs, sidesteps interference issues that can arise between the TSL's syntax and the enclosing language's syntax. In addition to this novel syntactic form, we also show how typical literal forms (e.g. string literals, array literals, etc.) can be repurposed to operate more generically as TSLs. We then develop a formal semantics, basing it on work on bidirectional type systems, and introduce a novel mechanism that statically prevents unsafe variable capture. Finally, we conduct a corpus analysis to examine this technique's applicability, finding that a substantial fraction of string literals in existing code could be replaced by TSL literals. In addition to being more natural, this shifts parsing errors to compile-time, improves performance and can help prevent security vulnerabilities.

Wyvern has an extensible syntax but a fixed static and dynamic semantics. While the general-purpose abstraction mechanisms we have included in Wyvern -- structurally-typed objects and inductive datatypes -- are powerful, and implementation techniques for these have been well-studied, there remain situations where providers may wish to extend the \textbf{semantics} of a language directly by introducing new primitive types and operators and specifying how they are implemented. Examples of type system extensions and new implementation strategies that require changing how operators are elaborated into terms in an intermediate language abound in the research literature. For example, to implement the features in Sec. \ref{regex}, new logic must be added to the type system to statically track information related to backreferences (feature 2b, see \cite{spishak2012type}) or to execute a decision procedure for language inclusion when determining subtyping relationships (feature 2c, see \cite{fulton-thesis}). New logic must also be added to the elaborator to implement feature 3. Having control over elaboration is particularly important in areas like parallel programming, where performance is of particular concern. To support these sorts of use cases, we next consider mechanisms for safe semantic extensions, while allowing the syntax to remain fixed. We begin in Sec. \ref{att} with a type theoretic treatment, by specifying an ``actively-typed'' lambda calculus called @$\lambda$. We prove key safety and non-interference theorems and examine the connections between active types and several prior notions, including type-level computation, type abstraction and typed compilation. We then go on in Sec. \ref{ace} to demonstrate the expressiveness of this mechanism by designing and implementing a full-scale language, Ace. We show how it relates to, and extends, the core calculus and implement a number of powerful primitives from existing languages as libraries. We give examples from a variety of paradigms, including low-level parallel programming, functional programming,  object-oriented programming and domain-specific languages to demonstrate the expressive power of this approach.

Finally, in Sec. \ref{acc}, we will show how \textbf{editor services} that can help developers write complex expressions can be introduced from within active libraries, by a technique we call \emph{active code completion}. Providers associate
domain-specific user interfaces, called \emph{palettes}, with types. Clients discover and invoke palettes from the code completion menu at edit-time, populated according to the expected type at the cursor (a protocol similar to the one we use for syntax extensions in Wyvern). When the interaction between the client and the palette is complete, the palette generates a term of the type it is associated with based on the information received from the user. Using several empirical
methods, we survey\- the expressive power of this approach and describe the design and safety constraints governing
the mechanism. Based on these initial studies, we then develop an active code completion system for Java called Graphite. Using Graphite,
we implement a palette for working with regular expressions in order to conduct a small study that provides evidence for the usefulness of this approach, and of contextually-invoked tools generally.

Taken together, these mechanisms demonstrate that actively-typed mechanisms can be introduced throughout a programming system to allow users to extend both its compile-time and edit-time semantics from within libraries, without  weakening the metatheoretic guarantees that the system provides. They also further demonstrate that types are a natural organizational unit for defining programming system features, because a great variety of features can be expressed in an actively-typed manner, and doing so can make it easier to guarantee that the features will be safely composable in any combination. In this thesis, each mechanism is  implemented within a different programming system, showing that actively-typed mechanisms are relevant across traditional paradigms, including functional languages (@$\lambda$), class-based OO languages (Graphite), structurally-typed languages (Wyvern) and scripting languages (Ace). In the future, we anticipate that mechanisms like those in this thesis will be brought together to form a single highly-extensible system with a minimal, well-specified core, where nearly every feature is distributed within a library. 

%
%This suggests that a natural place where these features can be defined is in the library containing the declaration of \verb|Pattern| itself, rather than in the language and tool implementations. An \emph{actively-typed} definition of \verb|Pattern| would thus be equipped with	 functions that described how the parser (item 1), type checker (item 2), translator (item 3) and editor (item 4) should operate when working with expressions of type \verb|Pattern|. We can abstractly denote this declaration, as it would exist within a user-defined library, as follows:
%\begin{equation*}
%{\sf type}~Pattern[f_{\text{editor}}]\{
%\textbf{z}[f_{\text{resolve-z}}, f_{\text{compile-z}}], 
%\textbf{s}[f_{\text{resolve-s}}, f_{\text{compile-s}}], 
%\textbf{natrec}[f_{\text{resolve-rec}}, f_{\text{compile-rec}}]\}
%\end{equation*}
%
%When type checking an expression like $\nats{\nats{\natz}}$, the type checker delegates to the user-provided type-level function $f_{\text{resolve-s}}$. This function would be tasked with assigning a type to expression as a whole, given information including the \emph{types} (but not necessarily the full syntax trees) of all its subexpressions, or if a type cannot be assigned, producing a specific error message. Similarly, the compiler calls the $f_{\text{compile-s}}$ function to determine a representation in the target language for the expression, checking to ensure that it is well-formed and type-correct with respect to the target type system. Finally, elements of the editor may call into the $f_{\text{editor}}$ function (or one of several such functions, more generally) to control behaviors like code completion and code prediction when an expression of type $\nat$ is being entered. 
%
%Note that these functions are \emph{not} to be conflated with methods or run-time functions -- they are functions written in a type-level language that are called at compile-time and edit-time to define the basic behaviors associated with the type that they are associated with.
%
%\subsection{Characteristics of an Actively-Typed Programming System}
%An actively-typed programming system can be characterized by its choice of type-level language, source grammar, target language and dispatch protocols.
%
%\paragraph{Type-Level Language} The type-level language is the language within which the type definitions and the functions that define their behaviors are defined. This language must be constrained so that different definitions do not interfere with one another and so that desirable safety properties for the system as a whole are maintained, as we discuss below.
%
%\paragraph{Source Language} The source language is the language with which run-time behavior is defined. In our example above, terms like $\nats{\nats{\natz}}$ are part of the source language. In the purest case, the source language is simply a grammar; its semantics are given entirely by active type specifications.
%
%\paragraph{Dispatch Protocol} For each syntactic form in the source language, there is a dispatch protocol that determines which type is delegated responsibility over it, and which specific function(s) are called for each behavior the system supports. This fixed protocol makes it possible for users to predict the meaning of a construct using information local to the term, a key differentiator of this approach compared to term-rewriting systems where there can be action at a distance.
%
%\paragraph{Target Language} The target language is the language that the front-end compilation phase of the system targets. The limitations and constraints imposed by the target language are final, because all constructs ultimately translate into terms in the target language. In other words, active type specifications can only add additional invariants to the language; they cannot violate invariants imposed by the target language.

%\subsection{Research Challenges}
%The example of natural numbers given above is relatively simple, and the solution we outline remains abstract. A key challenge is then to demonstrate that this approach is able to express the behaviors of more sophisticated language constructs that span diverse problem domains, and be implemented in the context of a realistic collection of tools. The resulting system should be usable by developers who lack the expertise needed to define new language constructs themselves.
%
%Simultaneously, we must also demonstrate that this model is well-motivated theoretically, place it within the broader context of the theory of typed programming languages, and demonstrate that it is possible for desirable system safety properties to be maintained. In particular, we are interested in properties like:
%
%\begin{itemize}
%\item Correctness of active type specifications, so that users of a library need not be forced to debug errors arising within the specifications themselves.
%\item Correctness of translations, so that the results of translation are guaranteed to be well-typed and consistent with respect to the target language.
%\item Termination of active type specifications, so that evaluation of the type-level functions cannot cause the compiler or editor to hang.
%\item Composability of active type specifications, so that the behaviors defined by one type cannot interfere with those defined by another, no matter the order in which they are imported. This property is essential if we wish to place these specifications within normal libraries.
%\end{itemize}


