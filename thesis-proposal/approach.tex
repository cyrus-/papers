% !TEX root = omar-thesis-proposal.tex
\section{Active Types}\label{contributions}
The language-integrated extension mechanisms that we will introduce in this thesis are designed to be highly {expressive}, permitting library-based implementations of features that compare to and go beyond the features found in modern programming systems, including those implemented via mechanisms like those described above. However, we seek to avoid the associated {safety} issues and  maintain the ability to understand and reason about code by a conventional type-based discipline. %This is accomplished by organizing extension logic around types and scoping it to or around expressions of the type it is associated with, rather than applying it globally or within an explicitly delimited scope as in previous mechanisms. 

To motivate our approach, let us return to our example of regular expressions. We observe that every feature described in Sec. \ref{regex} relates specifically to how terms  classified by a single user-defined type (or indexed family of types) should behave. In fact, nearly all the features relate to types representing regular expression patterns. Feature 1 calls for specialized syntax for the introductory form. Features 2a and 2b relates to how operations on patterns should be typechecked. Feature 3 discuss services only relevant when editing a pattern. Feature 2c relates to the semantics of a related  family of types: strings known to be in the language of a statically-known regular expression. %It is exclusively when editing or compiling expressions of the associated type that the logic in Sec. \ref{regex}  needs to be considered. 

Indeed, this is a common pattern. The semantics of programming languages (and logics) have long been organized around their types (equivalently, their propositions). %One of the principal tasks of the logical analysis of a given proposition is to find out the method of verification for that proposition.
For example, Carnap in his 1935 book \emph{Philosophy and Logical Syntax} stated \cite{carnap1935philosophy}:
\begin{quote}
One of the principal tasks of the logical analysis of a given proposition is to find out the method of verification for that proposition.
\end{quote}
In two major textbooks about programming languages, \emph{TAPL} \cite{tapl} and \emph{PFPL} \cite{pfpl}, most chapters describe the syntax, semantics and metatheory of a new type constructor and its associated  operators (collectively, a \emph{fragment}) in isolation. Combining the fragments from different chapters into complete languages is, however, a language-external (that is, metamathematical) operation. In \emph{PFPL}, for example,  the notation $\mathcal{L}$\{$\rightarrow$ \verb|nat| \verb|dyn|\} represents a language that combines the arrow ($\rightarrow$), \verb|nat| and \verb|dyn| type constructors and their associated operators. Each of these are defined in separate chapters, and it is generally left unstated that the semantics and metatheory developed separately can be combined conservatively, i.e. with all the fundamental metatheory left intact, a notion we will refine later. This is justified by a sense that the rules each chapter seem ``well-behaved'' in that they  avoid referring excessively to fragments in other chapters, preserving their autonomy.%This organization has long been employed in the study of logic as well. 

A fragment that violates the autonomy of another fragment could easily be defined. For example,  introducing a new value of a type defined elsewhere would render invalid any conclusions arrived at by induction over values of that type, clearly bad behavior. If we can somehow formalize this notion of a ``fragment'' and ``autonomy'' and internalize it into a language itself, rather than leaving it as a ``design pattern'' that only informally guides the work of a central language (or textbook) designer, we might achieve  a safely extensible language, i.e. one where separately defined embeddings of  fragments as libraries can be safely combined. Doing so without limiting expressiveness is precisely our thesis. We adopt the practice of identifying a fragment with a single type or type constructor, and call a type that defines new syntax, semantics or editor services an \emph{active type}. We call programming systems organized around these \emph{actively typed programming systems}.


%As we will show, taking a type-oriented point-of-view provides a means to satisfy this principle.
%Making this precise and showing how the language can preclude poorly-behaved fragments from causing problems, while retaining the ability to define interesting fragments, is the focus of this thesis.

%But enforce a golden rule: that each builder of a logic respects every other's autonomy. % That is our goal in this thesis. %By constraining the extension logic itself by various means we will show that the system as a whole can also maintain many other important safety and non-interference properties that have not previously been achieved. 
%We call types with such logic associated with them \emph{active types} and systems that support them \emph{actively-typed programming systems}. 

\subsection{Proposed Contributions}
This thesis will introduce several language-integrated extensibility mechanisms, each organized around active types in this way and following this intuition, that decentralizes control over a different feature of the system. In each case, we will show that the system retains important metatheory and that extensions cannot violate one another's autonomy, in ways that we will make more precise as we go on. We collectively call these ``safety properties''. We will also discuss various points related to extension correctness (as distinct from safety, which will be guaranteed even if an incorrect extension is imported). To justify the  expressiveness of each approach, we will give a number of examples of non-trivial features that are, or would need to be, built into conventional systems, but that can be expressed within libraries using these mechanisms. To help us gather a broad, unbiased collection of examples and demonstrate the scope and applicability of our approaches in practice, we will also conduct small empirical studies when appropriate (though the primary contributions of this work are technical).

We begin in Sec. \ref{aparsing} by considering \textbf{syntax}. The availability of specialized syntax can bring numerous cognitive benefits \cite{green1996usability}, and discourage the use of problematic techniques like using strings to represent structured data \cite{Bravenboer:2007:PIA:1289971.1289975}. But allowing library providers to add arbitrary new syntactic forms to a language's grammar can lead to ambiguities, as described above. We observe that many syntax extensions are motivated by the desire to add alternative  introductory forms (a.k.a. \emph{literal forms}) for a particular type. For example, regular expression pattern literals as described in Sec. \ref{regex} are an introductory form for the \verb|Pattern| type.  In the mechanism we introduce, literal syntax is associated directly with a type and can be used only where an expression of that type is expected (shifting part of the burden of parsing into the typechecker). This avoids the problem of an extension interfering with the base language or another extension  because these grammars are never modified directly. We begin by introducing these \emph{type-specific languages (TSLs)} in the context of a simplified variant of a language we are developing called Wyvern. Next, we show how interference issues in the other direction -- the base language interfering with  the TSL syntax -- can be avoided by using a novel layout-delimited literal form. We then develop a formal semantics, basing it on work in bidirectional type systems and elaboration semantics. Using this semantics, we introduce a novel mechanism that statically prevents another form of interference: unsafe variable capture and shadowing by user-defined elaborations (providing a form of \emph{hygiene}). Finally, we conduct a corpus analysis to examine this technique's expressiveness, finding that a substantial fraction of string literals in existing code could be replaced by TSL literals.

Wyvern has an extensible syntax but a fixed ``general-purpose'' static and dynamic semantics. The  constructs we have included in Wyvern are powerful, and implementation techniques for these are well-developed, but there remain situations where providers may wish to extend the {semantics} of a language directly, by introducing new type constructors and operators. Examples of language extensions that require this level of control abound in the research literature. For example, to implement the features in Sec. \ref{regex}, new logic must be added to the type system to statically track information related to backreferences (feature 2b, see \cite{spishak2012type}) or to execute a decision procedure for language inclusion when determining whether a coercion requires a run-time check (feature 2c, see \cite{fulton-thesis}\todo{cite xduce}). We discuss more examples from the literature where researchers had to turn to language-external approaches in Sec. \ref{att}. To support these more advanced use cases in a decentralized manner, we next develop mechanisms for implementing \textbf{type system} extensions. 

We begin in Sec. \ref{atlam} with a type theoretic treatment, specifying an ``actively typed'' lambda calculus called @$\lambda$. We discuss how this calculus allows providers to go from a weak encoding of an abstraction (one that does not preserve static reasoning principles, in a manner that we will make precise) to an isomorphic embedding by introducing directly the necessary static logic. Going further, the calculus guarantees that a strong embedding cannot be weakened once established by enforcing abstraction barriers between extensions using a form of type abstraction. We call isomorphic embeddings constructed in this way \emph{active embeddings}. By beginning from first principles, we are able to cleanly state and prove the key metatheoretic principles, define the criteria for a strong embedding and give a conservativity theorem. We also discover connections with several prior notions, including type-level computation, typed compilation and abstract types. 

We then go on in Sec. \ref{ace} to demonstrate the expressiveness of this mechanism by designing and implementing a full-scale actively typed language, Ace. Interestingly, Ace is itself bootstrapped as a library within an existing language that has a rather impoverished type system, Python. We discuss how we accomplish this, relate Ace to the core calculus, and implement a number of powerful primitives from existing languages as libraries. These examples cover a variety of paradigms, including low-level parallel and concurrent languages, functional languages, object-oriented languages and specialized domains, like the regular expression types discussed in the introduction. We also introduce a novel extensible form of staged compilation where the tags associated with Python values can propagate into Ace functions as static types according to an extensible protocol, and show how this is particularly well-suited to contemporary scientific workflows.

Finally, in Sec. \ref{acc}, we show an example of a novel class of \textbf{editor services} that can be implemented within libraries, introducing a technique we call \emph{active code completion}. Code completion is a common editor service (found in editors like Vim and Emacs as well as in the editor components of development environments like Eclipse) that helps programmers avoid typos, minimize keystrokes and explore APIs quickly by providing a menu of code snippets based on the surrounding code context. This is a useful but rather general-purpose user interface. There are a variety of tools in the literature and online that help programmers generate code snippets using alternative, more specialized user interfaces. For example, a regular expression workbench helps programmers write regular expression patterns more easily (e.g. \cite{IntelliJRegexp,_txt2re:_????}). A color chooser can be considered a specialized user interface for creating an expression of type \verb|Color|. 
Active code completion brings these kinds of type-specific code generation interfaces, which we call \emph{palettes}, into the editor, and allows library providers to associate them with their own types. Clients discover and invoke palettes from the standard code completion menu, populated according to the expected type at the cursor (a protocol similar to the one we use for syntax extensions in Wyvern, and one that requires a type-aware editor). When the interaction between the client and the palette is complete, the palette generates a term of the type it is associated with based on the information received from the user (the reader may skip ahead to Fig. \ref{colorpalette} in Sec. \ref{acc} for an example). Using several empirical
methods, including a large developer survey, we examine the expressive power of this approach and develop design criteria. Based on these criteria, we then develop an active code completion system called Graphite. Palettes are implemented as webpages, avoiding excessive reliance on any particular editor implementation (our initial implementation is as a very small Eclipse extension). Using Graphite,
we implement a palette for working with regular expressions (as well as some other simpler examples) and conduct a small study that demonstrates the usefulness of type-specific editor services as compared to similar externally-available tools.

Taken together, this work aims to demonstrate that actively typed mechanisms can be introduced into many different kinds of programming systems to increase expressiveness without  weakening safety guarantees. We approach the problem both by building up from first principles with type-theoretic models, and by developing practical designs and providing realistic contemporary examples.  
%It is precisely our type-oriented approach that makes it possible to guarantee that features introduced by extension providers will be safely composable in any combination. 
In the future, we anticipate that this work will provide foundations for an actively typed programming system organized around a minimal, well-specified and formally verified core, where nearly every feature is specified, implemented and verified in a decentralized manner. We conclude with a brief historic discussion in Sec. \ref{conclusion}.

%
%This suggests that a natural place where these features can be defined is in the library containing the declaration of \verb|Pattern| itself, rather than in the language and tool implementations. An \emph{actively-typed} definition of \verb|Pattern| would thus be equipped with	 functions that described how the parser (item 1), type checker (item 2), translator (item 3) and editor (item 4) should operate when working with expressions of type \verb|Pattern|. We can abstractly denote this declaration, as it would exist within a user-defined library, as follows:
%\begin{equation*}
%{\sf type}~Pattern[f_{\text{editor}}]\{
%\textbf{z}[f_{\text{resolve-z}}, f_{\text{compile-z}}], 
%\textbf{s}[f_{\text{resolve-s}}, f_{\text{compile-s}}], 
%\textbf{natrec}[f_{\text{resolve-rec}}, f_{\text{compile-rec}}]\}
%\end{equation*}
%
%When type checking an expression like $\nats{\nats{\natz}}$, the type checker delegates to the user-provided type-level function $f_{\text{resolve-s}}$. This function would be tasked with assigning a type to expression as a whole, given information including the \emph{types} (but not necessarily the full syntax trees) of all its subexpressions, or if a type cannot be assigned, producing a specific error message. Similarly, the compiler calls the $f_{\text{compile-s}}$ function to determine a representation in the target language for the expression, checking to ensure that it is well-formed and type-correct with respect to the target type system. Finally, elements of the editor may call into the $f_{\text{editor}}$ function (or one of several such functions, more generally) to control behaviors like code completion and code prediction when an expression of type $\nat$ is being entered. 
%
%Note that these functions are \emph{not} to be conflated with methods or run-time functions -- they are functions written in a type-level language that are called at compile-time and edit-time to define the basic behaviors associated with the type that they are associated with.
%
%\subsection{Characteristics of an Actively-Typed Programming System}
%An actively-typed programming system can be characterized by its choice of type-level language, source grammar, target language and dispatch protocols.
%
%\paragraph{Type-Level Language} The type-level language is the language within which the type definitions and the functions that define their behaviors are defined. This language must be constrained so that different definitions do not interfere with one another and so that desirable safety properties for the system as a whole are maintained, as we discuss below.
%
%\paragraph{Source Language} The source language is the language with which run-time behavior is defined. In our example above, terms like $\nats{\nats{\natz}}$ are part of the source language. In the purest case, the source language is simply a grammar; its semantics are given entirely by active type specifications.
%
%\paragraph{Dispatch Protocol} For each syntactic form in the source language, there is a dispatch protocol that determines which type is delegated responsibility over it, and which specific function(s) are called for each behavior the system supports. This fixed protocol makes it possible for users to predict the meaning of a construct using information local to the term, a key differentiator of this approach compared to term-rewriting systems where there can be action at a distance.
%
%\paragraph{Target Language} The target language is the language that the front-end compilation phase of the system targets. The limitations and constraints imposed by the target language are final, because all constructs ultimately translate into terms in the target language. In other words, active type specifications can only add additional invariants to the language; they cannot violate invariants imposed by the target language.

%\subsection{Research Challenges}
%The example of natural numbers given above is relatively simple, and the solution we outline remains abstract. A key challenge is then to demonstrate that this approach is able to express the behaviors of more sophisticated language constructs that span diverse problem domains, and be implemented in the context of a realistic collection of tools. The resulting system should be usable by developers who lack the expertise needed to define new language constructs themselves.
%
%Simultaneously, we must also demonstrate that this model is well-motivated theoretically, place it within the broader context of the theory of typed programming languages, and demonstrate that it is possible for desirable system safety properties to be maintained. In particular, we are interested in properties like:
%
%\begin{itemize}
%\item Correctness of active type specifications, so that users of a library need not be forced to debug errors arising within the specifications themselves.
%\item Correctness of translations, so that the results of translation are guaranteed to be well-typed and consistent with respect to the target language.
%\item Termination of active type specifications, so that evaluation of the type-level functions cannot cause the compiler or editor to hang.
%\item Composability of active type specifications, so that the behaviors defined by one type cannot interfere with those defined by another, no matter the order in which they are imported. This property is essential if we wish to place these specifications within normal libraries.
%\end{itemize}


