% !TEX root = omar-thesis-proposal.tex
\vspace{-25pt}
\section{Motivation}\label{motivation}
Designing and implementing a programming language together with its supporting tools (collectively, a \emph{programming system}) that has a sound theoretical foundation, helps users identify and fix errors as early as possible, supports a natural programming style, and that performs well across diverse problem domains and hardware platforms remains a grand challenge in computing. Due to the increasing diversity and complexity of modern problem domains and hardware platforms, it has become clear that no small  collection of general-purpose primitives backed by a simple toolchain will be able to fully satisfy these criteria in all cases. Instead,  researchers will continue to provide specialized abstractions, notations,  type systems, implementation strategies, optimizations, run-time systems and tool support (collectively, specialized \emph{features}) in order to meet these growing challenges. %, researchers and domain experts must continue to design and develop, in a principled manner, specialized notations, type systems, optimizations, run-time systems and tools (collectively, \emph{features}) to support developers as they work in increasingly complex problem domains and on modern hardware systems.

% Rather, researchers and domain experts must continue, in a principled manner, to specify and implement novel abstractions, provide alternative implementations of existing abstractions, supplement languages with useful tools and improve tools with new behaviors (collectively, realize new \emph{features}) that better satisfy these criteria by balancing the concerns relevant to particular application domains. 

Ideally, providers would develop and distribute new features as libraries, so that developers could granularly choose those that best satisfy the constraints of their problem domains. Unfortunately, this is often infeasible, because libraries are nearly exclusively vehicles for specifying the run-time behaviors of a program, but providing these kinds of features  requires or benefits from some measure of control over the compile-time or edit-time semantics of the programming system. That is, from the perspective of a library, the language's semantics are fixed in advance, the compiler and run-time system are ``black box'' implementations of these fixed semantics, and the other tools, like code editors and debuggers, operate according to domain-agnostic protocols also based exclusively on these fixed semantics. As a result, providers of new system features must take \emph{language-external approaches}. We will argue that such approaches have several fundamental problems, and that taking them has led to an unnecessary gap between research and practice. In place of these approaches, we will advocate for \emph{language-internal extensibility mechanisms}, and show how, by organizing new features around types and constraining them appropriately, such mechanisms can be made both safe and highly expressive.
%But taking a \emph{language-internal approach} to implementing a feature is the most practical. If a feature can be realized by creatively using existing language constructs and distributed as a library, clients face fewer barriers to adoption because it is easy to integrate library-based features into existing projects gradually and granularly and they leverage well-understood and well-developed mechanisms.
% But taking this approach is often \emph{not} possible today %We call designs \emph{monolithic programming systems}.

%To realize a new abstraction or system behavior, such experts can consider either a \emph{language-internal approach}, where they work within an existing language and distribute their solutions as libraries, or a \emph{language-external approach}, where they create a new, distinct programming system (often centered around what has come to be called a new \emph{domain-specific language} \cite{dsl}) or extend an existing system by some mechanism that is not part of the language itself, such as an extension mechanism supported by a {particular} compiler, editor or other tool.
\subsection{Motivating Example: Regular Expressions}\label{regex}
To make the issue concrete, let us begin with a simple example. \emph{Regular expressions} are a widely-used mechanism for finding patterns in unstructured and semi-structured strings (when formal grammars are not appropriate) \cite{regex}. If a programming system included full compile-time and edit-time support for regular expressions, it might provide features like:

\begin{enumerate}
\item \textbf{built-in syntax for pattern literals} so that malformed patterns result in intelligible \emph{compile-time} parsing errors, motivated by the frequency of run-time errors relating to pattern syntax in Java \cite{regex-type-system} and other languages that do not have this feature.
\item \textbf{type checking logic} that ensures that key constraints related to regular expressions are not violated, such as that out-of-bounds group indices are not used \cite{regex-type-system} and that only values with correct types are spliced into regular expressions. When a type error is found, the error message should again be intelligible.
\item \textbf{translation logic} that partially or fully compiles regular expressions into the efficient internal representation that will be used by the regular expression matching engine at run-time. In most languages, this compilation step occurs at run-time, even if the pattern is fully known at compile-time, thereby introducing latency into programs. If the developer is not careful, regular expressions used repeatedly in a program might be needlessly re-compiled on each use. %By performing this step ahead-of-time, these dangers can be avoided.
\item \textbf{editor-integrated tooling} for interactively testing patterns against example strings, quickly referring to documentation, searching databases of common patterns and other domain-specific edit-time facilities.
\end{enumerate}

%In a conventional \emph{monolithic} programming system, support for each of these features would need to be built into the language and tools. 
No system today has built-in support for all of the features enumerated above. Instead, libraries generally provide support for regular expressions by leveraging  general-purpose constructs. Unfortunately, it is impossible to fully encode the syntax and the specialized static and dynamic semantics described above in terms of standard general-purpose notations and abstractions. Library providers have thus needed to compromise, typically by representing regular expressions using strings and deferring parsing, typechecking and translation to run-time, which introduces performance overhead and can lead to unanticipated run-time errors (as shown in \cite{regex-type-system}) and security vulnerabilities (due to injection attacks when splicing is used, for example). Similarly, edit-time features, as described above, are rarely integrated into editors, and never in a way that facilitates their discovery and use directly when the developer is manipulating regular expressions. In most cases, tools must be discovered independently and accessed externally (for example, via a browser), making both their development and use less common and more awkward than necessary \cite{active-code-completion} (see Section \ref{acc}).

\subsection{Language-External Approaches}
\begin{figure}
\begin{center}
\includegraphics[scale=0.45]{approaches.pdf}
\end{center}
\vspace{-20px}
\caption{\small (a) With the language-external approach, novel constructs are packaged into separate languages. Users can only safely and naturally call into languages if the interface uses common constructs and an interoperability layer has been developed (the \emph{interoperability problem}). (b) With the active library approach, there is one extensible host language and the compile-time and edit-time logic governing novel constructs is expressed within libraries. If the extension mechanism guarantees the safety of arbitrary compositions of extensions, the necessary primitives can simply be imported by library clients as needed, and so interoperability is not a problem.}
\label{approaches}
\end{figure}

When the compile-time or edit-time semantics of a system must be modified to fully realize a new feature, as in the example above, providers often take a \emph{language-external approach}, either by developing a new or derivative programming system (often centered around a so-called \emph{domain-specific language} \cite{dsl}) or by extending an existing system by some mechanism that is not part of the language itself, such as an extension mechanism supported by a {particular} compiler\footnote{Note that compilers that modify or allow modification of  the semantics of their base language, rather than simply implementing meaning-preserving optimizations, should be considered as pernicious means for creating new languages. Many compilers, including \texttt{gcc}, \texttt{GHC} and \texttt{SML/NJ}, are guilty of this sin, meaning that some programs that seem to be written in C, Haskell or Standard ML are actually written in tool-specific derivatives of those languages. Language-internal mechanisms do not lead to such fragmentation.} or other tool. %This latter method couples the semantics of the feature to the implementation details of a particular tool. Because the use of one implementation entails a different semantics for the feature than another, the extended tool acts, \emph{de facto}, as a distinct system for our purposes. 

Unfortunately, when providers of new features take language-external approaches, it causes problems for clients. Features cannot be adopted individually, but instead are only available coupled to a collection of other often-unrelated  features (the incidental features included in a newly-designed language or tool, or the existing features of the particular tool that was externally extended). This makes adoption more costly when these other features are either not appropriate or insufficiently developed, or when the features bundled with a different language or tool are simultaneously desirable. For example, although evidence suggests that developers prefer language-integrated parallel programming abstractions to library-based implementations if all else is equal \cite{langvslib}, library-based implementations are more widely adopted because parallel programming languages privilege only a few abstractions, even though parallel programming is rarely the only concern relevant to a component or application. Regular expression support, for example, may be simultaneously desirable when processing large amounts of textual data in parallel. %Similarly, a language and tools designed primarily to support regular expressions might make an interesting research project, but it would not be a suitable tool for writing large applications with more varied needs.

%\item Developing a new language and its associated tools places a significant development burden on providers who may wish only to promote a few core innovations, although tools like compiler generators, language workbenches and easy-to-extend tools can decrease this burden. 
%\item 

%Clients seem to prioritize the ability to choose different features for different portions of an application. 
%If calling between languages were safe and easy, then using a variety of specialized languages and associated tools might be less problematic. In fact, s
%Recognizing the limitations of relying on monolithic collection of primitives, some researchers have advocated instead for a model where multiple languages used within a single application, calling it the \emph{language-oriented approach} to software development \cite{languageoriented}. 

Even when various concerns can be separated into different components, each written in a suitable language (often called the \emph{language-oriented approach} to software development \cite{language-oriented}), the interfaces between these components remains an issue. The specialized primitives particular to one language cannot always be safely and naturally expressed in terms of those available in another, so building a program out of components written in a variety of different languages is difficult or impossible whenever these primitives are exposed at interface boundaries. We refer to this fundamental issue as the \emph{interoperability problem}. 

One strategy often taken by programming language designers to partially address the interoperability problem is to  target an established language or bytecode, such as the Java Virtual Machine (JVM) bytecode or LLVM IR, and support a superset of its constructs. Scala \cite{scala} and F\# \cite{fsharp} are two prominent examples of general-purpose languages that have taken this approach, and many domain-specific language frameworks also rely on this strategy (e.g. Delite \cite{delite}). This only enables full interoperability in one direction (Figure \ref{approaches}a). While calling into the common language becomes straightforward, calls in the other direction, or between the languages sharing the common target, are still restricted by the semantics of the common language. 
If new languages only include constructs that can already be expressed safely and reasonably naturally in the common language, then this approach can work well. 
But many of the most innovative constructs found in modern languages (often, the features that justify their creation) are difficult to define in terms of existing constructs in ways that guarantee all necessary invariants are statically maintained and that do not require large amounts boilerplate code and run-time overhead. For example, the type system of F\# guarantees that null values cannot occur within F\# data structures, but maintaining this important invariant still requires run-time checks because the typing rules of F\# do not apply when F\# code is called from other languages on the Common Language Infrastructure (CLI) like C\#. The F\# type system also includes support for checking that units of measure are used correctly \cite{fsharpunits}, but this specialized invariant is left completely unchecked at language boundaries. In Scala, interfaces built around traits that have default method implementations are difficult to implement from Java or other JVM languages and the workaround can break if the trait is modified \cite{scalatraitinterop}. In some cases, desirable features must be omitted entirely due to concerns about  interoperability. The module system in F\#, for example, is substantially simpler than that in its predecessor, OCaml, despite F\# otherwise aiming to maintain compatibility, due to the need for bidirectional interoperability between F\# and other CLI languages.
%\end{itemize}

\subsection{Active Libraries}
For these reasons, we argue that taking a language-external approach to realizing a new feature, by packaging it into a new or derivative language or tool, should be considered harmful and avoided whenever possible. The goal of the research being proposed here is to fundamentally reorganize the core components of the programming system so that such language-external approaches are less frequently necessary, by designing \emph{language-internal extension mechanisms} that give developers control over edit-time and compile-time behaviors that have previously been defined externally and thus, in the case of popular languages, become available only subject to the approval of slow-moving governing committees\footnote{One might compare today's monolithic programming systems to  {centrally-planned} economies, whereas extensible\- systems more closely resemble modern market economies.}\todo{read Arch D. Robison. Impact of economics on compiler optimization.}. Specifically, we will show how control over \textbf{parsing}, \textbf{typechecking}, \textbf{translation} (the first stage of compilation) and \textbf{code completion} can be delegated to user-defined logic distributed in {libraries}, as illustrated in Figure \ref{approaches}b. 
Such libraries are called \emph{active libraries} because, rather than being passive consumers of features already available in the system, they contain logic invoked by the system during development or compilation to provide new domain-specific features  \cite{active-libraries}. Features implemented within active libraries are imported as needed by the clients of libraries that rely on them, unlike features implemented by language-external means.

Some critical issues having to do with {safety} must be overcome before library-based extension mechanisms can be introduced into a programming system, because if too much control over such core aspects of the system is given  to developers, the system may become unreliable. 
%For example, an extension could weaken important metatheoretic guarantees previously provided by the system. 
Type safety, for example, may not hold if the static and dynamic semantics of the language can be modified or extended arbitrarily from within libraries. Furthermore, even if extensions can be shown not to cause such problems in isolation, there may still be conflicts between extensions that could weaken their semantics and lead to subtle problems at link-time. For example, if two active libraries defined differing semantics for the same syntactic form, the issue would only manifest itself when both libraries were imported somewhere within the same program. These kinds of safety issues have plagued previous attempts at language-internal extensibility.% To prevent them, our mechanisms will organize  extension logic around types to guarantee that extensions are both safe in isolation and also safely composable in any combination. 


 %This represents a minimalist approach to system design -- the conventional distinction between built-in and user-defined constructs is blurred and most features of the system are orthogonally implemented as {libraries}, rather than by the maintainers of the system.

%The mechanisms we describe will do so primarily by delimiting the scope of an extension to expressions of a single user-defined type or family of types. 

%This can be thought of as a more pernicious form of the conflict that arises when two globally-accessible constructs are given the same name. n languages without universal namespacing mechanisms (e.g. C, JavaScript, \LaTeX, ML and many others). 

%The extension mechanism\todo{elaborate on safety requirements + tension between expressiveness and safety, merge with next paragraph}. must be expressive enough to allow users to associate rich run-time, compile-time and edit-time behaviors with user constructs directly, while being sufficiently restrictive to maintain the global safety properties of the language and system as a whole, and to ensure that constructs cannot interfere with one another. 
