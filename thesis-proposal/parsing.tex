% !TEX root = omar-thesis-proposal.tex
\lstset{tabsize=2, 
basicstyle=\ttfamily\fontsize{8pt}{1em}\selectfont, 
commentstyle=\itshape\rmfamily, 
stringstyle=\ttfamily,
numbers=left, numberstyle=\scriptsize\color{gray}\ttfamily, language=ML,moredelim=[il][\sffamily]{?},mathescape=true,showspaces=false,showstringspaces=false,xleftmargin=15pt,escapechar=@, morekeywords=[1]{let,fn,val,def,casetype,objtype,metadata,of,*,datatype,new,valAST},deletekeywords={for,double,in},classoffset=0,belowskip=\smallskipamount,
moredelim=**[is][\color{cyan}]{SSTR}{ESTR},
moredelim=**[is][\color{OliveGreen}]{SHTML}{EHTML},
moredelim=**[is][\color{purple}]{SCSS}{ECSS},
moredelim=**[is][\color{brown}]{SSQL}{ESQL},
moredelim=**[is][\color{orange}]{SCOLOR}{ECOLOR},
moredelim=**[is][\color{magenta}]{SPCT}{EPCT}, 
moredelim=**[is][\color{gray}]{SNAT}{ENDNAT}, 
moredelim=**[is][\color{blue}]{SURL}{EURL},
moredelim=**[is][\color{SeaGreen}]{SQT}{EQT},
moredelim=**[is][\color{Periwinkle}]{SGRM}{EGRM},
moredelim=**[is][\color{YellowGreen}]{SID}{EID}
}
\lstloadlanguages{Java,VBScript,XML,HTML}
\let\li\lstinline

\section{Type-Specific Languages}\label{aparsing}
By using a general-purpose abstraction mechanism to encode a data structure, one immediately benefits from a body of established reasoning principles and primitive operations. For example, inductive datatypes can be used to express data structures like lists: intuitively, a list can either be empty, or be broken down into a value (its \emph{head}) and another list (its \emph{tail}). In an ML-like language, this concept is conventionally written:
\begin{lstlisting}[numbers=none]
datatype 'a list = Nil | Cons of 'a * 'a list
\end{lstlisting}
By encoding lists in this way, we can reason about them by structural induction, construct them by choosing the appropriate case and inspect them by pattern matching. The programmer only needs to provide an encoding of the structure of lists; the semantics are filled in by the general-purpose abstraction mechanism.

While inheriting semantics can be quite useful, inheriting associated general-purpose syntax can sometimes be a liability. For example, few would claim that writing a list of numbers as a sequence of \li{Cons} cells is convenient:
\begin{lstlisting}[numbers=none]
Cons(1, Cons(2, Cons(3, Cons(4, Nil))))
\end{lstlisting}

Because lists are a common data structure, many languages provide specialized notation for constructing them, e.g. \li{[1, 2, 3, 4]}. This notation is semantically equivalent to the general-purpose notation shown above, but brings cognitive benefits by drawing attention to the content of the list, rather than the nature of the encoding. More specifically, it is more \emph{terse}, \emph{visible} and \emph{maps more closely} to the intuitive notion of a list, to use terminology from the literature on the cognitive dimensions of notations \cite{green1996usability}.

Although number, string and list literals are nearly ubiquitous features of modern languages, some languages also  provide specialized notation for other common data structures, like maps and sets, data formats, like XML and JSON, query languages, like regular expressions and SQL, and markup languages, like HTML. For example, a language with built-in syntax for HTML and SQL, with type-safe interpolation of host language terms via curly braces, might allow:
\begin{lstlisting}
let webpage : HTML = SHTML<html><body><h1>Results for {EHTMLkeywordSHTML}</h1>
  <ul id="results">{EHTMLto_list_items(query(db, 
    SSQLSELECT title, snippet FROM products WHERE {ESQLkeywordSSQL} in titleESQL)SHTML}
  </ul></body></html>EHTML
\end{lstlisting}
to mean:
\begin{lstlisting}
let webpage : HTML = HTMLElement(Empty, [BodyElement(Empty,
  [H1Element(Empty, [TextNode($\texttt{"}$SSTRResults for $\texttt{"}$ESTR + keyword)]), 
  ULElement((add Empty ($\texttt{"}$SSTRid$\texttt{"}$ESTR, $\texttt{"}$SSTRresults$\texttt{"}$ESTR)), to_list_items(query(db, 
    SelectStmt([$\texttt{"}$SSTRtitle$\texttt{"}$ESTR, $\texttt{"}$SSTRsnippet$\texttt{"}$ESTR], $\texttt{"}$SSTRproducts$\texttt{"}$ESTR, 
      [WhereClause(InPredicate(StringLit(keyword), $\texttt{"}$SSTRtitle$\texttt{"}$ESTR))]))))]]]
\end{lstlisting}

When a specialized notation is not available, and equivalent general-purpose notation is too cognitively demanding for comfort, developers typically turn to run-time mechanisms to make constructing data structures more convenient. Among the most common strategies in these situations is to simply use a string representation that is parsed at run-time. Developers are frequently  tempted to write the example above as:
\begin{lstlisting}
let webpage : HTML = parse_html($\texttt{"}$SSTR<html><body><h1>Results for ESTR$\texttt{"}$+keyword+$\texttt{"}$SSTR</h1>
  <ul id=\$\texttt{\color{cyan}"}$results\$\texttt{\color{cyan}"}$>$\texttt{"}$ESTR + to_string(to_list_items(query(db, parse_sql(
  	$\texttt{"}$SSTRSELECT title, snippet FROM products WHERE '$\texttt{"+keyword+"}$' in title$\texttt{"}$ESTR)))) + 
  $\texttt{"}$SSTR</ul></body></html>$\texttt{")}$
\end{lstlisting}

Though recovering much of the notational convenience of the literal version, it is still more awkward to write, requiring explicit conversions to and from structured representations and escaping when the syntax of the language clashes with the syntax of string literals (line 2). But code like this also causes a number of more serious problems beyond cognitive load. Because parsing occurs at run-time, syntax errors will not be discovered statically, causing potential problems in production scenarios. Run-time parsing also incurs performance overhead, particularly relevant when code like this is executed often (as on a heavily-trafficked website, or in a loop). But the most serious issue with this code is that it is fundamentally insecure: it is vulnerable to cross-site scripting attacks (line 1) and SQL injection attacks (line 3). For example, if a user provided the keyword \li{'; DROP TABLE products --}, the entire product database could be erased. These attack vectors are considered to be two of the most serious security threats on the web today \cite{owasp2013}. Although developers are cautioned to sanitize their input, it can be difficult to verify that this was done correctly throughout a codebase. The most straightforward way to avoid these problems is to use structured representations throughout the codebase, aided by specialized notation like that above \cite{Bravenboer:2007:PIA:1289971.1289975}.

To emphasize that this is a common problem, let us return to considering regular expression literals. It is quite tedious to write out a regular expression in a structured manner. A simple regular expression like \verb!(\d\d):(\d\d)\w*((am)|(pm))! representing times might be written:
\begin{lstlisting}
Seq(Group(Seq(Digit, Digit), Seq(Char($\texttt{"}$SSTR:ESTR$\texttt{"}$), Seq(Group(Seq(Digit, Digit)), 
  Seq(ZeroOrMore(Whitespace), Group(Or(Group(Seq(Char($\texttt{"}$SSTRaESTR$\texttt{"}$), Char($\texttt{"}$SSTRmESTR$\texttt{"}$))), 
  Group(Seq(Char($\texttt{"}$SSTRpESTR$\texttt{"}$), Char($\texttt{"}$SSTRmESTR$\texttt{"}$))))))))))
\end{lstlisting}
This is clearly more cognitively demanding, both when authoring the regular expression and when reading it. Among the most common strategies in these situations, for users of both object-oriented and functional languages, is to simply use a string representation that is parsed at run-time.
\begin{lstlisting}
rx_from_str($\texttt{"}$SSTR(\\d\\d):(\\d\\d)\\w*((am)|(pm))ESTR$\texttt{"}$)
\end{lstlisting}
%%
%%For example, in languages without SQL literals, developers can implement a builder pattern:
%%\begin{lstlisting}
%%new SQLQuery().SELECT("*").FROM("table").WHERE("username").Eq(username)
%%\end{lstlisting}
This is problematic, for the same reasons as described above. 

As we will examine further in our corpus analysis, situations like this, where specialized notation is  necessary to maintain strong correctness, performance and security guarantees while avoiding unacceptable cognitive overhead, are quite common. 
Today, implementing new notations within an existing language requires the cooperation of the language designer. A primary reason for this is that, with conventional parsing strategies, not all notations can safely coexist, so a designer is needed to make choices about which syntactic forms are available and what their semantics are. For example, conventional notations for sets and maps are both delimited by curly braces. When Python introduced set literals, it chose to distinguish them based on whether the literal contained only values, or key-value pairs. But this causes an ambiguity with the syntactic form \verb|{ }| -- should it mean an empty set or an empty map (called a dictionary in Python)? The designers of Python chose the latter interpretation (for backwards compatibility reasons, in this case).

Languages that allow users to introduce new syntax from within libraries hold promise, but because there is no longer a designer making decisions about such ambiguities, the burden of resolving them falls to the clients of extensions. For example, SugarJ \cite{erdweg2011sugarj} and other extensible languages generated by Sugar* \cite{erdweg2013framework} allow providers to extend the base syntax of the host language (e.g. Java) with new forms, like set and map literals. New forms are imported transitively throughout a program. To resolve syntactic ambiguities that arise, clients must manually augment the composed grammar with new rules that allow them to choose the correct interpretation explicitly. This is both difficult to do, requiring an understanding of the underlying parser technology (in Sugar*, GLR parsing using SDF) and increases the cognitive load of using the conflicting notations (e.g. both sets and dictionaries) in the same file. These kinds of conflicts occur in a variety of circumstances: HTML and XML, different variants of SQL, JSON literals and dictionaries, or simply different implementations (``desugarings'') of the same specialized syntax (e.g. two regular expression engines) can all cause problems.

In this work, we will describe an alternative parsing strategy that avoids these problems by shifting responsibility for parsing certain \emph{generic literal forms} into the typechecker. The typechecker, in turn, defers responsibility to user-defined types, by treating the body of the literal as a term of the   \emph{type-specific language (TSL)} associated with the type it is being checked against. The TSL is responsible for rewriting this term to ultimately use only general-purpose notation. This strategy avoids the problem of conflicting syntax, because neither the base language nor TSLs are ever extended directly. It also avoids semantic conflicts -- the meaning of a form like \verb|{ }| can differ depending  on its type, so it is safe to use it for empty sets, dictionaries and other data structures, like JSON literals. This frees these common notations from the variant of a  data structure built into the standard library, which sometimes does not provide the exact semantics that a programmer needs (for example, Python dictionaries do not preserve order, while JSON does).
%\begin{lstlisting}
%let empty_set : Set = { }
%let empty_dict : Dict = { }
%let empty_json : JSON = { }
%\end{lstlisting}
\subsection{Wyvern}
We develop our work as a variant of an emerging programming language being developed by our group called Wyvern \cite{Nistor:2013:WST:2489828.2489830}. To allow us to focus on the essence of our proposal, the variant of Wyvern we will describe in this thesis is simpler than the variant previously described: it is purely functional (there are no effects or mutable state) and it does not enforce a uniform access principle for objects (fields can be accessed directly). We also add recursive sum types, which we call \emph{case types}, that operate similarly to datatypes in ML. One can refer to the version of the language described in this thesis as \emph{TSL Wyvern} when the variant being discussed is not clear.

We begin with an example in Fig. \ref{f-example} showing several different TSLs being used to define a fragment of a web application showing search results from a database. We will review this example below to develop intuitions about TSLs in Wyvern. \todo{describe colors}
\begin{figure}[t]
\begin{lstlisting}
let imageBase : URL = <SURLimages.example.comEURL>
let bgImage : URL = <SURL%EURLimageBaseSURL%/background.pngEURL>
new : SearchServer
  def resultsFor(searchQuery : String, page : Nat) : Unit =
    serve(~) (* serve : HTML -> Unit *)
SHTML      :html
        :head
          :title Search Results
          :style EHTML~
SCSS            body { background-image: url(%ECSSbgImageSCSS%) }
            #search { background-color: %ECSS`SCOLOR#aabbccECOLOR`.darken(SPCT20pctEPCT)SCSS% }
ECSSSHTML        :body
          :h1 Results for {EHTMLsearchQuerySHTML}
          :div[id="search"]
            Search again: {EHTMLSearchBox($\texttt{"}$SSTRGo!ESTR$\texttt{"}$)SHTML}
          {EHTML (* fmt_results : (DB, SQLQuery, Nat, Nat) -> HTML *)
            fmt_results(db, ~, SNAT10ENDNAT, page)
              SSQLSELECT * FROM products WHERE {ESQLsearchQuerySSQL} in titleESQL
          SHTML}
\end{lstlisting}
\vspace{-8px}
\caption{Wyvern Example with Multiple TSLs}
\label{f-example}
\vspace{-10px}
\end{figure}
\subsection{Inline Literals}
\begin{figure}[t]
\begin{lstlisting}
<SURLliteral body here, <inner angle brackets> must be balancedEURL>
{SURLliteral body here, {inner braces} must be balancedEURL}
[SURLliteral body here, [inner brackets] must be balancedEURL]
`SURLliteral body here, ``inner backticks`` must be doubledEURL`
$\texttt{'}$SURLliteral body here, ''inner single quotes'' must be doubledEURL$\texttt{'}$
$\texttt{"}$SURLliteral body here, ""inner double quotes"" must be doubledEURL$\texttt{"}$
SURL12xyzEURL (* no delimiters necessary for number literals *)
\end{lstlisting}
\vspace{-8px}
\caption{Inline Generic Literal Forms}
\vspace{-10px}
\label{f-delims}
\end{figure}
Our first TSL appears on line 1. The type of \li{imageBase} is \li{URL}, a \emph{structural type} containing several fields representing the components of a URL: its protocol, domain name, port, path and so on. We could create a value of type \li{URL} using general-purpose notation:
\begin{lstlisting}
let imageBase : URL = new
  val protocol : String = $\text{"}$SSTRhttpESTR$\texttt{"}$
  val subdomain : String = $\texttt{"}$SSTRimagesESTR$\texttt{"}$
  val domain : String = $\texttt{"}$SSTRexampleESTR$\texttt{"}$
  (* ... *)
\end{lstlisting}
This is tedious. If the \li{URL} type has a TSL associated with it, we can instead instantiate precisely this value using conventional notation for URLs by placing it in a \emph{generic literal}, \li{<SURLimages.example.comEURL>}. The type annotation on \li{imageBase} implies that this literal's \emph{expected type} is \li{URL}, so the \emph{body} of the literal (the characters between the angle brackets, in blue) is governed by the \li{URL} TSL. This TSL will parse the body {at compile-time} to produce a Wyvern AST that explicitly instantiates a new object of type \li{URL}  (see below). Any other delimited form in Fig. \ref{f-delims} could equivalently be used if the constraints shown are obeyed.

In addition to supporting conventional notation for URLs, this TSL supports \emph{typed interpolation}
of a \li{URL} expression to form a larger URL. The interpolated term is delimited by percent signs,
as seen on line 2 of Fig. \ref{f-example}. The TSL parses code between percent signs  as a Wyvern expression with expected type \li{URL}. The TSL then assumes the interpolated expression is of this
type to construct an AST. Untyped---and thus unsafe---interpolation of strings
does not occur. Note that the delimiters that can be used to go from Wyvern to a TSL are determined by Wyvern (those in Fig. \ref{f-delims}) while the delimiters that can be used to go from a TSL back to Wyvern are chosen by the TSL (see Sec. \ref{ss:implementing-interpolation}).

%\subsection{General-Purpose Notation for Object and Case Types}
%The general-purpose introductory form for object types is \li{new}. This form is a syntactic \emph{forward reference} to the layout-delimited block of {definitions} beginning on the line immediately after the line \li{new} appears in (line 4 in this case), and ending when the indentation level has returned to the baseline, or when the file ends (after line 19 in this case). An object in TSL Wyvern can contain methods, introduced using \li{def}, and fields, introduced using \li{val}. Here we have just a single method, \li{serve_results} taking two arguments. Object types in TSL Wyvern are simple structural interfaces that constrain the signatures of fields and methods. The \emph{type ascription} around \li{new} checks that the object being introduced satisfies the signature of \li{SearchServer} (not shown).\todo{discuss case types}
\subsection{Layout-Delimited Literals}
On line 5 of Fig. \ref{f-example}, we see a call to a function \li{serve}, not shown, which has type \li{HTML -> Unit}. Here, \li{HTML} is a user-defined \emph{case type}, having cases for each HTML tag as well as some other structures. Declarations  of some of these cases can be seen on lines 2-6 of Fig. \ref{f-htmltype} (TSL Wyvern also includes simple product types for convenience, written \li{T1 * T2}). The general-purpose introductory form for a case type like \li{HTML} is, e.g., \li{HTML.BodyElement((attrs, child))}. But, as discussed above, using this syntax can be cognitively demanding. Thus, we associate a TSL with \li{HTML} that provides a simplified notation for writing HTML, shown being used on lines 6-20 of Fig. \ref{f-example}. This literal body is layout-delimited, rather than delimited by explicit tokens as in Fig. \ref{f-delims}, and introduced by a form of \emph{forward reference}, written \li{~} (``tilde''), on the previous line. Because the forward reference occurs in a position where the expected type is \li{HTML}, the literal body is governed by that type's TSL. The forward reference will be replaced by a general-purpose term of type \li{HTML} generated from the literal body by the TSL during compilation.
\begin{figure}[t]
\begin{lstlisting}[escapechar=$]
casetype HTML 
    Empty of Unit
  | Text of String
  | Seq of HTML * HTML 
  | BodyElement of Attributes * HTML
  | StyleElement  of Attributes * CSS
  | ...
  metadata = new : HasParser
    val parser : Parser = ~
SGRM      start -> ':body'= child::start>
        EGRM`SQTHTML.BodyElement(([], %EQTchildSQT%))EQT`
SGRM      start -> ':style'= e::EXP[NEWLINE]>
        EGRMlet empty_attrs : Attributes = []
        Exp.CaseIntro(Type.Var($\texttt{"}$SIDHTMLEID$\texttt{"}$), $\texttt{"}$SIDStyleElementEID$\texttt{"}$,
          Exp.ProdIntro(valAST(empty_attr), e))
SGRM      start -> '{'= e::EXP['}']>EGRM
        `SQT%EQTeSQT% : HTMLEQT`
\end{lstlisting}
\vspace{-8px}
\caption{A Wyvern case type with an associated TSL.}
\vspace{-10px}
\label{f-htmltype}
\end{figure}

\subsection{Implementing a TSL}
Portions of the implementation of the TSL for \li{HTML} are shown on lines 8-17 of Fig. \ref{f-htmltype}, written as a declarative grammar. A \li{Parser} is associated with a type using \li{metadata}, as shown. The \li{metadata} of a type \li{t} is simply a value that is associated with the type at both compile-time and run-time. It can be accessed using the syntactic form \li{t.metadata}. In this case, it is an object with a single field, called \li{parser} of type \li{Parser} (defined in Wyvern's standard library). A type equipped with a parser in this way is an example of an \emph{active type}.

A grammar can be thought of as specialized notation that generates a parser. Since we have a type for parsers, \li{Parser}, we can implement a grammar-based parser generator  itself  as a TSL. In this case, we are basing our grammar formalism on the layout-sensitive formalism developed by Adams \cite{Adams:2013:PPI:2429069.2429129} -- Wyvern is itself layout-sensitive and has a grammar that can be written down using this formalism, so it makes sense to support it for layout-sensitive TSLs as well. Most aspects of this formalism are completely conventional. 
Each non-terminal (e.g. \li{start}) is defined by a number of disjunctive productions, each introduced using \li{->}. Each production defines a sequence of terminals (e.g. \li{':body'}) and non-terminals (e.g. \li{start}), which can have names (e.g \li{child}) associated with them using \li{::}. Unique to Adams' formalism is that each terminal and non-terminal in a production can also have a \emph{layout constraint} following it. Here, the layout constraints can be either \li{=} (meaning that the leftmost column of the annotated term must be aligned with that of the parent term), \li{>} (the leftmost column must be indented further), \li{>=} (the leftmost column \emph{may} be indented further). Layout constraints are optional in TSLs. We will discuss this further when we formally describe Wyvern's layout-sensitive concrete syntax.

Each rule is followed by a Wyvern expression, in an indented block, that implements the rewriting logic for the associated rule. This expression should have type \li|Exp|, a case type built into the standard library representing Wyvern expression ASTs. The ASTs generated by named non-terminals in the rule (e.g. \li{child}) are bound to the corresponding variables within this logic. Here, we show how to generate an AST using general-purpose notation for \li{Exp} (lines 13-15) as well as the more natural \emph{quasiquote} style (lines 11 and 18). Quasiquotes are simply the TSL associated with \li{Exp} and support the full Wyvern concrete syntax as well as an additional delimiter form, written with \li{%}s, that allows ``unquoting'': interpolating another AST into the one being generated. Again, interpolation is typesafe, structured and occurs at compile time.

\subsection{Implementing Interpolation}\label{ss:implementing-interpolation}
We have now seen several examples of interpolation. Within the TSL for \li{HTML}, for example, we see it used in several ways:

\subsubsection{HTML Interpolation} At any point where a tag should appear, we can also interpolate a Wyvern expression of type \li{HTML} by enclosing it within curly braces (e.g. on line 13, 15 and 16-19 of Fig. \ref{f-example}). This is implemented on lines 17 and 18 of Fig. \ref{f-htmltype}. The special non-terminal \li{EXP[token]} signals a switch into the Wyvern grammar. The tokenstream will be parsed as a Wyvern expression until the token \li{token} is encountered \emph{where it would otherwise trigger a parse error}. In other words, the Wyvern grammar binds more tightly to itself than to any surrounding TSL, avoiding potential ambiguities. The AST for the parsed Wyvern expression is given an expected type, \li{HTML}, by simply surrounding it with a type ascription (line 18). Because interpolation must be structured (a string cannot be interpolated directly), injection and cross-site scripting attacks cannot occur. Safe interpolation of expressions of type \li{String} (where any inner angle brackets and other special characters are turned into HTML entities, e.g. \li{&lt;} for \li{<}) could similarly be implemented using another delimiter.

\subsubsection{CSS Interpolation} After the \li{:style} tag appears (e.g. on line 9 of Fig. \ref{f-example}), instead of hard-coding CSS syntax into the HTML DSL, we instead wish to use the TSL associated with a type representing a CSS stylesheet: \li{CSS}. We do this by again interpolating a Wyvern expression (lines 12-15 of Fig. \ref{f-htmltype}), making sure that it appears in a position where the expected type is \li{CSS} (the second piece of data associated with the \li{StyleElement} constructor, in this case). Wyvern is given control until a full expression has been read and an unexpected newline appears (that is, a newline that does not introduce a layout-delimited block). Here we see a use of a layout-delimited TSL within another layout-delimited TSL.

\subsubsection{Interpolation within the CSS TSL} The TSL for \li{CSS} itself has support for interpolation in a similar manner, choosing \li{%} as the delimiter. It chooses the type based on the semantics of the surrounding CSS form. For example, when a Wyvern expression appears inside \li{url}, as on line 10 of Fig. \ref{f-example}, it must be of type \li{URL}. When a Wyvern expression appears where a color is needed, the \li{Color} type is used. This type itself has a TSL associated with it that interprets CSS color strings, showing again that TSLs can be used within TSLs by simply escaping out to Wyvern, the host language, and then back in. 
In this case, we emphasize that TSLs produced structured values by calling the \li{darken} method on it to produce a new color. This method itself takes a \li{Percentage} as an argument. The TSL for this type accepts literal bodies containing numbers followed by \li{pct}, or simply a real number without a suffix. Numeric literals, because they begin with a number (and no other form in Wyvern can), do not require delimiters (Fig. \ref{f-delims}). 

\subsubsection{Interpolation within the SQLQuery TSL} The TSL used for SQL queries on line 18 of Fig. \ref{f-example} follows an identical pattern, allowing strings to be interpolated into portions of a query in a safe manner. This prevents SQL injection attacks from occurring while maintaining standard SQL syntax.

\subsection{Formalization}
A formal and more detailed description can be found in our paper draft\footnote{\url{https://github.com/wyvernlang/docs/tree/master/ecoop14}}. In particular\todo{should I include some/all of this in the proposal?}:
\begin{enumerate}
\item We provide a more complete layout-sensitive concrete syntax. We show how it can be written without the need for a context-sensitive lexer or parser and give a full specification for the layout-delimited literal form introduced by a forward reference, \li{~}, as well as other forms of forward-referenced blocks.
\item We detail the general mechanism for associating metadata with a type. A TSL is then implemented by associating a parser (of type \li{Parser}) with a type. The parser is responsible for rewriting tokenstreams (of type \li{Tokenstream}) into Wyvern ASTs (of type \li{Exp}). These types are defined in the standard library.
%\item This lower-level mechanism is general, but writing a hand-written parser and manipulating syntax trees manually is cognitively demanding. We observe that \emph{grammars} and \emph{quasiquotes} can both be seen as TSLs for parsers and ASTs respectively and discuss how to implement them as such.
\item A na\"ive rewriting strategy would be \emph{unhygienic} -- it could allow for the inadvertent capture of local variables. We show a novel mechanism that ensures hygiene by requiring that the generated AST is closed except for subtrees derived from portions of the user's tokenstream that are interpreted as nested Wyvern expressions. We also show how to explicitly refer to local values available in the parser definition (e.g. helper functions) in a safe way. 
\item We formalize the static semantics and literal parsing rules of TSL Wyvern as a bidirectional type system. By distinguishing locations where an expression synthesizes a type from locations where an expression is being analyzed against a previously synthesized type, we can precisely state where generic literals can appear. This system also provides a formal specification of our hygiene mechanism.
\item We provide several examples of TSLs throughout the paper, but to examine how broadly applicable the technique is, we conduct a simple corpus analysis, finding that string languages are used ubiquitously in existing Java code  (collaborative work with Darya Kurilova).
\end{enumerate}

\subsection{Remaining Tasks}
The following tasks remain to be completed:
\begin{enumerate}
\item We must write down the full formal semantics (including rules that we omitted for concision in the paper draft) in a technical report, as well as provide more rigorous proofs of the metatheory.
\item We must further consider aspects of hygiene. In particular, we do not have a clean mechanism for preventing unintentional variable \emph{shadowing}, only unintentional variable \emph{capture}. It may be possible to prevent shadowing by making it impossible for variables to be introduced into interpolated Wyvern expressions (so that function application is the only way to pass data from a TSL to Wyvern code).
\item The corpus analysis we conducted was preliminary. We must perform this in a more complete and rigorous manner (collaborative work with Darya Kurilova).
%\item The current implementation of Wyvern does not include all of these mechanisms as described. Although the implementation of Wyvern is not a project I am responsible for, I plan on working with the student who is doing this to implement as much of what we have described as possible.\todo{should I drop this from the proposal? I don't want to promise that everything will be implemented because that is largely contingent on Benjamin's effort, not mine.}
\end{enumerate}
%
%\subsection{TODO}
%- Figure out separate compilation (e.g. of CSS)
