\documentclass[10pt,preprint]{sigplanconf}
\newcommand{\lamAce}{\lambda_{\text{Ace}}}
% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.
\usepackage{listings}
\usepackage[usenames,dvipsnames]{color}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amssymb} 
\usepackage{amsthm}
\usepackage{ stmaryrd }
\usepackage{verbatimbox}
\input{../att-icfp14/macros-atlam}
\usepackage{alltt}
\renewcommand{\ttdefault}{txtt}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{light-gray}{gray}{0.5}
\usepackage{listings}
\usepackage{wasysym}
    \makeatletter

% \btIfInRange{number}{range list}{TRUE}{FALSE}
%
% Test if int number <number> is element of a (comma separated) list of ranges
% (such as: {1,3-5,7,10-12,14}) and processes <TRUE> or <FALSE> respectively
%
        \newcount\bt@rangea
        \newcount\bt@rangeb

        \newcommand\btIfInRange[2]{%
            \global\let\bt@inrange\@secondoftwo%
            \edef\bt@rangelist{#2}%
            \foreach \range in \bt@rangelist {%
                \afterassignment\bt@getrangeb%
                \bt@rangea=0\range\relax%
                \pgfmathtruncatemacro\result{ ( #1 >= \bt@rangea) && (#1 <= \bt@rangeb) }%
                \ifnum\result=1\relax%
                    \breakforeach%
                    \global\let\bt@inrange\@firstoftwo%
                \fi%
            }%
            \bt@inrange%
        }

        \newcommand\bt@getrangeb{%
            \@ifnextchar\relax%
            {\bt@rangeb=\bt@rangea}%
            {\@getrangeb}%
        }

        \def\@getrangeb-#1\relax{%
            \ifx\relax#1\relax%
                \bt@rangeb=100000%   \maxdimen is too large for pgfmath
            \else%
                \bt@rangeb=#1\relax%
            \fi%
        }

%
% \btLstHL{range list}
%
        \newcommand{\btLstHL}[1]{%
            \btIfInRange{\value{lstnumber}}{#1}%
            {\color{black!10}}%
            {\def\lst@linebgrd}%
        }%

%
% \btInputEmph[listing options]{range list}{file name}
%
        \newcommand{\btLstInputEmph}[3][\empty]{%
            \lstset{%
                linebackgroundcolor=\btLstHL{#2}%
                \lstinputlisting{#3}%
            }% \only
        }

% Patch line number key to call line background macro
        \lst@Key{numbers}{none}{%
            \def\lst@PlaceNumber{\lst@linebgrd}%
            \lstKV@SwitchCases{#1}{%
                none&\\%
                left&\def\lst@PlaceNumber{\llap{\normalfont
                \lst@numberstyle{\thelstnumber}\kern\lst@numbersep}\lst@linebgrd}\\%
                right&\def\lst@PlaceNumber{\rlap{\normalfont
                \kern\linewidth \kern\lst@numbersep
                \lst@numberstyle{\thelstnumber}}\lst@linebgrd}%
            }{%
                \PackageError{Listings}{Numbers #1 unknown}\@ehc%
            }%
        }

% New keys
        \lst@Key{linebackgroundcolor}{}{%
            \def\lst@linebgrdcolor{#1}%
        }
        \lst@Key{linebackgroundsep}{0pt}{%
            \def\lst@linebgrdsep{#1}%
        }
        \lst@Key{linebackgroundwidth}{\linewidth}{%
            \def\lst@linebgrdwidth{#1}%
        }
        \lst@Key{linebackgroundheight}{\ht\strutbox}{%
            \def\lst@linebgrdheight{#1}%
        }
        \lst@Key{linebackgrounddepth}{\dp\strutbox}{%
            \def\lst@linebgrddepth{#1}%
        }
        \lst@Key{linebackgroundcmd}{\color@block}{%
            \def\lst@linebgrdcmd{#1}%
        }

% Line Background macro
        \newcommand{\lst@linebgrd}{%
            \ifx\lst@linebgrdcolor\empty\else
                \rlap{%
                    \lst@basicstyle
                    \color{-.}% By default use the opposite (`-`) of the current color (`.`) as background
                    \lst@linebgrdcolor{%
                        \kern-\dimexpr\lst@linebgrdsep\relax%
                        \lst@linebgrdcmd{\lst@linebgrdwidth}{\lst@linebgrdheight}{\lst@linebgrddepth}%
                    }%
                }%
            \fi
        }

 % Heather-added packages for the fancy table
 \usepackage{longtable}
 \usepackage{booktabs}
 \usepackage{pdflscape}
 \usepackage{colortbl}%
 \newcommand{\myrowcolour}{\rowcolor[gray]{0.925}}
 \usepackage{wasysym}
 
    \makeatother

\lstset{
  language=Python,
  showstringspaces=false,
  formfeed=\newpage,
  tabsize=4,
  commentstyle=\itshape\color{light-gray},
  basicstyle=\ttfamily\scriptsize,
  morekeywords={lambda, self, assert, as, cls},
  numbers=left,
  numberstyle=\scriptsize\color{light-gray}\textsf,
  xleftmargin=2em,
  stringstyle=\color{mauve}
}
\lstdefinestyle{Bash}{
    language={}, 
    numbers=left,
    numberstyle=\scriptsize\color{light-gray}\textsf,
    moredelim=**[is][\color{blue}\bf\ttfamily]{`}{`},
}
\lstdefinestyle{OpenCL}{
	language=C++,
	morekeywords={kernel, __kernel, global, __global, size_t, get_global_id, sin, printf, int2}
}

\usepackage{float}
\floatstyle{ruled}
\newfloat{codelisting}{tp}{lop}
\floatname{codelisting}{Listing}
\setlength{\floatsep}{10pt}
\setlength{\textfloatsep}{10pt}


\usepackage{url}

\usepackage{todonotes}

\usepackage{placeins}

\usepackage{textpos}

\renewcommand\topfraction{0.85}
\renewcommand\bottomfraction{0.85}
\renewcommand\textfraction{0.1}
\renewcommand\floatpagefraction{0.85}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{bussproofs}    % Gentzen-style deduction trees *with aligned sequents!*
\usepackage{mathpartir}	% For type-settting type checking rule figures
\usepackage{syntax}		% For type-setting formal grammars.


\usepackage{hyperref}		% For links in citations

\usepackage{float}			% Make figures float if [H] option is passed.

\iffalse
\usepackage{listings}		% For typesetting code listings
\usepackage{callout}
\usepackage{titlesec}
\usepackage[T1]{fontenc}
\usepackage{upquote}
\lstset{upquote=true}
\fi

\usepackage{textcomp}		% For \textquotesingle as used in introduction
\usepackage{color}			% for box colors, like in TAPL.

\usepackage{amsmath}		% Begin Carthage default packages
\usepackage{makeidx}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{epsfig}
\usepackage{csquotes}
\usepackage{enumitem}

\newtheorem{thm}{Theorem}                                                       
\newtheorem{cor}[thm]{Corollary}                                                
\newtheorem{lem}[thm]{Lemma}                                                    
\newtheorem{prop}[thm]{Proposition}                                             
\newtheorem{ax}[thm]{Axiom}                                                     
\theoremstyle{definition}                                                       
\newtheorem{defn}[thm]{Definition}                                              
\newtheorem{exam}[thm]{Example}                                                 
\newtheorem{rem}[thm]{Remark} 

%
% For type setting inference rules with labels.
%
\newcommand{\inferlbl}[3]
			{\inferrule{#3}{#2}{\textsf{\footnotesize{\sc #1}}}}
\newcommand{\inferline}[3]
			{\inferrule{#3}{#2} & {\textsf{\footnotesize{\sc #1}}} \\ \\}

\newcommand{\Lagr}{\mathcal{L}}
\newcommand{\lang}[1]{\Lagr\{#1\}}
\newcommand{\stru}[2]{ {\tt string\_union}(#1,#2)}


\newcommand{\dconvert}[2]{ {\tt dconvert}(#1,#2) }
\newcommand{\filter}[2]{ {\tt filter}(#1,#2) }
\newcommand{\ifilter}[2]{ {\tt ifilter}(#1,#2) }

\newcommand{\reduces}{ \Rightarrow }
\newcommand{\gvd}{\Gamma \vdash }
\newcommand{\ovd}{\Omega \vdash }

\newcommand{\trep}{{\tt rep}}

\newcommand{\val}{ \ {\tt val} }
\newcommand{\ival}{ \ {\tt ival} }

\newcommand{\tstrf}[1]{`#1\textrm'} %??
\newcommand{\strf}[1]{``#1"}

%%
%% Source and Target language definitions.
%%
% Source language terms.
\newcommand{\sisubst}[3]{{\tt subst}[#1](#2,#3)}
\newcommand{\coerce}[2]{ {\tt coerce}[#1](#2)}
\newcommand{\sistr}[1]{{\tt si\_str}[#1]}
\newcommand{\strin}[1]{\sistr{#1}}
\newcommand{\siconcat}[2]{{\tt siconcat}(#1,#2)}

% Source language types.
\newcommand{\stringin}[1]{{\tt string\_in}[#1]}

% target language terms.
\newcommand{\tsubst}[3]{{\tt tsubst}(#1,#2,#3)}
\newcommand{\tcheck}[2]{{\tt tcheck}(#1, #2)}
\renewcommand{\tstr}[1]{{{\tt tstr}[#1]}}
\newcommand{\tconcat}[2]{{\tt tconcat}(#1,#2)}

% Target language types
\newcommand{\str}{{\tt string}}
\newcommand{\regext}[1]{ {\tt rx}[#1] }
\newcommand{\rx}[1]{ {\tt rx}[#1] }

% Meta-theoretic functions
\newcommand{\dosubst}[3]{{\tt dosubst}(#1,#2,#3)}
\newcommand{\lsubst}[3]{{\tt lsubst}(#1,#2,#3)}

% Judgements
\newcommand{\err}{{\tt err}}
\newcommand{\trden}[1]{[[#1]]} % = Translation Denotation.

% Relations
\newcommand{\treduces}{ \Downarrow }
\newcommand{\sreduces}{ \Downarrow }

%%
%% Constrain the size of full-page diagrams and rule lists
%%
%%\newcommand{\pagewidth}{5in}
%%\newcommand{\rulelistwidth}{3in}

% Names of type systems presented in paper
\newcommand{\lcs}{\lambda_{CS}}

\setlength{\grammarindent}{3em}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

\conferenceinfo{-}{-} 
\copyrightyear{-} 
\copyrightdata{[to be supplied]} 

%\titlebanner{{\tt \textcolor{Red}{{\small Under Review -- distribute within CMU only.}}}}        % These are ignored unless
%\preprintfooter{Distribute within CMU only.}   % 'preprint' option specified.

\newcommand{\Ace}{\textsf{Ace}}

\title{A Type System for String Sanitation\\Implemented Inside a Python}

%\authorinfo{~}{~}{~}
\authorinfo{Nathan Fulton\and Cyrus Omar\and Jonathan Aldrich}
           {School of Computer Science\\
            Carnegie Mellon University}
           {\{nfulton, comar, aldrich\}@cs.cmu.edu}

\maketitle
\begin{abstract}
%Evidence suggests that programmers are reluctant to adopt new languages to
ABSTRACT HERE
\end{abstract}

%\category{D.3.2}{Programming Languages}{Language Classifications}[Extensible Languages]
%\category{D.3.4}{Programming Languages}{Processors}[Compilers]
%\category{F.3.1}{Logics \& Meanings of Programs}{Specifying and Verifying and Reasoning about Programs}[Specification Techniques]
%\keywords
%type-level computation, typed compilation
\section{Introduction}\label{intro}
In web applications and other settings, incorrect input sanitation often causes
security vulnerabilities. In fact, ...OWASP says it's important... .
Mention CVE stats.
For this reason, modern web frameworks and libraries use various techniques to
ensure proper sanitation of arbitrary user input. On the rare occasions when
these methods are unavailable or insufficient, developers (hopefully) create 
ad hoc sanitation algorithms. Im most cases, sanitation algorithms -- ad hoc 
or otherwise -- are ultimately implemented using the language's regular
expression capabilities. Therefore, a system capable of statically 
checking properties about operations performed using regular expressions will
be expressive enough to capture real-world implementations of sanitation 
algorithms.

Input sanitation is the problem of ensuring that an arbitrary string
is coerced into a safe form before potentially unsafe use. For example, 
preventing SQL injection attacks requires ensuring that any string
coming from user input to a query does not contain unescaped SQL. 
The point at which arbitrary user input is concatenated into a SQL query is called a use site.
Although we believe are general approach extends to a wider class of problems
(e.g. sanitation algorithms for preventing XSS attacks might be definable using
regular tree languages), these generalizations are beyond the scope of the 
present paper.

This paper presents a language extension, definable in the Ace programming language,
for ensuring that input sanitation algorithms are implemented correctly with
respect to use site specifications. If use site specifications are sufficient, 
then type checking ensures the absence of vulnerabilities and other bugs which
arise from improper sanitation. Our extension focuses on sanitation algorithms 
which aim to prevent command-injection style attacks (e.g. SQL injection or RFI). 

\subsection{Related Work and Alternative Approaches}

The input sanitation problem is well-understood. There exist a large number
of techniques and technologies, proposed by both practitioners and researchers, for
preventing injection-style attacks. In this section, we defend the novelty and
significance of our approach with respect to the state of the art in practice 
and in research.

Unlike frameworks provided by languages such as Haskell and
Ruby, our type system provides a \emph{static} guarantee that input is always 
properly sanitized before use. We achieve this by defining a typing relation
which captures idiomatic sanitation algorithms. Type safety in our system relies upon 
several closure and decidability results about regular languages. 

Libraries and frameworks available in functional programming language communities often
make claims about security and sometimes even sophistically mention sophisticated
type systems as evidence of freedom from injection-style attacked.
However, even the specification that input is always sanitized properly before use is not
actually captured by the type system or anywhere else; in fact, the full specification of these
algorithms is rarely characterized by anything more specific than the type
String $\rightarrow$ String, which is a class of safe input sanitation algorithms
only in the most degenerate case.

A number of research languages provide actually static guarantees that a program
is free of input sanitation vulnerabilities. Most rely on some form of information
flow. TODO-nrf  give citations and examples. Our extension to Ace differs from
these systems in the ways following:
\begin{itemize}
  \item Our system is a light-weight solution to a single class of sanitation
  vulnerabilities (e.g. we do not address Cross-Site Scripting). We present our
  system not as a comprehensive solution to the web security problem, but rather as
  evidence that composable, light-weight and simple analyses can address security
  problems.
  \item Our system is defined as a library in terms of an extensible type system,
  as opposed to a stand-alone language. This is important for two reasons.
  First, our system is one of the first large examples written in Ace, and serves
  as an extended case study. Second, although our approach requires
  developers to adopt a new language, it does not require developers to adopt
  a language specifically for web development.
  \item Ace is implemented in Python and shares its grammar. Since Python is a 
  popular programming language among web developers, the barrier between our research
  and adopted technologies is far lower than is e.g. Ur/Web's.
  \item In general, our is a composable, light-weight and
  natural solution to a single problem -- rather than a comprehensive 
  solution to the web security problem. Our goal is to demonstrate that extensible
  type systems can capture static properties of common idioms, and thereby ensure
  safety without introducing much additional complexity.
\end{itemize}

Finally, incorporating regular expressions into the type system is not novel.
The XDuce system \cite{pierce} typechecks XML schemas using regular expressions.
We differ from this and related work in at least two ways.
First, our system  is defined within an extensible type system;
this first difference introduced an interesting class of design problems (see \S ???).
TODO-nrf this is the second time this is used as a warrant. Factor out this argument
and place it at the top???
Second, our focus on security required novel design decisions; for instance, the
filter elimination form is unique to Ace.

In conclusion, our system is novel in at least two ways:
\begin{itemize}
\item The safety guarantees provided by libraries and frameworks in popular languages
are not as (statically) justified as is often belived (or even claimed).
\item Our extension is the first major demonstration of how an extensible type
system may be used to provide light-weight, composable security analyses based upon
idiomatic code.
\end{itemize}

\subsection{Outline}

An outline of this paper follows:

TODO-nrf real outline!
\begin{itemize}
  \item In \S 2, we define the type system's static and dynamic semantics.
  \item Section 3 recalls some classical results about regular expressions and presents meta-theory for our system, including
    the main soundness theorem for $\lcs$.
  \item Finally, \S 4 discusses our implemention of $\lcs$ as a type system extension  within the Ace programming language.
\end{itemize}

\section{A Type System for String Sanitation}

The $\lcs$ language is characterized by a type of strings indexed by regular
expressions, together with operations on such strings which correspond to common
input sanitation patterns.

This section presents the grammar and semantics of $\lcs$.
The semantics are defined in terms of an internal language with at least strings and a regex filter function.
These constraints are captured by the internal term valuations ($\ival$).
The internal language does not necessarily need a regex filter function because
any dynamic conversion is easily definable using a combination of filters and safe
casting.


% Whatever just dropping this in somewhere random.
\begin{thm}
If $S : \strin{r}$ then there exists a T such that $\trden{s} = T$ and either: 
\begin{itemize}
\item (a) $T \treduces \tstr{s}$ and $S \sreduces \strin{s}$, and $s \in lang{r}$.
\item (b) $T \err$ and $S \err$.
\end{itemize}
\end{thm}
\begin{proof}
By induction on the derivation of $\trden{S} = T$. TODO-nrf add case magic.
\begin{itemize}
\item Tr-string. By assumption $\trden{S} = \tstr{s}$. The (a) property follows.
By S-E-Str, $S \sreduces \str{s}$ and by T-E-Str, $\tstr{s} \treduces \tstr{s}$.
By source language type safety, it follows that $s \in \lang{r}$.
\item Tr-Concat.
By inversion of the typing relaiton for the source lnaguage, $S_1 : \strin{r_1}$ and $S_2 : \stringin{S_2}$.
By induction on the left premise, $T_1 \treduces \tstr{s_1}$, $S_1 \sreduces \str{s_1}$ and $s_1 \in \lang{r_1}$
or else $T_1 err$. 
Similarly for $T_2$ and $S_2$.
In the error cases, the propagations rules corresponding to S-E-Concat and T-E-Concat imply that $\tconcat{T_1}{T_2} \err$ and $\siconcat{S_1}{S_2} \err$.
In the non-error case, $\siconcat{S_1}{S_2} \sreduces \strin{s_1 \cdot s_2}$ by S-E-Concat and $\tconcat{T_1}{T_2} \treduces \tstr{s_1 \cdot s_2}$ by T-E-Concat.
Finally, $s_1 \in \lang{r_1}$ and $s_2 \in \lang{r_2}$ implies that $s_1 \cdot s_2 \in \lang{r}$ by \ref{lemmaregex}.
\item T-subst.
Suppose $\sisubst{r}{S_1}{S_2} : \strin{s}$ for some $x$. 
By inverison, $S_1 : \strin{r_1}$ and $S_2 : \strin{r_2}$.
Note that $s : \subst{r}{S_1}{S_2} : \stringin{\tsubst{r}{r_1}{r_2}}$ by S-T-Subst.
By induction, $\trden{S_1} = T_1$ and $\trden{S_2} = T_2$.
Either (a) or (b) holds for each.

If (a) holds for both, the $S_1 \sreduces \strin{S_1}$ and $S_2 \sreduces \strin{S_2}$ for $s_1 \in \lang{r_1}$ and $s_2 \in \lang{r_2}$.
Therefore, $\sisubst{r}{S_1}{S_2} \sreduces \strin{\dosubst{r,s_1,s_2}}$.
The same fact can be shown in an analogous manner for $T_1$ and $T_2$.
Finally, $s_1 \in \lang{r_1}$ and $s_2 \in \lang{r_2}$, which implies that $\dosubst{r}{s_1}{s_2} \in \lang{\sisubst{r}{s_1}{s_2}}$ by \ref{substhm}.

If (b) holds for either the left or right premise, then $\sisubst{r}{S_1}{S_2} \err$ by the propagation rules corresponding to S-T-subst, 
and $\tsubst{S_1}{S_2} \err$ by the propagation rules corresponding to T-T-Subst.
\end{itemize}
\end{proof}

%
% Begin Grammar 
%

% Remove the < > from grammar productions.
\renewcommand{\grammarlabel}[2]{#1\hfill#2}

\begin{figure}
\begin{grammar}
<r> ::= $\epsilon$ | $.$ | $a$ | $r \cdot r$ | $r + r$ | $r*$ \hfill Regex ($a \in \Sigma$).

<$\psi$> ::=				\hfill	Source language types					\\
$\stringin{r}$				\hfill Regular expression types \alt

<S> ::= \hfill Source language expressions \\
      $\strin{S}$ \alt
      $\siconcat{S}{S}$ \hfill String concatenation \alt
      $\sisubst{r}{S}{S}$ \alt
      $\coerce{r}{S}$

<$\theta$> ::= \hfill Target language types \\
$\str$ \alt $\regext$

<T> ::= \hfill Internal expressions \\
  $\tstr{T}$ \alt
  $\siconcat{T}{T}$ \alt
  $\tsubst{r}{T}{T}$ \alt
  $\tcheck{r}{T}$
\end{grammar}
\caption{Syntax for the string sanitation fragment of $\lcs$}
\label{fig:lcsSyntax}
\end{figure}

%The $\lcs$ language gives static semantics for common regular expression library
%functions. In this treatment, we include concatenation and filtering.
%The ${\tt filter}$ function removes all instances of a regular expression in a string,
%while concatenation ($+$) concatenates two strings.
%
%\subsection{Typing}
%
%The $\strin[r]$ type is parameterized by regular expressions; if $e:\strin[r]$,
%then $e \in r$. Mapping from an arbitrary $\str$ to a $\strin[r]$ requires
%defining an algorithm -- in terms of filter -- for converting a $\strin[.*]$
%into a $\strin[r]$. The static semantics of the language defines the types of
%operations on regular expressions in terms of well-understood properties about
%regular lanugages; we recall these properties in section 3.
%
%\subsection{Dynamics}
%
%There are two evaluation judgements: $e:T \reduces e'$ and $e:T \treduces i$.
%The $\reduces$ relation is between $\lcs$ expressions, while the $\treduces$
%relation is a mapping from $\lcs$ expressions into internal language expressions
%$i$ such that $i \ival$.
%
%Safety of the evaluation relation depends upon an injective mapping from $\lcs$ types info
%internal language types. This relation, $h$, is defined below.
%
%\subsection{Type Safety}
%
%The type safety proof relies upon some assumptions about the type system and
%dynamics of the internal language, as well as some properties of regular
%languages.
%
%There must exist a translation from $\lcs$ types to the types of the internal
%language. For the remainder of this paper, we call the type translation function
%$h$.
%
%\begin{defn}[Type Translation Function $h$]
%  The type translation function $h : Type \rightarrow IType$ is defined as follows:
%  \begin{itemize}
%    \item $\forall r. h(\strin[r]) = istr$
%    \item $h(\str) = istr$
%  \end{itemize}
%\end{defn}
%
%Additionally, we assume that the internal language contains an implementation of strings,
%together with operations for concatenation and filtering by regular expression.
%
%\begin{defn}[Types of internal values]
%  Let $\tstrf{s}$ range over string literals and $r$ over regular expressions.
%  Internal values are typed as follows:
%\begin{itemize}
%  \item If $e=\tstrf{s}$ then $e:istr$.
%  \item If $e=\ifilter{r}{\tstrf{s}}$ then $e:istr$.
%  \item If $e=\tstrf{s_1}+\tstrf{s_2}$ then $e:istr$.
%\end{itemize}
%\end{defn}
%
%For simplicity, we assume a fixed translation from
%$\lcs$ regular expressions to regular expressions recognizable by the internal
%language's regex library (in practice, a fixed translation is acceptable.)
%To summarize, we assume an internal language containing 
%a string type together with operations for string concatentation and filtering. We
%expect closure over strings for both operations.
%Finally, recall that ${\tt ifilter}$ is only needed for dynamic casts, which may be removed without
%descreasing the expressivity or even usability of the language.
%Finally, the semantics of the filter function are defined in terms of ${\tt rl\_filter}$,
%which is a static version of ${\tt ifilter}$.
%
\subsection{Properties of Regular Languages}

The regular languages are the smallest set generated by regular expressions
defined in Figure 1.

\begin{thm}{Closure Properties.} \label{thm:closure}
The regular expressions are closed under complements and concatenation.
\end{thm}
\begin{proof}
See \cite{cinderella}.
\end{proof}

\begin{thm}{Coercion Theorem.} \label{thm:coerce}
Suppose that $R$ and $L$ are regular expressions, and that $s \in R$ is a finite string.  Let $s' := coerce(R,L,s)$ with all maximal substrings recognized by $L$ replaced with $\epsilon$.  Then $s'$ is recognized by $(R \backslash L) + \emptyset$ and the construction of $R \backslash L$ is decidable.
\end{thm}
\begin{proof}
Let $F,G$ be FAs corresponding to $R$ and $L$, and let $G'$ be $G$ with its final states inverted (so that $G'$ is the complement of $L$).  Define an FA $H$ as a DFA corresponding to the NFA found by combining $F$ and $G'$ such that $H$ accepts only if $R$ and $L'$ accept or if $s$ is empty (this construction may result in an exponential blowup in state size.)  Clearly, $H$ corresponds to $R \backslash L + \emptyset$.  Thus, the construction of $R \backslash L + \emptyset$ is decidable.

If $R \subset L$, $s' = \emptyset$.  If $L \subset R$, either $s' = \emptyset$, or $s' \in R$ and $s' \not \in L$. If $R$ and $L$ are not subsets of one another, then it may be the case that $L$ recognizes part of $R$.  Consider $L$ as the union of two languages, one which is a subset of $R$ and one which is disjoint.  The subset language is considered above and the disjoint language is inconsequential.
\end{proof}


%
% Begin typing/translation relation
%

\onecolumn
\newcommand{\sctx}{\Gamma} % Context for external typing
\newcommand{\tctx}{\Omega} % Context for internal typing

\newcommand{\ereduces}{\Downarrow}

\begin{figure}
\begin{center}
\begin{tabular}{c r}

\inferline{S-T-include}
{\sctx \vdash \strin{s} : \stringin{r}}
{s \in \lang{r}}

\inferline{S-T-Concat}
{\sctx \vdash \siconcat{S_1}{S_2} : \strin{r_1 \cdot r_2}}
{\sctx \vdash S_1 : \strin{r_1} \\ \sctx \vdash S_2 : \strin{r_2}}

\inferline{S-T-subst}
{\sctx \vdash \sisubst{r}{S_1}{S_2} : r'}
{\sctx \vdash S_1 : \strin{r_1} \\ \sctx \vdash S_2 : \strin{r_2} \\ {\tt lsubst}(r,r_1,r_2) = r'}

\inferline{S-T-coerce}
{\sctx \vdash \coerce{r'}{s} : \stringin{r'}}
{\sctx \vdash S : \stringin{r}}

\end{tabular}
\caption{Typing rules for source langauge terms (S). The metavariable s ranges over
string literals.}
\label{fig:etyping}
\end{center}
\end{figure}



\begin{figure}
\begin{center}
\begin{tabular}{c r}
\inferline{Te-Include}
{\strin{s} \val}
{ \cdot }

\inferline{S-E-Concat}
{\siconcat{S_1}{S_2} \ereduces \strin{s_1 \cdot s_2}} % ???
{S_1 \Downarrow \strin{s_1} \\ S_2 \Downarrow \strin{s_2}} 

\inferline{S-E-Subst}
{\sisubst{r}{S_1}{S_2} \ereduces s}
{S_1 \Downarrow \strin{s_1} \\ S_2 \Downarrow \strin{s_2} \\ \dosubst{r}{s_1}{s_2} = s} 

\inferline{S-E-Coerce-OK}
{\coerce{r}{S} \ereduces \strin{s}}
{S \ereduces \strin{s} \\ x \in \lang{r}}

\inferline{S-E-Coerce-NotOk}
{S \err}
{\coerce{r}{S} \ereduces \strin{s} \\ s \not \in \lang{r}}


\end{tabular}
\caption{Big step semantics for the string fragment of the source language.
There are also unmentioned error propagation rules for for S-E-Concat and S-E-Subst.}
\label{fig:eeval}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\begin{tabular}{c r}

\inferline{T-T-String}
{\tctx \vdash \tstr{s} : \str}
{\cdot}

\inferline{T-T-Concat}
{\tctx \vdash \tconcat{T_1}{T_2} : \str}
{\tctx \vdash T_1 : \str \\ \tctx \vdash T_2 : \str}

\inferline{T-T-Subst}
{\tctx \vdash \tsubst{\rx{r}}{T_1}{T_2} : \str}
{\tctx \vdash T_1 : \str \\ \tctx \vdash T_2 : \str}

\inferline{T-T-Check}
{\tctx \vdash \tcheck{\rx{r}}{s} : \str}
{\tctx \vdash T : \str}

\end{tabular}
\caption{Typing rules for target langauge terms (T). The metavariable s ranges over
string literals.}
\label{fig:etyping}
\end{center}
\end{figure}


\begin{figure}
\begin{center}
\begin{tabular}{c r}
\inferline{T-E-Str}
{\tstr{s} \treduces \str{s}}
{ \cdot }

\inferline{T-E-Include}
{\rx{r} \treduces \rx{r}}
{ \cdot }

\inferline{T-E-Concat}
{\tconcat{T_1}{T_2} \treduces \tstr{s_1 \cdot s_2}} % ???
{T_1 \treduces \tstr{s_1} \\ T_2 \treduces \tstr{s_2}} 

\inferline{T-E-Subst}
{\tsubst{r}{T_2}{T_3} \treduces \tstr{s}}
{T_1 \treduces \rx{r} \\ T_2 \treduces \tstr{s_2} \\ T_3 \treduces \tstr{s_3} \\ \dosubst{r}{s_2}{s_3} = s} 

\inferline{T-E-Check-OK}
{\tcheck{r}{T} \treduces \tstr{s}}
{T \treduces \strin{s} \\ s \in \lang{r}}

\inferline{T-E-Check-NotOk}
{T \err}
{\tcheck{r}{T} \treduces \tstr{s} \\ s \not \in \lang{r}}

\end{tabular}
\caption{Big step semantics for the target lanugage.
There are also unimplemented error propagation rules for for Te-Concat and Te-Subst.}
\label{fig:ieval}
\end{center}
\end{figure}


%
% Begin big-step sematnics for internal terms.
%

\begin{figure}
\begin{center}
\begin{tabular}{c r}

\inferline{Tr-string}
{\trden{\strin{s}} = \tstr{s}}
{ \ }

\inferline{Tr-Concat}
{\trden{\siconcat{S_1}{S_2}} = \tconcat{T_1}{T_2}}
{ \trden{S_1} = T_1 \\ \trden{S_2} = T_2}

\inferline{Tr-Subst}
{\trden{ \sisubst{r}{S_1}{S_2} } = \tsubst{\rx{r}}{T_1}{T_2} }
{ \trden{S_1} = T_1 \\ \trden{S_2} = T_2 }

\inferline{Tr-Subst}
{\trden{ \coerce{r'}{S} } = T}
{ \trden{s} = T \\ S : \strin{r} \\ \lang{r'} \subseteq \lang{r}}

\inferline{Tr-Coerce-NotOk}
{\trden{\coerce{r'}{S}} = \tcheck{\rx{r'}}{S}}
{\trden{S} = T \\ s : \strin{r} \\ \lang{r'} \not \subseteq \lang{r}}

\end{tabular}
\caption{Translation from source terms (S) to target terms (T).
The translation is type-directed in the Tr-Coerce cases.}
\end{center}
\end{figure}

\twocolumn

Note that we never insert an internal check where the type of the string implies
that a check must succeed. Furthermore, expensive calculations (such as language
inclusion or ${\tt computer\_replacement\_language}$, all occur at compile time.
Since sanitation problems are generally expressible with smalle, simple expressions,
we believe that the compile-time overhead is not significant enough to prohibiour target usecase. Informal experimentation with our implementation seems to
support this assertion.

Due to Ei-Replace, all of our meta-theory depends upon a correct implementation
of both regular expression replacement and inclusion checking in the internal language.
We believe this assumption is okay for two reasons. First, our system is still
superior to the status quo, which relies upon the correctness of these libraries
\emph{in addition to} correct application logic. Second, regular expression libraries are
generally well-tested and there exist verified implementations.

\subsection{Type Safety Proof}

\subsection{New Theorems}

\begin{thm}[Progress for Internal Language]
\end{thm}

\begin{thm}[Preservation for Internal Language]
\end{thm}


\begin{thm}[Representational Consistency]
If $\cdot \vdash e : \tau \sreduces i$ then $\cdot \vdash i : \sigma$ and $\sigma \equiv \trep(\tau)$.
\end{thm}

\begin{thm}[Main Soundness Result]
  If $\cdot \vdash e : \strin{r} \sreduces i$ then either $i \treduces \err$ or
  if $i \sreduces v$ for $v \ival$ then $v \in r$.
\end{thm}

%\begin{thm}[Preservation]
%  Let $T$ be a type in $\lcs$ and $h(T)=\sigma$ the corresponding type in the internal language.
%  For all terms $e$:
%  \begin{itemize}
%    \item If $e:T$ and $e:T \treduces i$ then $i : \sigma$ such that $h(T) = \sigma$.
%    \item If $e:T$ and $e:T \reduces e'$ then $e':T$.
%  \end{itemize}
%\end{thm}
%\begin{proof}
%The proof is a straightforward induction on the derivation of the combined evaluation relation.
%\begin{itemize}[label=$ $,itemsep=1ex]
%  \item \textbf{E-Ival, E-Ifilterval}. Both cases hold since the terms at hand are not $\lcs$ terms.
%  \item \textbf{E-Stringval, E-strval}. Both cases hold since no reduction is possible. 
%  \item \textbf{E-String}. By the definition of typing for internal terms, $\tstrf{e} : istr$. It suffices to show that $h(\str) = istr$, which follows from the definition of $h$.
%  \item \textbf{E-String\_in}. By the definition of typing for internal terms, $\tstrf{e} : istr$. It suffices to show that $h(\strin[r]) = istr$, which follows from the definition of $h$ for arbitrary $r$.
%  \item \textbf{E-concatval}. By the definition of typing for internal terms, $\tstrf{e_1} + \tstrf{e_2} : istr$. So it suffices to show that $h(\strin[r_1+r_2]) = istr$, which follows from the definition of $h$ for arbitrary $r_1$, $r_2$.
%  \item \textbf{E-concatR, E-concatL}. Consider E-concatR. By induction, $e_1' : \strin{l_1}$. By inversion of T-Concat at the premise, $e_2 : \strin{r_2}$. Therefore, $e_1 + e_2 : \strin[r_1 + r_2]$. The left rule is symmetric.
%  \item \textbf{E-Filterval}. We have that $\filter{\strin[r']}{e}:\strin[r\backslash r' + \emptyset]$. By inversion of T-Filter, $e:\strin[r]$.
%    By T-Equiv-string\_in (which is bidirectional), $e \in \lang{r}$.
%    By the Coercion Theorem, ${\tt rl\_filter}(r,e) \in \lang{r\backslash r' + \emptyset}$.
%    By T-Equiv-string\_in,  $e \in \lang{r}$ and ${\tt rl\_filter}(r,e) \in \lang{r\backslash r' + \emptyset}$ implies ${\tt rl\_filter}(r,e):\strin[r\backslash r' + \emptyset]$.
%  \item \textbf{E-Filter}. By inversion, $e : \strin[r']$ $\reduces e'$ so by the induction $e':\strin[r']$.
%    Therefore, \\${\tt filter}(\strin[r], e'):$ $\strin[r \backslash r' + \emptyset]$ by T-Filter.
%  \item \textbf{E-Convertval}. It suffices to show that $h(\strin[r]) = istr$, which is true by definition.
%  \item \textbf{E-Convert}. By inversion and induction, $e' : \strin[r]$. We know that $[\strin[r']](e) : \strin[r']$, so by inversion of T-Convert $\lang{r'} \subseteq \lang{r}$.
%    It follows that $[\strin[r']](e') : \strin[r']$.
%  \item \textbf{E-DConvert}. By inversion, $e : \strin[r'] \reduces e'$. By the induction hypothesis, $e' : \strin[r']$; therefore, by T-Dconvert, $\dconvert[\strin[r]](e):\strin[r]$.
%  \item \textbf{E-DConvertval}. By the definition of typing for internal terms, $\ifilter(r,\tstrf{e}) : istr$. It suffices to show that $h(\strin[r_1+r_2]) = istr$, which follows from the definition of $h$.
%\end{itemize}
%\end{proof}
%
%\begin{thm}[Progress]
%  If $e:T$ then $e:T \reduces^* e' \treduces^* i$ where $i \ival$.
%\end{thm}
%\begin{proof}
%By induction on the derivation of $e:T$.
%For \textbf{T-Equiv-Include}, note that $e \in \lang{r}$, $e = \strf{s}$ for some $s$; therefore, $e \val$ by E-Strinval. 
%We have that $e \val$ and $e : \strin[r]$, so $e \treduces \tstrf{e}$ by E-string\_in.
%The remaining cases follow by induction on the hypotheses and application of corresponding evaluation rules.
%\end{proof}
%
\section{Implementation Inside a Python}
%
%TODO-nrf rewrite
%The $\lcs$ language is implemented as a type system extension in Ace; this extension
%is illustrated in the examples at the beginning of this paper.
%
%Computing a regular expression representating the language
%$R \backslash S$ is necessary in order to type-check expressions in which the filter function
%occurs. This language is computed by translating $R$ and $S$ into finite automata,
%complementing the final states of $S$, then constructing the cross-product of $R$
%and $S'$. Type checking terminates only because this construction is decidable.
%
%In addition to this construction, other more typical operations -- such
%as equality checks for regular expressions and regular expression matching -- are
%also necessary. For these reasons, the Ace extension implementing $\lcs$ includes a library
%implementing each of these constructions.
\newcommand{\F}[1]{\textsf{#1}~}
\newcommand{\FF}[1]{\textsf{#1}}
\newcommand{\Q}{\FF{Arg}}
\newcommand{\xlA}[1]{\lfloor #1 \rfloor_{\lamAce}}
\newcommand{\xA}[1]{$\lfloor #1 \rfloor_{\texttt{ace}}$}
\begin{figure*}
\begin{tabular}{ l r l l }
$\tau$ & & $\xlA{\tau}$ & \xA{\tau}\\
\hline
$\strin{r}$ & & $\fvar{stringin}[r]$ & \verb|string_in["|$r$\verb|"]|\\
\\
  $e$ & & $\xlA{e}$ & \xA{e}\\
  \hline
  ${\tt str}[r, s]$ & \text{synthetic position} & $\FF{intro}[\FF{str}[s]]()$ : \fvar{stringin}[\FF{rx}[$r$]] & \verb|"|$s$\verb|" (string_in["|$r$\verb|"])|\\
  & \text{analytic position} & $\FF{intro}[\FF{str}[s]]()$ & \verb|"|$s$\verb|"|\\
  ${\tt concat}(e_1; e_2)$ & & $\xlA{e_1}\cdot\FF{elim}[\tvar{concat}](\xlA{e_2})$ & \xA{e_1}\verb| + |\xA{e_2} \\
  ${\tt replace}[r](e_1; e_2)$ & & $\xlA{e_1}\cdot\FF{elim}[\tvar{replace}~\FF{rx}[r]](\xlA{e_2})$ & \xA{e_1}\verb|.replace("|$r$\verb|", |\xA{e_2}\verb|)|\\
  ${\tt coerce}[r](e)$ & & $\xlA{e}\cdot\FF{elim}[\tvar{coerce}~\FF{rx}[r]]()$ & \xA{e}\verb|.coerce("|$r$\verb|")|
\end{tabular}
\caption{Translation of $\lcs$ to $\lamAce$ and Ace.}
\end{figure*}
\begin{figure}
\small\begin{flalign}
& \F{tycon}\fvar{stringin}~\F{of}\FF{R}~\{\\
& \quad \F{iana}\{\tlam{opidx}{\FF{String}}{
	\tlam{tyidx}{\FF{R}}{
	\tlam{a}{\klist{\Q}}{\\
& \quad\quad \tvar{arity0}~\tvar{a}~(\tvar{check}~\tvar{opidx}~\tvar{tyidx}~\titerm{\iup{\tvar{opidx}}})
	}}
}\}\\
& \quad \F{esyn}\{\tlam{opidx}{\kunit+(\FF{R}+\FF{R})}{
	\tlam{a}{\klist{\Q}}{\\
& \quad\quad \tsumcase{\tvar{opidx}}{\_}{\\
& \quad\quad\quad \tvar{arity2}~\tvar{a}~\tlam{a1}{\Q}{\tlam{a2}{\Q}{\\
& \quad\quad\quad\quad \tvar{rsyn}~\tvar{a1}~\tlam{r1}{\FF{R}}{\tlam{i1}{\kITerm}{~}}\\
& \quad\quad\quad\quad \tvar{rsyn}~\tvar{a2}~\tlam{r2}{\FF{R}}{\tlam{i2}{\kITerm}{~}}\\
& \quad\quad\quad\quad\quad (\ttype{stringin}{\FF{rseq}(\tvar{r1}; \tvar{r2})}, \\
& \quad\quad\quad\quad\quad\titerm{{\tt iconcat}(\iup{\tvar{i1}}; \iup{\tvar{i2}})})
}}\\
& \quad\quad}{opidx'}{d}}
}\}
\}
\end{flalign}
\caption{Definition of ...}
\end{figure}
\begin{figure}
\[
\begin{array}{lcl}
% & & Definition & Kind\\
\tvar{concat} & := & \tinl{\kunit, R+R}{b}\\%& \kunit + (R + R)\\
\tvar{replace} & := & \tlam{r}{R}{\tinr{\kunit, R+R}{\tinl{R,R}{\tvar{r}}}}\\% & \karrow{a}{b}\\
\tvar{coerce} & := & \tlam{r}{R}{\tinr{\kunit, R+R}{\tinr{R,R}{\tvar{r}}}}\\
\end{array}
\]
\caption{Definitions}
\end{figure}

\subsection{Background: Ace}
TODO: Make a TR out of the OOPSLA submission.
\subsection{Explicit Conversions}
\subsection{Adding Subtyping to Ace}
\subsection{Theory}

\section{Related Work}

\section{Discussion}


\bibliographystyle{abbrv}

% The bibliography should be embedded for final submission.

\bibliography{../research}
%\softraggedright
%P. Q. Smith, and X. Y. Jones. ...reference text...


\end{document}
