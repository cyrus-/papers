\documentclass[9pt]{sig-alternate}
\newcommand{\lamAce}{\lambda_{\text{Ace}}}
% The following \documentclass options may be useful:
%
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.
\usepackage{afterpage}
\usepackage{listings}
\usepackage[usenames,dvipsnames]{color}
\usepackage{mathpartir}
\usepackage{amsmath}
\usepackage{amssymb} 

% Hack. Something's wrong with PLAS paper when using the ACM Proc docclass
\let\proof\relax
\let\endproof\relax
\usepackage{amsthm}

\usepackage{ stmaryrd }
\usepackage{verbatimbox}
\input{../att-icfp14/macros-atlam}
\usepackage{alltt}
\renewcommand{\ttdefault}{txtt}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{light-gray}{gray}{0.5}
\usepackage{listings}
\usepackage{wasysym}
    \makeatletter
\usepackage{enumitem}
\usepackage{enumerate}

% \btIfInRange{number}{range list}{TRUE}{FALSE}
%
% Test if int number <number> is element of a (comma separated) list of ranges
% (such as: {1,3-5,7,10-12,14}) and processes <TRUE> or <FALSE> respectively
%
        \newcount\bt@rangea
        \newcount\bt@rangeb

        \newcommand\btIfInRange[2]{%
            \global\let\bt@inrange\@secondoftwo%
            \edef\bt@rangelist{#2}%
            \foreach \range in \bt@rangelist {%
                \afterassignment\bt@getrangeb%
                \bt@rangea=0\range\relax%
                \pgfmathtruncatemacro\result{ ( #1 >= \bt@rangea) && (#1 <= \bt@rangeb) }%
                \ifnum\result=1\relax%
                    \breakforeach%
                    \global\let\bt@inrange\@firstoftwo%
                \fi%
            }%
            \bt@inrange%
        }

        \newcommand\bt@getrangeb{%
            \@ifnextchar\relax%
            {\bt@rangeb=\bt@rangea}%
            {\@getrangeb}%
        }

        \def\@getrangeb-#1\relax{%
            \ifx\relax#1\relax%
                \bt@rangeb=100000%   \maxdimen is too large for pgfmath
            \else%
                \bt@rangeb=#1\relax%
            \fi%
        }

%
% \btLstHL{range list}
%
        \newcommand{\btLstHL}[1]{%
            \btIfInRange{\value{lstnumber}}{#1}%
            {\color{black!10}}%
            {\def\lst@linebgrd}%
        }%

%
% \btInputEmph[listing options]{range list}{file name}
%
        \newcommand{\btLstInputEmph}[3][\empty]{%
            \lstset{%
                linebackgroundcolor=\btLstHL{#2}%
                \lstinputlisting{#3}%
            }% \only
        }


        
% Patch line number key to call line background macro
        \lst@Key{numbers}{none}{%
            \def\lst@PlaceNumber{\lst@linebgrd}%
            \lstKV@SwitchCases{#1}{%
                none&\\%
                left&\def\lst@PlaceNumber{\llap{\normalfont
                \lst@numberstyle{\thelstnumber}\kern\lst@numbersep}\lst@linebgrd}\\%
                right&\def\lst@PlaceNumber{\rlap{\normalfont
                \kern\linewidth \kern\lst@numbersep
                \lst@numberstyle{\thelstnumber}}\lst@linebgrd}%
            }{%
                \PackageError{Listings}{Numbers #1 unknown}\@ehc%
            }%
        }

% New keys
        \lst@Key{linebackgroundcolor}{}{%
            \def\lst@linebgrdcolor{#1}%
        }
        \lst@Key{linebackgroundsep}{0pt}{%
            \def\lst@linebgrdsep{#1}%
        }
        \lst@Key{linebackgroundwidth}{\linewidth}{%
            \def\lst@linebgrdwidth{#1}%
        }
        \lst@Key{linebackgroundheight}{\ht\strutbox}{%
            \def\lst@linebgrdheight{#1}%
        }
        \lst@Key{linebackgrounddepth}{\dp\strutbox}{%
            \def\lst@linebgrddepth{#1}%
        }
        \lst@Key{linebackgroundcmd}{\color@block}{%
            \def\lst@linebgrdcmd{#1}%
        }

% Line Background macro
        \newcommand{\lst@linebgrd}{%
            \ifx\lst@linebgrdcolor\empty\else
                \rlap{%
                    \lst@basicstyle
                    \color{-.}% By default use the opposite (`-`) of the current color (`.`) as background
                    \lst@linebgrdcolor{%
                        \kern-\dimexpr\lst@linebgrdsep\relax%
                        \lst@linebgrdcmd{\lst@linebgrdwidth}{\lst@linebgrdheight}{\lst@linebgrddepth}%
                    }%
                }%
            \fi
        }

 % Heather-added packages for the fancy table
 \usepackage{longtable}
 \usepackage{booktabs}
 \usepackage{pdflscape}
 \usepackage{colortbl}%
 \newcommand{\myrowcolour}{\rowcolor[gray]{0.925}}
 \usepackage{wasysym}
 
    \makeatother

\lstset{
  language=Python,
  showstringspaces=false,
  formfeed=\newpage,
  tabsize=4,
  commentstyle=\itshape\color{light-gray},
  basicstyle=\ttfamily\scriptsize,
  morekeywords={lambda, self, assert, as, cls},
  numbers=left,
  numberstyle=\scriptsize\color{light-gray}\textsf,
  xleftmargin=2em,
  stringstyle=\color{mauve}
}
\lstdefinestyle{Bash}{
    language={}, 
    numbers=left,
    numberstyle=\scriptsize\color{light-gray}\textsf,
    moredelim=**[is][\color{blue}\bf\ttfamily]{`}{`},
}
\lstdefinestyle{OpenCL}{
	language=C++,
	morekeywords={kernel, __kernel, global, __global, size_t, get_global_id, sin, printf, int2}
}

\usepackage{float}
\floatstyle{ruled}
\newfloat{codelisting}{tp}{lop}
\floatname{codelisting}{Listing}
\setlength{\floatsep}{10pt}
\setlength{\textfloatsep}{10pt}


\usepackage{url}

%\usepackage{todo}
%\usepackage[subject={Todo},author={Josef}]{pdfcomment}
%\usepackage{cooltooltips}
\newcommand{\todo}[1]{{\color{red} #1}}
\usepackage{placeins}

\usepackage{textpos}

\renewcommand\topfraction{0.85}
\renewcommand\bottomfraction{0.85}
\renewcommand\textfraction{0.1}
\renewcommand\floatpagefraction{0.85}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{bussproofs}    % Gentzen-style deduction trees *with aligned sequents!*
\usepackage{mathpartir}	% For type-settting type checking rule figures
\usepackage{syntax}		% For type-setting formal grammars.


\usepackage{hyperref}		% For links in citations

\usepackage{float}			% Make figures float if [H] option is passed.

\iffalse
\usepackage{listings}		% For typesetting code listings
\usepackage{callout}
\usepackage{titlesec}
\usepackage[T1]{fontenc}
\usepackage{upquote}
\lstset{upquote=true}
\fi

\usepackage{textcomp}		% For \textquotesingle as used in introduction
\usepackage{color}			% for box colors, like in TAPL.

\usepackage{amsmath}		% Begin Carthage default packages
\usepackage{makeidx}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphics}
\usepackage{enumerate}
\usepackage{multicol}
\usepackage{epsfig}
\usepackage{csquotes}
\usepackage{enumitem}

\newtheorem{thm}{Theorem}                                                       
\newtheorem{cor}[thm]{Corollary}                                                
\newtheorem{lem}[thm]{Lemma}                                                    
\newtheorem{prop}[thm]{Proposition}                                             
\newtheorem{ax}[thm]{Axiom}                                                     
\theoremstyle{definition}                                                       
\newtheorem{defn}[thm]{Definition}                                              
\newtheorem{exam}[thm]{Example}                                                 
\newtheorem{rem}[thm]{Remark} 
\renewcommand*{\proofname}{Proof Sketch}

%
% For type setting inference rules with labels.
%
\newcommand{\inferlbl}[3]
			{\inferrule{#3}{#2}{\textsf{\footnotesize{\sc #1}}}}
\newcommand{\inferline}[3]
			{\inferrule{#3}{#2} & {\textsf{\footnotesize{\sc #1}}} \\ \\}

\newcommand{\Lagr}{\mathcal{L}}
\newcommand{\lang}[1]{\Lagr\{#1\}}
\newcommand{\stru}[2]{ {\tt string\_union}(#1,#2)}


\newcommand{\dconvert}[2]{ {\tt dconvert}(#1,#2) }
\newcommand{\filter}[2]{ {\tt filter}(#1,#2) }
\newcommand{\ifilter}[2]{ {\tt ifilter}(#1,#2) }

\newcommand{\reduces}{ \Rightarrow }
\newcommand{\gvd}{\Gamma \vdash }
\newcommand{\ovd}{\Omega \vdash }

\newcommand{\trep}{{\tt rep}}

\newcommand{\tstrf}[1]{`#1\textrm'} %??
\newcommand{\strf}[1]{``#1"}


\newcommand{\iso}{\cong}
%%
%% Source and Target language definitions.
%%
\newcommand{\lambdas}{\lambda_{RS}}
\newcommand{\lambdap}{\lambda_P}

% Source language terms.
\newcommand{\sisubst}[3]{{\sf rreplace}[#1](#2;#3)} \newcommand{\rreplace}[3]{{\sf rreplace}[#1](#2;#3)} % lots of legacy naming around these parts...

\newcommand{\rssreplace}[3]{\sisubst{#1}{#2}{#2}} % TODO-nrf fix this.

\newcommand{\coerce}[2]{ {\sf rcoerce}[#1](#2)}
\newcommand{\rcoerce}[2]{{\sf rcoerce}[#1](#2)}
\newcommand{\sistr}[1]{{\sf rstr}[#1]}   \newcommand{\rstr}[1]{{\sf rstr}[#1]} % Lots of legacy naming around these parts...

\newcommand{\val}{{\sf val}}

\newcommand{\rcheck}[4]{ {\sf rcheck}[#1](#2;#3;#4) }


\newcommand{\strin}[1]{\sistr{#1}}
\newcommand{\rsconcat}[2]{{\sf rconcat}(#1;#2)} \newcommand{\rconcat}[2]{{\sf rconcat}(#1;#2)} % lots of legact naming around these parts..

% Source language types.
\newcommand{\stringin}[1]{{\sf stringin}[#1]}

% target language terms.
\newcommand{\tsubst}[3]{{\sf replace}(#1;#2;#3)} \newcommand{\metareplace}[3]{{\sf replace}(#1;#2;#3)} % TODO-nrf rename the commands. Lots of legacy naming around these parts...

\newcommand{\tcheck}[4]{{\sf check}(#1; #2; #3; #4)}
\renewcommand{\tstr}[1]{{{\sf str}[#1]}}
\newcommand{\preplace}[3]{{\sf preplace}(#1;#2;#3)}
\newcommand{\tconcat}[2]{{\sf concat}(#1;#2)} \newcommand{\concat}[2]{{\sf concat}(#1;#2)} % lots of legacy naming around these parts...

\newcommand{\regext}[1]{ {\sf rx}[#1] } % TODO-nrf remove
\newcommand{\rx}[1]{ {\sf rx}[#1] }

% Target language types
\newcommand{\str}{{\sf string}}
\newcommand{\regex}{{\sf regex}}

% Meta-theoretic functions
\newcommand{\lsubst}[3]{{\sf subst}(#1;#2;#3)} % This used to renderlreplace(...) so there're probably mistkes wherever this command was used now.
\newcommand{\lreplace}[3]{{\sf lreplace}(#1; #2; #3)}

\newcommand{\sctx}{\Psi} % Context for external typing
\newcommand{\tctx}{\Theta} % Context for internal typing
\newcommand{\ereduces}{\Downarrow}


\newcommand{\strcase}[3]{ {\sf rstrcase}(#1; #2; #3)}
\newcommand{\pstrcase}[3]{ {\sf pstrcase}(#1; #2; #3)}

\newcommand{\lhead}[1]{ {\sf lhead}(#1) }
\newcommand{\ltail}[1]{ {\sf ltail}(#1) }


% Judgements
\newcommand{\trden}[1]{\llbracket #1 \rrbracket} % = Translation Denotation.

% Relations
\newcommand{\treduces}{ \Downarrow }
\newcommand{\sreduces}{ \Downarrow }

%%
%% Constrain the size of full-page diagrams and rule lists
%%
%%\newcommand{\pagewidth}{5in}
%%\newcommand{\rulelistwidth}{3in}

% Names of type systems presented in paper
\newcommand{\lcs}{\lambda_{S}}

\setlength{\grammarindent}{3em}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{document}

%dep_docclass\conferenceinfo{-}{-} 
%dep_docclass\copyrightyear{-} 
%dep_docclass\copyrightdata{[to be supplied]} 

%\titlebanner{{\tt \textcolor{Red}{{\small Under Review -- distribute within CMU only.}}}}        % These are ignored unless
%\preprintfooter{Distribute within CMU only.}   % 'preprint' option specified.

\newcommand{\Ace}{\textsf{Ace}}

\title{Statically Typed String Sanitation Inside a Python}
\numberofauthors{3}
\author{
  \alignauthor
  Nathan Fulton
  \alignauthor
  Cyrus Omar
  \alignauthor
  Jonathan Aldrich
  \and
  \affaddr{Carnegie Mellon University}\\
  \affaddr{Pittsburgh, PA}\\
  \email{\{nathanfu, comar, aldrich\}@cs.cmu.edu}
}
%\authorinfo{~}{~}{~}
%\authorinfo{Nathan Fulton\and Cyrus Omar\and Jonathan Aldrich}
 %          {School of Computer Science\\
  %          Carnegie Mellon University
   %        \{nathanfu, comar, aldrich\}@cs.cmu.edu}

\maketitle
\begin{abstract}
%Evidence suggests that programmers are reluctant to adopt new languages to
Web applications must ultimately command systems like web browsers and database engines using strings. Strings derived from improperly sanitized user input  can thus be a vector for command injection attacks. %Structured frameworks for constructing commands centralizes control over string sanitization, but verifying that the framework itself sanitizes user input correctly can still be tricky.
In this paper, we introduce \emph{regular string types}, which classify strings known statically to be in a specified regular language. These types come equipped with common operations like concatenation, substitution and coercion, so they  can be used to implement, in essentially a conventional manner, the portions of a web application or web application framework that must directly construct command strings. Simple type annotations at key interfaces can be used to statically verify that sanitization has been performed correctly without introducing redundant run-time checks. We specify this type system as a minimal typed lambda calculus, $\lambda_{RS}$.

To be practical, adopting a specialized type system like this should not require the adoption of a new programming language. Instead, we advocate for extensible type systems: new type system fragments like this should be implemented as libraries atop a mechanism that guarantees that they can be safely composed.  We support this by 1) specifying a translation from $\lambda_{RS}$ to a language containing only strings and regular expressions, then, taking Python as such a language, 2) implementing the type system together with the translation as a library using \texttt{atlang}, an extensible static type system for Python (being developed by the authors).% represents the most sophisticated application of this library to date.

% Security-oriented programming languages do not enjoy wide adoption. Conversely, library and framework-based approaches to security are pervasive. Unfortunately, libraries and frameworks are only effective solutions if they are implemented and used properly. In this paper, we propose that extensible programming languages provide a promising mechanism for increasing the amount of trust that can be place in libraries and frameworks. To demonstrate this approach, we present a conservative extension to the simply-typed lambda calculus for checking the correctness of input sanitation algorithms. We also demonstrate how this language's security guarantees are preserved under translation into an underlying language containing a regular expression library. We believe this approach -- complementing existing techniques with light-weight, composable type-based analyses -- constitutes a promising compromise between usability, potential for industry adoption, and theoretically grounded safety guarantees.
\end{abstract}

%\category{D.3.2}{Programming Languages}{Language Classifications}[Extensible Languages]
%\category{D.3.4}{Programming Languages}{Processors}[Compilers]
%\category{F.3.1}{Logics \& Meanings of Programs}{Specifying and Verifying and Reasoning about Programs}[Specification Techniques]
%\keywords
%type-level computation, typed compilation
\section{Introduction}\label{intro}
Command injection vulnerabilities are among the most common and severe security vulnerabilities in modern web applications \cite{OWASP}. They arise because web applications, at their boundaries, control external systems using commands represented as  strings. For example, web browsers are controlled using HTML and Javascript sent from a server as a string, and database engines execute SQL queries also sent as strings. When these commands include data derived from user input, care must be taken to ensure that the user cannot  subvert the intended command by carefully crafting the data they send. For example, a  SQL query constructed using string concatenation exposes a SQL injection vulnerability: 
\begin{lstlisting}[numbers=none]
'SELECT * FROM users WHERE name="' + name + '"'
\end{lstlisting}
If a malicious user enters the name \lstinline{'"; DROP TABLE users --'}, the entire database could be erased. 

To avoid this problem, the program must \emph{sanitize} user input. For example, in this case, the developer (or, more often, a framework) might define a function \verb|sanitize| that escapes double quotes and existing backslashes   with a backslash, which SQL treats safely. Alternatively, it might HTML-encode special characters, which would head off both SQL injection attacks and cross-site scripting attacks. Guaranteeing that user input has already been sanitized  before it is used to construct a command is challenging, because  sanitation is often performed in a different part of the code than the place where commands are ultimately constructed.% Note, for example, that \verb|sanitize| is not idempotent, so it should only be called once.

We observe that many such sanitization techniques can be understood using \emph{regular languages} \cite{cinderella}. For example, \verb|name| must be a string in the language described by the regular expression \verb!([^"\]|(\")|(\\))*! -- a sequence of characters other than quotation marks and backslashes; these can only appear escaped. This concrete syntax for regular expression patterns can be understood to desugar, in a standard way, to the syntax for regular expressions shown in Figure \ref{fig:regex}, where $r \cdot r$ is sequencing and $r + r$ is  disjunction. We will work with this ``core'' for simplicity.

In this paper, we present a static type system that tracks the regular language a string belongs to. For example, the output of \verb|sanitize| will be a string in the regular language described by the regular expression above (we identify regular languages by the notation $\mathcal{L}\{r\}$). By leveraging closure and decidability properties of regular languages, the type system tracks the language of a string through uses of a number of operations, including \emph{replacement} of substrings matching a given pattern. This makes it possible to implement sanitation functions like the one just described in an essentially conventional manner. The result is a system where the fact that a string has been {correctly} sanitized is manifest in its type. Missing calls to sanitization functions are detected statically, and, importantly, so are \emph{incorrectly implemented sanitization functions} (i.e. these functions need not be trusted). These guarantees require run-time checks only when going from less precise to more precise types (e.g. at the edges of the system). %implementing and statically checking input sanitation techniques. Our solution suggests a more general approach to the integration of security concerns into programming language design. This approach is characterized by \emph{composable} type system extensions which \emph{complement} existing and well-understood solutions with compile-time checks.

We will begin in Sec. \ref{calculus} by specifying this type system minimally, as a conservative extension of the simply typed lambda calculus called $\lambdas$. This allows us to specify the guarantees that the type system provides precisely. We also formally specify a translation from this calculus to a typed calculus with only standard strings and regular expressions, intending it as a guide to language implementors interested in building this feature into their own languages. This also demonstrates that no additional space overhead is required.

Waiting for a language designer to build this feature in is unsatisfying in practice. Moreover, we also face a ``chicken-and-egg problem'': justifying its inclusion into a commonly used language benefits from empirical demonstrations that it is useful, but this is difficult to do if developers have no way to use it in practice. As such, we take the position that a better path forward for the community is to work within a programming language where such type system fragments can be introduced modularly and orthogonally, as libraries. 

In Sec. \ref{atlang}, we show how to implement the type system fragment we have specified  using \texttt{atlang}, an extensible static type system implemented as a library inside Python. \texttt{atlang} leverages local type inference to control the semantics of literal forms, so reguar string types can be introduced using string literals without any run-time overhead. Coercions that are known to be  safe due to a sublanguage relationship are performed implicitly, also without run-time overhead. This results in a \emph{usably secure} system: working with regular strings differs little from working with standard strings in a language that web developers have already widely adopted.

We conclude after discussing related work in Sec. \ref{related}.

\section{Regular String Types, Minimally}\label{calculus}
\noindent
%This will serve as the source language for our translation to a calculus with only standard strings and regular expressions, defined in Section~\ref{sec:tr}. 
This section is organized as follows:
\begin{itemize}
\item Section \ref{sec:rs} describes $\lambda_{RS}$. We also give proof outlines of  type safety and correctness theorems and relevant propositions about regular languages.
\item Section \ref{sec:p} describes a simple target language, $\lambdap$, with a minimal regular expression library. In Section \ref{atlang}, we will take Python to be such a language.
\item Section \ref{sec:tr} describes the translation from $\lambdas$ to $\lambdap$ and ensures the correcness result for \ref{sec:rs} is preserved under translation. 
\end{itemize}

\subsection{The Language of Regular Strings}\label{sec:rs}
In this section, we define a minimal typed lambda calculus with regular string types called $\lambda_{RS}$. The syntax of $\lambda_{RS}$ is specified in Figure \ref{fig:glambdas}, its static semantics in Figure \ref{fig:slambdas} and its evaluation semantics in Figure \ref{fig:dlambdas}.\footnote{For convenience, a single sheet containing Figures \ref{fig:glambdas}-\ref{fig:tr} is available at http://nfulton.org/strings/printout.pdf.}

There are two type constructors in $\lambdas$, $\rightarrow$ and $\textsf{stringin}$. Arrow types classify functions, which are introduced via lambda abstraction, $\lambda x.e$, and can be applied, written $e(e)$, in the usual way \cite{pfpl}. Regular string types are of the form $\stringin{r}$, where $r$ is a regular expression. Values of such regular string types take the form $\strin{s}$, where $s$ is a string (i.e. $s \in \Sigma^\star$, defined in the usual way). The rule \textsc{S-T-Stringin-I} statically guarantees that $s \in \lang{r}$.
 %The remaining operations on terms of type $\stringin{r}$ preserve this property. %The remaining operators operate on regular strings.


$\lambdas$ provides several familiar operations on strings. The type system  relates these operations over strings to corresponding operations over the  regular languages they belong to. 
Since these operations over regular languages are known to be closed and decidable, we can use these operations as a basis for static analysis of sanitation protocols (we will see a concrete example in Section \ref{atlang}).

%This section describes our approach, culminating in a Security Theorem. The main technical result of this paper shows that this Security Theorem is preserved when $\lambdas$ is translated to a more traditional language. Throughout this section, we refer to \textsc{Inference Rules} defined in the figures contained in this section.
%\todo{remove tranditional, most and improve description}

%In this section, we define $\lambdas$, describe each operation, and finally prove both type safety and a correctness result for the language.
%The grammar for $\lambdas$ is defined in Figure \ref{fig:glambdas}. Typing rules \textsc{S-T-} are defined in Figure \ref{fig:slambdas} and a big-step semantics
%is defined in Figure \ref{fig:dlambdas}



\renewcommand{\grammarlabel}[2]{#1\hfill#2}
\begin{figure}[h]
\begin{grammar}
<$r$> ::= $\epsilon$ | $.$ | $a$ | $r \cdot r$ | $r + r$ | $r*$ \hfill $a \in \Sigma$

\caption{Regular expressions over the alphabet $\Sigma$.}
\label{fig:regex}
\end{grammar}
\end{figure}

\begin{figure}[h]
\begin{grammar}

<$\sigma$> ::=  $\sigma \rightarrow \sigma$     \hfill  source types          \alt
$\stringin{r}$         

<$e$> ::= 
      $x$ \hfill source terms \alt 
      $\lambda x . e$ \alt
      $e(e)$ \alt
      $\strin{s}$ \hfill $s \in \Sigma^{*}$ \alt
      $\rsconcat{e}{e}$ \alt
      $\strcase{e}{e}{x,y.e}$ \alt
      $\sisubst{r}{e}{e}$ \alt
      $\rcoerce{r}{e}$ \alt
      $\rcheck{r}{e}{x.e}{e}$

<$v$> ::= $\lambda x . e$ \hfill source values \alt
          $\strin{s}$ \hfill $s \in \Sigma^{*}$


      
\caption{Syntax of $\lambda_{RS}$.}
\label{fig:glambdas}
\end{grammar}
\end{figure}


\begin{figure}[h]
\small
$\fbox{\inferrule{}{\sctx \vdash e : \sigma}}$
~~~~$\sctx ::= \emptyset \pipe \sctx, x : \sigma$
\begin{mathpar}
\inferrule[S-T-Var]
{ x:\sigma \in \sctx }
{ \sctx \vdash x:\sigma}

\inferrule[S-T-Abs]
{\sctx, x : \sigma_1 \vdash e : \sigma_2}
{\sctx \vdash \lambda x.e : \sigma_1 \rightarrow \sigma_2}

\inferrule[S-T-App]
{\sctx \vdash e_1 : \sigma_2 \rightarrow \sigma \\ \sctx \vdash e_2 : \sigma_2}
{\sctx \vdash e_1(e_2) : \sigma}
  
\inferrule[S-T-Stringin-I]
{s \in \lang{r}}
{\sctx \vdash \strin{s} : \stringin{r}}

\inferrule[S-T-Concat]
{\sctx \vdash e_1 : \stringin{r_1} \\ \sctx \vdash e_2 : \stringin{r_2}}
{\sctx \vdash \rsconcat{e_1}{e_2} : \stringin{r_1 \cdot r_2}}

\inferrule[S-T-Case]
{ \sctx \vdash e_1 : \stringin{r} \\
  \sctx \vdash e_2 : \sigma \\
  \sctx, x : \stringin{\lhead{r}}, y : \stringin{\ltail{r}} \vdash e_3 : \sigma
}
{
  \sctx \vdash \strcase{e_1}{e_2}{x.y.e_3} : \sigma
}

\inferrule[S-T-Replace]
{\sctx \vdash e_1 : \stringin{r_1} \\ \sctx \vdash e_2 : \stringin{r_2} \\\\ \lreplace{r}{r_1}{r_2} = r'}
{\sctx \vdash \sisubst{r}{e_1}{e_2} : \stringin{r'}}

\inferrule[S-T-SafeCoerce]
{\sctx \vdash e : \stringin{r'} \\ \lang{r'} \subseteq \lang{r}}
{\sctx \vdash \coerce{r}{e} : \stringin{r}}

\inferrule[S-T-Check]
{\sctx \vdash e_0 : \stringin{r_0} \\ \sctx, x:\stringin{r} \vdash e_1 : \sigma \\ \sctx \vdash e_2 : \sigma}
{\sctx \vdash \rcheck{r}{e_0}{x.e_1}{e_2} : \sigma}

\end{mathpar}

\caption{Typing rules for $\lambdas$. 
The typing context $\sctx$ is standard.}
\label{fig:slambdas}
\end{figure}


\begin{figure}
  \small
$\fbox{\inferrule{}{e \sreduces e}}$
\begin{mathpar}
\inferrule[S-E-Abs]                                                             
{ \ }                                                                           
{\lambda x.e \sreduces \lambda x.e}                                             

\inferrule[S-E-App]
{ e_1 \sreduces \lambda x . e_3 \\ e_2 \sreduces v_2 \\ [ v_2 / x ] e_3 \sreduces e' }
{ e_1(e_2) \sreduces e' }

\inferrule[S-E-RStr]
{ \ }
{\strin{s} \sreduces \strin{s}}

\inferrule[S-E-Concat]
{e_1 \sreduces \strin{s_1} \\ e_2 \sreduces \strin{s_2}} 
{\rsconcat{e_1}{e_2} \sreduces \strin{s_1 s_2}} % ???

\inferrule[S-E-Case-$\epsilon$]
{
  e_1 \sreduces \strin{\epsilon} \\
  e_2 \sreduces v_2
}
{
  \strcase{e_1}{e_2}{e_3} \sreduces v_2
}

\inferrule[S-E-Case-Concat]
{
  e_1 \sreduces \strin{p s} \\
  e_3 \sreduces x.y.e_4 \\
  [p/x][s/y]e_4 \sreduces e'
}
{
  \strcase{e_1}{e_2}{e_3} \sreduces e'
}

\inferrule[S-E-Replace]
{e_1 \sreduces \strin{e_1} \\ e_2 \sreduces \strin{s_2} \\ \lsubst{r}{s_1}{s_2} = s} 
{\sisubst{r}{e_1}{e_2} \sreduces \sistr{s}}

\inferrule[S-E-SafeCoerce]
{e \sreduces \strin{s}}
{\coerce{r}{e} \sreduces \strin{s}}

\inferrule[S-E-Check-Ok]
{e \sreduces \strin{s} \\ s \in \lang{r} \\ [\strin{s} / x]e_1 \sreduces e'}
{
  \rcheck{r}{e}{x.e_1}{e_2} \sreduces e'
}

\inferrule[S-E-Check-NotOk]
{
  e \sreduces \strin{s} \\ s \not \in \lang{r}
}
{
  \rcheck{r}{e}{x.e_1}{e_2} \sreduces e_2
}



\end{mathpar}
\caption{Big step semantics for $\lambdas$}.
\label{fig:dlambdas}
\end{figure}





\subsubsection{Concatenation and String Decomposition}

The \textsc{S-T-Concat} rule is the simplest example of our approach. The rule is sound because the result of concatenating two strings will always be in the sequential composition two regular expressions matching the respective strings. The rule therefore relates string concatenation to sequential composition of regular expressions.

Whereas concatenation allows the construction of large strings from smaller strings, \textsc{S-T-Case} allows the decomposition, or elimination, of large strings into smaller strings. Intuitively, this rule ``peels off" the first character, and then performs a specified operation on the first character and the remaining string. In terms of strings, this is essentially the ubiquitious substring operation.

The definition of \textsc{S-T-Case} is subtle because even simple string operations sometimes require complicated operations on regular expressions. Peeling off the first character of a string is deterministic -- the first character is always one, concrete value. However, a regular expression describing the first character of any matching string might recognize multiple concrete values. For instance, the first character of ``CMU" is always ``C"; however, if the expression associated with this string is CMU$+$KIT, then the expression describing the first character is C$+$K.
Therefore, an operation on languages corresponding to case analysis on strings must consider one-character prefixes (a head) and their corresponding suffixes (a tail).

Fortunately, regular expression derivatives \cite{bowzer} convienantly capture this intuition.
The regular expression recognizing any one-character prefix of the strings in $\lang{r}$ is easily defined.
The one-character prefix definition combined with derivatives gives a concise definition of the
remaining string.

\begin{defn}[Definition of \lhead{r}]
The function $\lhead{r}$ is defined in terms of the structure of $r$:
\begin{itemize}
\item $\lhead{a r'} = a$ where $a \in \Sigma$
\item $\lhead{\epsilon} = \epsilon$
\item $\lhead{r_1 +  r_2}  = \lhead{r_1} + \lhead{r_2}$
\item $\lhead{r*} = \lhead{r}$
\item $\lhead{.} = a_1 + a_2 + ... + a_n$ for all $a_i \in \Sigma$ where $|\Sigma| = n$.
\end{itemize}
\end{defn}

Given this definition of $\lhead{r}$, regular expression derivatives provide a useful tool for defining $\ltail{r}$.

\begin{defn}[Definition of \ltail{r}]
The function \ltail{r} is defined in terms of $\lhead{r}$.
Note that $\lhead{r} = a_1 + a_2 + ... + a_i$.
We define $\ltail{r} = \delta_{a_1}(r) + \delta_{a_2}(r) + ... + \delta_{a_i}(r)$
where $\delta_s(r)$ is the Brzozowski derivative of $r$ with respect to $s$ \cite{bowzer}.
\end{defn}

The \textsc{S-T-Concat} rule, which is defined in terms of these operations, relates the result of ``peeling off" the first character of a string to regular expression derivatives.

\subsubsection{Coercion}

The $\lambdas$ language supports two forms of coercion. Safe coercion only allows coercsion between 
strings types which are guaranteed to be safe. This form of coercion is useful because the replacement operation (introduced below in Section~\ref{sec:replace}) is often more conservative than absolutely necessary.
Conversely, unsafe coercion -- which we refer to as a checked coercion -- 
allows for potential unsafe type casts. Our semantics for check ensures that only safe values are used. Whenever a value is determined to be unsafe at runtime, a default value $e_2$ is used instead.

Summarily, 
 \textsc{S-T-SafeCoerce} allows only safe coercions between string types by
    expoiting the decidability of language inclusion, while
\textsc{S-T-Check} allows casts between strings that cannot be guaranteed at compile time, but inserts a runtime check a runtime check.

\subsubsection{Replacement}\label{sec:replace}

The premier operation for manipulating strings in $\lambdas$ is string substitution.
On strings, the string substitution operator is familiar, and roughly analogous to \lstinline{str_replace} in PHP and \lstinline{String.replace} in Java.
The definition of \textsc{S-T-Case} requires a definition of replacement for regular expressions (or languages) corresponding to string replacement.
In this section, we define this operation. 

Both string and language replacement are defined extra-linguistically.
The system $\lambdas$ is defined in terms of these functions.
The function $\lsubst{r}{s_1}{s_2}$ replaces every substring of $s_1$ matching $r$ with $s_2$.
In an analogous manner, the function $\lreplace{r}{r_1}{r_2}$ replaces every sublanguages of $r_1$ matching $r$ with $r_2$.
If an intuiition for this operation is not clear, it may be helpful to think in terms replacing sub-automata.


Throughout this section, we fix an alphabet $\Sigma$ over which strings $s$ and
regular expressions $r$ are defined. We use $\lang{r}$ to refer to the
language recognized by the regular expression $r$. 

\begin{lem}[Properties of Regular Languages and Expressions.] \label{thm:regexprops}
The following are properties of regular expressions which are necessary for our proofs:
If $s_1 \in \lang{r_1}$ and $s_2 \in \lang{r_2}$ then $s_1s_2 \in \lang{r_1r_2}$.
For all strings $s$ and regular expressions $r$, either $s \in \lang{r}$ or $s \not \in \lang{r}$.
Regular languages are closed under reversal.
\end{lem}

If any of these properties are unfamiliar, the reader may refer to a standard text on the subject \cite{cinderella}.

\begin{defn}[$\tt{subst}$]
The relation $\lsubst{r}{s_1}{s_2} = s$ produces a string $s$ in which all substrings of $s_1$ matching $r$ are replaced with $s_2$.
\end{defn}

A proper definition of ${\sf lreplace}$ would give an rewrite system with correctness and termination proofs, which is beyond the scope of this paper
on security-motivated type system extensions. Instead, we provide an abstract definition of the relation and state necessary propositions.

\begin{defn}[$\tt{lreplace}$]
  The relation $\lreplace{r}{r_1}{r_2} = r'$ relates $r, r_1,$ and $r_2$ to
  a language $r'$ containing all strings of $r_1$ except that any substring $s_{pre} s s_{post} \in \lang{r_1}$ where $s \in \lang{r}$
  is replaced by the set of strings $s_{pre} s_2 s_{post}$ for all $s_2 \in \lang{r_2}$ (the prefix and postfix positions may be empty).
\end{defn}

\begin{prop}[Closure.] \label{thm:total}
  If $\lang{r}, \lang{r_1}$ and $\lang{r_2}$ are regular expressions, then $\lang{\lreplace{r}{r_1}{r_2}}$ is also a regular language.
\end{prop}
\begin{proof}
Algorithms for the inclusion problem may be adopted to identify any sublanguage $x \subseteq r$ of $r_1$.
The language $x_{pre}$ can be computed by taking total derivatives until the remaining language
equals $x$; $x_{post}$ can be computed in a similar way after reversal.
Then $r'$ is $x_{pre}r_2x_{post}$.
\end{proof}

\begin{prop}[Substitution Correspondence.] \label{thm:substcorrespondence}
  If $s_1 \in \lang{r_1}$ and $s_2 \in \lang{r_2}$ then

  $\lsubst{r}{s_1}{s_2} \in \lang{\lreplace{r}{s_1}{s_2}}$.
\end{prop}
\begin{proof}
The proposition follows from the definitions of subst and lreplace; note that language substitutions over-approximate string substitutions.
\end{proof}

\subsubsection{Safety}

In this section, we establish type soundness for $\lambdas$.
The theorem relies upon the lemmas and propositions established above.
We also rely on additional lemmas which establish the preservation of well-formedness
of regular expressions.

\begin{lem}
  If $\sctx \vdash e : \stringin{r}$ then $r$ is a well-formed regular expression.
\end{lem}
\begin{proof}
  The only non-trivial case is S-T-Replace, which follows from lemma \ref{thm:total}. 
\end{proof}
\begin{lem}
If $\tctx \vdash \iota : \regex$ then $\iota \treduces \rx{r}$ such that $r$ is a well-formed regular expression. 
\end{lem}

Safety for the string fragment of $\lambdas$ requires validating that the type system's definition is justified
by our theorems about regular languages.
We avoid the most significant issues inherent to big-step semantics by avoiding non-termination.
The simply typed lambda calculus terminates, and our conservative, compositional extension clearly
terminates modulo termination of ${\sf subst}$ and ${\sf lreplace}$ (but even if these were non-terminating, this still does not pose a problem for the big-step semantics itself).
However, a more careful treatment or treatment for a language with non-termination might proceed by either coinduction \cite{coinductionoo, coinduction} or step-indexing \cite{stepindexing}.

\begin{thm}[Canonical Forms for String Fragment of $\lambdas$.]\label{thm:cfs}
  If $\sctx \vdash e : \stringin{r}$ 
  then $e \sreduces \rstr{s}$ 
\end{thm}

\begin{thm}[Type Safety.] \label{thm:scorrect}
  If $\sctx \vdash e : \sigma$ 
  then $e \sreduces e'$ and $\sctx \vdash e' : \stringin{r}$.
\end{thm}
\begin{proof}
By induction on the typing relation.
The S-T-Concat case requires Lemma \ref{thm:regexprops} 
and the S-T-Replace case appeals to Lemma \ref{thm:substcorrespondence}.
\end{proof}

\subsubsection{The Security Theorem}\label{sec:securitythm}

The chief benefit of $\lambdas$ is its safety theorem, which states that any value of
a regular expression type is recognized by the regular expression corresponding to its type.
Our main technical result, stated later in this section, establishes that this property
is preserved under translation into $\lambdap$.

\begin{thm}[Correctness of Input Sanitation for $\lambdas$.]\label{thm:scorrect}
  If  $\sctx \vdash e : \stringin{r}$ and $e \sreduces \rstr{s}$ then $s \in \lang{r}$.
\end{thm}
\begin{proof}
  The theorem follows directly from type safety, canonical forms for $\lambdas$, and inversion of the typing relation for $\lambdas$.
\end{proof}

\subsection{A Target Language with a Regular Expression Library}\label{sec:p}

The system $\lambdap$ is a straight-forward extension of a simply typed lambda calculus
with a $\str$ type and a regular expression type, as well as 
some operations -- such as concatenation and replacement -- found in many the standard libraries of many programming languages.
The operations of $\lambdap $ correspond precisely to the operations of $\lambdas$ in a way made precise by the translation rules described in the next section.
Unlike $\lambdas$, $\lambdap$ does not statically track the effects of string operations.
The language $\lambdap$ is so-called because it is reminscent of popular web programming languages,
such as \textbf{P}ython or \textbf{P}HP.

The grammar of $\lambdap$ is defined in Figure~\ref{fig:lcsSyntax}.
The typing rules \textsc{P-T-} are defined in Figure~\ref{fig:slambdap}
and a big-step semantics is defined by the rules \textsc{P-E-} in Figure~\ref{fig:dlambdap}.

\renewcommand{\grammarlabel}[2]{#1\hfill#2}

\begin{figure}[h]
\begin{grammar}

<$\theta$> ::= $\theta \rightarrow \theta$ \hfill target types \alt
$\str$ \alt $\regex$

<$\iota$> ::= $x$  \hfill target terms \alt
             $\lambda x . \iota$ \alt
                    $\iota(\iota)$ \alt
$\tstr{s}$ \alt
  $\rx{r}$ \alt
  $\tconcat{\iota}{\iota}$ \alt
  $\pstrcase{\iota}{\iota}{x.y.\iota}$ \alt
  $\preplace{\iota}{\iota}{\iota}$ \alt
  $\tcheck{\rx{r}}{\iota}{\iota}{\iota}$ 


<$\dot{v}$> ::= $\lambda x . \iota$ \hfill target values \alt
                $\tstr{s}$

\end{grammar}
\caption{Syntax for the target language, $\lambdap$, containing strings and statically constructed regular expressions.}
\label{fig:lcsSyntax}
\end{figure}



\begin{figure}[h]\label{fig:lambdap}
\small
$\fbox{\inferrule{}{\tctx \vdash \iota : \tau}}$
~~~~$\tctx ::= \emptyset \pipe \tctx, x : \tau$

\begin{mathpar}
\inferrule[P-T-Var]
{ x:\tau \in \tctx }
{ \tctx \vdash x:\tau }

\inferrule[P-T-Abs]
{\tctx, x : \tau_1 \vdash \iota_2 : \tau_2}
{\tctx \vdash \lambda x.\iota_2 : \tau_1 \rightarrow \tau_2}

\inferrule[P-T-App]
{\tctx \vdash \iota_1 : \tau_2 \rightarrow \tau \\ \tctx \vdash \iota_2 : \tau_2}
{\tctx \vdash \iota_1(\iota_2) : \iota}

\inferrule[P-T-String]
{ \ }
{\tctx \vdash \tstr{s} : \str}

\inferrule[P-T-Regex]
{ \ }
{\tctx \vdash \rx{r} : \regex}

\inferrule[P-T-Concat]
{\tctx \vdash \iota_1 : \str \\ \tctx \vdash \iota_2 : \str}
{\tctx \vdash \tconcat{\iota_1}{\iota_2} : \str}

\inferrule[P-T-Case]
{\tctx \vdash \iota_1 : \str \\ \tctx \vdash \iota_2 : \tau \\ \tctx, x:\str, y:\str \vdash \iota_3:\tau}
{\tctx \vdash \pstrcase{\iota_1}{\iota_2}{\iota_3} : \tau}

\inferrule[P-T-Replace]
{\tctx \vdash \iota_1 : \regex \\ \tctx \vdash \iota_2 : \str \\ \tctx \vdash \iota_3 : \str }
{\tctx \vdash \preplace{\iota_1}{\iota_2}{\iota_3} : \str}

\inferrule[P-T-Check]
{\tctx \vdash \iota_r : \regex \\ \tctx \vdash \iota_1 : \str \\ \tctx, x:\str \vdash \iota_2 : \sigma \\ \tctx \vdash \iota_3 : \sigma}
{\tctx \vdash \tcheck{\iota_r}{\iota_1}{x . \iota_2}{\iota_3} : \sigma}
\end{mathpar}
\caption{Typing rules for $\lambdap$.
The typing context $\tctx$ is standard.}
\label{fig:slambdap}
\end{figure}

\begin{figure}[t]
\small
$\fbox{\inferrule{}{\iota \treduces \iota}}$

\begin{mathpar}
\inferrule[P-E-Abs]
{ \ }
{\lambda x.e \sreduces \lambda x.e}

\inferrule[P-E-App]
{ \iota_1 \sreduces \lambda x . \iota_3 \\  \iota_2 \sreduces v \\ [v / x] \iota_3 \sreduces \iota'}
{ \iota_1(\iota_2) \sreduces \iota'}

\inferrule[P-E-Str]
{ \ }
{\tstr{s} \treduces \tstr{s}}

\inferrule[P-E-Rx]
{ \ }
{\rx{r} \treduces \rx{r}}

\inferrule[P-E-Concat]
{\iota_1 \treduces \tstr{s_1} \\ \iota_2 \treduces \tstr{s_2}} 
{\tconcat{\iota_1}{\iota_2} \treduces \tstr{s_1 s_2}} % ???

\inferrule[P-E-Case-$\epsilon$]
{
  \iota_1 \treduces \tstr{\ } \\
  \iota_2 \treduces \iota_2' \\
}
{
  \pstrcase{\iota_1}{\iota_2}{\iota_3} \treduces \iota_1'
}


\inferrule[P-E-Case-Concat]
{
  \iota_1 \treduces \tstr{ps} \\
  x.y.\iota_3 \treduces \iota_4 \\
  [p/x][s/y]\iota_4 \treduces \iota'
}
{
  \pstrcase{\iota_1}{\iota_2}{\iota_3} \treduces \iota'
}

\inferrule[P-E-Replace]
{\iota_1 \treduces \rx{r} \\ \iota_2 \treduces \tstr{s_2} \\ \iota_3 \treduces \tstr{s_3} \\ \lsubst{r}{s_2}{s_3} = s} 
{\preplace{\iota_1}{\iota_2}{\iota_3} \treduces \tstr{s}}

\inferrule[P-E-Check-OK]
{\iota \treduces \tstr{s} \\ s \in \lang{r} \\ [\tstr{s} / x] \iota_1 \sreduces \iota'}
{\tcheck{\rx{r}}{\iota}{x.\iota_1}{\iota_2} \treduces \iota'}

\inferrule[P-E-Check-NotOK]
{\iota \treduces \tstr{s} \\ s \not \in \lang{r}}
{\tcheck{\rx{r}}{\iota}{x.\iota_1}{\iota_2} \treduces \iota_2}
\end{mathpar}
\caption{Big step semantics for of $\lambdap$}.
\label{fig:dlambdap}
\end{figure}





\subsubsection{Safety}

Type safety for $\lambdap$ is straight-forward, but is necessary in order to establish the 
correctness of our translation.
Again, we elide a more careful treatment by treating a special case where our language terminates but
note the multiple approaches to proving soundness for non-terminating languages with natural semantics \cite{coinductionoo, stepindexing, coinduction}.



\begin{thm} 
  Let $\iota$ be a term in the target language. If $\tctx \vdash \iota : \tau$ 
  then $\iota \sreduces \iota'$ and $\tctx \vdash \iota' : \tau$.
\end{thm}

\subsection{Translation from $\lambdas$ to $\lambdap$}\label{sec:tr}


The translation from $\lambdas$ to $\lambdap$ is defined in figure 5.
The coercion cases are most interesting. If the safety of coercion in manifest in the
types of the expressions, then no runtime check is inserted.
If the safety of coercion is not manifest in the types, then a check is inserted.

In practice, the type of a replacement rarely matches a specification.
Therefore, it is convienant in an implementation to always insert the appropriate
safe coercion. This way, violations of the sanitation protocol manifest as type errors,
but the definition of an adequate replacement is not arduous.
Alternatively, this policy may 
be codified in the type system itself using subtyping \cite{fulton12}.

The translation is defined by the rules \textsc{Tr-} in Figure~\ref{fig:tr}.
This section ultimately establishes that the security theorem for $\lambdas$ is preserved under compilation.


\begin{figure}[h]

$\fbox{\inferrule{}{ \trden{e} = \iota}}$
\begin{mathpar}
\inferrule[Tr-Var]
{ }
{ \trden{x} = x}

\inferrule[Tr-Abs]
{  \trden{e} = \iota }
{ \trden{ \lambda x.e } = \lambda x . \iota}

\inferrule[Tr-App]
{ \trden{e_1} = \iota_1 \\  \trden{e_2} = \iota_2}
{ \trden{e_1(e_2)} = \iota_1(\iota_2)}

\inferrule[Tr-Case]
{ \trden{e_1} = \iota_1 \\
   \trden{e_2} = \iota_2 \\
   \trden{e_3} = \iota_3
}
{ \trden{ \strcase{e_1}{e_2}{e_3} } = \pstrcase{\iota_1}{\iota_2}{\iota_3} }

\inferrule[Tr-string]
{ \ }
{   \trden{\strin{s}} = \tstr{s}}

\inferrule[Tr-Concat]
{  \trden{e_1} = \iota_1 \\  \trden{e_2} = \iota_2}
{  \trden{\rsconcat{e_1}{e_2}} = \tconcat{\iota_1}{\iota_2} }

\inferrule[Tr-Subst]
{   \trden{e_1} = \iota_1 \\   \trden{e_2} = \iota_2 }
{   \trden{ \sisubst{r}{e_1}{e_2} } = \tsubst{\rx{r}}{\iota_1}{\iota_2} }

\inferrule[Tr-SafeCoerce]
{  \trden{e} = \iota }
{   \trden{ \coerce{r'}{e} } = \iota }

\inferrule[Tr-Check]
{  \trden{e} = \iota_1 \\  \trden{e_1} = \iota_1 \\  \trden{e_2} = \iota_2} 
{  \trden{ \rcheck{r}{e}{x.e_1}{e_2} } = \tcheck{\rx{r}}{\iota}{x.\iota_1}{\iota_2} } 

\end{mathpar}
\caption{Translation from source terms ($e$) to target terms ($\iota$).
The translation is type-directed.}
\label{fig:tr}
\end{figure}

\begin{thm}[Translation Correctness]\label{thm:trcorrect}
  If $\tctx \vdash e : \stringin{r}$ then there exists an $\iota$ such that $\trden{e} = \iota$, $\iota \sreduces \tstr{s}$,
  and $e \treduces \rstr{s}$.
\end{thm}
\begin{proof}
The proof proceeds by induction on the typing relation for $e$ and an appropriate choich of $\iota$; in each case,
the choice is the syntactic form in $\lambdap$ corresponding to the form under consideration (e.g. choose {\sf preplace} when considering {\sf sreplace}).
After the correct choice, the proof proceeds by our type safety theorems and an appeal to the induction hypothesis.
\end{proof}

\subsubsection{Preservation of Security}

Finally, our main result establishes that correctness of $\lambdas$ is preserved under the translation into $\lambdap$.

\begin{thm}[Correctness of Input Sanitation for Translated Terms.]\label{thm:main}
  If $\trden{e} = \iota$ and $\sctx \vdash e : \stringin{r}$ then $\iota \sreduces \tstr{s}$
  for $s \in \lang{r}$.
\end{thm}
\begin{proof}
  By theorem \ref{thm:trcorrect}, $\iota \sreduces \tstr{s}$ implies that $e \sreduces \strin{s}$.
  By theorem \ref{thm:scorrect}, the above property together with the assumption that $e$ is well-typed implies that $s \in \lang{r}$.
\end{proof}

%\begin{figure}
%\begin{lstlisting}
%output of successful compilation
%\end{lstlisting}
%\caption{Output of successful compilation.}
%\end{figure}
%
%\begin{figure}
%\begin{lstlisting}
%output of failed compilation
%\end{lstlisting}
%\caption{Output of failed compilation.}
%\end{figure}
%

%\subsection{An Example}\label{whatev}

\section{Implementation in {Atlang}}\label{atlang}
In the previous section, we specified a type system and a translation semantics to a language containing only strings and regular expressions. In this section, we take Python to be such a target language. Python does not have a static type system, however, so to implement these semantics, we will leverage \verb|atlang|, an extensible type system for Python (being developed by the authors). By using \verb|atlang|, which builds on Python's quotations and reflection facilities, we can implement these semantics as a library, rather than as a new dialect of Python. 

\subsection{Example Usage}

\begin{figure}[h]\begin{lstlisting}
from atlib import fn, string_in

@fn
def sanitize(s : string_in[r'.*']):
  return (s.replace(r'"', '&quot;') 
           .replace(r'<', '&lt;')
           .replace(r'>', '&gt;'))

@fn
def results_query(s : string_in[r'[^"]*']):
  return 'SELECT * FROM users WHERE name="' + s + '"'

@fn
def results_div(s : string_in[r'[^<>]*']):
  return '<div>Results for ' + s + '</div>'

@fn
def main(db):
  input = sanitize(user_input())
  results = db.execute(results_query(input))
  return results_div(input) + format(results)
\end{lstlisting}
\vspace{-10px}
\caption{Regular string types in atlang, a library that enables static type checking for Python. }\label{fig:atexample}
\end{figure}



Figure \ref{fig:atexample} demonstrates the use of two type constructors, \verb|fn| and \verb|string_in|, both of which we have included in \verb|atlib|, the standard library for \verb|atlang|. The \verb|fn| type constructor can be used to annotate functions that should be statically checked by \verb|atlang|. The function \verb|sanitize| on lines 3-7 specifies one argument, \verb|s|, of type \lstinline{string_in[r'.*']}.\todo{fix sizes}

The sanitize function takes an arbitrary string and returns a string without
double quotes or left and right brackets. In this example, we use HTML
escape sequences.

The main function receives user input and passes this input to a 
sanitize function, which replaces all double quotes and brackets with HTML
escape sequences. 

The result of applying sanitize to input is appended in two functions which
construct a safe query (avoiding command injection) and safe HTML output (avoiding Cross-Site Scripting (XSS) attacks).
The arguments to the result and output construction functions constitute \emph{specifications}.
In the case of \textsf{results_query}, this specification ensures that user input is always interpreted
as a string literal by the SQL server.
In the case of \textsf{results_div}, this specification ensures that user input does 
not contain any HTML tags, which is a conservative but effective policy for preventing XSS attacks.

Note that ${\sf input}$ does not actually meet these specifications without additional machinery.
The type of ${\sf input}$ is quite large
and does not actually equal the specified domains of the query or output construction
methods. This mismatch is common -- in fact, nearly universal. Therefore, 
our implementation includes a simple subtyping relation between regular expression
types. 

This subtyping relation is justified theoretically by the fact that language inclusion is
decidable; see \cite{fulton12} for a formal definition of the subtyping relation.
Additionally, our extension remains composable because subtyping is defined on a type-by-type basis;
see \cite{fulton13} for a discussion of subtyping in Atlang (referred to there as Ace).

\subsection{Implementation of the Regular Expression Type}

\begin{figure}
\begin{lstlisting}
class string_in(atlang.Type):
  def __init__(self, rx):
    rx = rx_normalize(rx)
    atlang.Type.__init__(idx=rx)

  def ana_Str(self, ctx, node):
    if not in_lang(node.s, self.idx):
      raise atlang.TypeError("...", node)

  def trans_Str(self, ctx, node):
    return astx.copy(node)

  def syn_BinOp_Add(self, ctx, node):
    left_t = ctx.syn(node.left)
    right_t = ctx.syn(node.right)
    if isinstance(left_t, string_in):
      left_rx = left_t.idx
      if isinstance(right_t, string_in):
        right_rx = right_t.idx
        return string_in[lconcat(left_rx, right_rx)]
    raise atlang.TypeError("...", node)

  def trans_BinOp_Add(self, ctx, node):
    return astx.copy(node)

  def syn_Method_replace(self, ctx, node):
    [rx, exp] = node.args
    if not isinstance(rx, ast.Str):
      raise atlang.TypeError("...", node)
    rx = rx.s
    exp_t = ctx.syn(exp)
    if not isinstance(exp_t, string_in):
      raise atlang.TypeError("...", node)
    exp_rx = exp_t.idx
    return string_in[lreplace(self.idx, rx, exp_rx)]

  def trans_Method_replace(self, ctx, node):
    return astx.quote(
      """__import__(re); re.sub(%0, %1, %2)""",
      astx.Str(s=node.args[0]),
      astx.copy(node.func.value),
      astx.copy(node.args[1]))

  def syn_Method_check(self, ctx, node):
    [rx] = node.args
    if not isinstance(rx, ast.Str):
      raise atlang.TypeError("...", node)
    return string_in[rx.s]

  def trans_Method_check(self, ctx, node):
    return astx.quote(
      """__import__(string_in_helper);
      string_in_helper.coerce(%0, %1)""",
      astx.Str(s=other_t.idx),
      astx.copy(node))

  def check_Coerce(self, ctx, node, other_t):
    # coercions can only be defined between 
    # types with the same type constructor, 
    if rx_sublang(other_t.idx, self.idx):
      return other_t
    else: raise atlang.TypeError("...", node)
\end{lstlisting}
\vspace{-10px}
\caption{Implementation of the \texttt{string\_in} type constructor in atlang.}
\label{fig:impl}

\label{fig:atimpl}\end{figure}

We implemented a variation on the type system presented in this paper with two
significant differences. first, we only support replacements where $s_2$ is the empty
string. Therefore, our implementation respects the system presented in section 2
only modulo the definition of \textsf{lreplace}. Seocnd, we use subtyping instead of
\textsc{S-*-SafeCoerce}, which decreases inessential verbosity of the language.

Atlang translates programs using type definitions, which may extend both the
static and dynamic semantics of the language. New types are defined as Python
classes; figure \ref{fig:impl} contains the source code of our implementation.

The \textsf{string_in} type has an indexing regular expression \texttt{idx}.
Our translation is defined by the \textsf{trans_} methods while the \textsf{syn_}
methods define our type checker. Atlang defers type checking and translation
to these methods whenever an expression of type \textsf{string_in} is encountered.


\section{Related Work and Alternative Approaches}\label{related}



The input sanitation problem is well-understood. There exist a large number of techniques and technologies, proposed by both practitioners and researchers, for preventing injection-style attacks. In this section, we explain how our approach to the input sanitation problem differs from each of these approaches. More important than these differences, however, is our more general assertion that language extensibility is a promising approach toward consideration of security goals in programming language design.

Unlike \emph{frameworks and libraries} provided by languages such as Haskell and Ruby, our type system provides a \emph{static} guarantee that input is always properly sanitized before use. Doing so requires reasoning about the operations on regular languages corresponding to standard operations on strings; we are unaware of any production system which contains this form of reasoning. Therefore, even where frameworks and libraries provide a viable interface or wrapper around input sanitation, our approach is complementary because it ensures the correctness of the framework or library itself. Furthermore, our approach is more general than database abstraction layers because our mechanism is applicable to all forms of command injection (e.g. shell injection or remote file inclusion).

A number of research languages provide static guarantees that a program is free of input sanitation vulnerabilities \cite{UrFlowOSDI10}. 
Unlike this work, our solution to the input sanitation problem has a very low barrier to adoption; for instance, our implementation conservatively extends Python -- a popular language among web developers.
We also believe our general approach is better-positioned for security, where continuously evolving threats might require frequent addition of new analyses; in these cases, the composability and generality of our approach is a substantial advantage.

%\begin{itemize}
%  \item Our system is a light-weight solution to a single class of sanitation vulnerabilities (e.g. we do not address Cross-Site Scripting).
%  \item Our system is defined as a library in terms of an extensible type system, as opposed to a stand-alone language. Instead of introducing new technologies and methodologies for addressing security problems, we provide a light-weight static analysis which complements approaches developers already understand well.
%  \item Our implementation of the translation is implemented in Python and shares its grammar. Since Python is a popular programming language among web developers, the barrier between our research and adopted technologies is lower than for greenfield security-oriented languages.
%\end{itemize}

The Wyvern programming language provides a general framework for composing language extensions \cite{tsl}\cite{wyvern}.
Our work identifies one particular extension, and is therefore complementary to Wyvern and related
work on extensible programming languages.
We are also unaware of any extensible programming languages which emphasize applications to security concerns.

Incorporating regular expressions into the type system is not novel. The XDuce system \cite{HosoyaVouillonPierce2000ICFP,HosoyaPierce2002} checks XML documents against schema using regular expressions. 
Similarly, XHaskell \cite{xhaskell} focuses on XML documents.
We differ from this and related work in at least three ways:
\begin{itemize}
  \item Our system is defined within an extensible type system.
  \item We demonstrate that regular expression types are applicable to the web security domain, whereas previous work on regular expression types focused on XML schema.
  \item Although our static replacement operation is definable in some languages with regular expression types, we are the first to expose this operation and connect the semantics of regular language replacement with the semantics of string substitution via a type safety and compilation correctness argument.
\end{itemize}

In conclusion, our contribution is a type system, implemented within an extensible type system, for checking the correctness of input sanitation algorithms.

\section{Future Work}

We believe that this type system extension serves as a useful basis for web-oriented static analysis.
The use sites of arbitrary strings are usually constrained to a few sections of the application. Assuming
regular expressions are used for input sanitation, annotations at these use sites could be sufficient input to a sound and complete static analysis.

We also believe that extensible programming languages are a promising approach toward incorporating security
and privacy into programming languages. The Software Industry moves quickly, and developing new languages for 
the particular security and privacy concerns of each new domain is likely a losing strategy. Conversely, extensible
languages might provide developers with a way to incorporate domain-specific security and privacy analyses into their
daily development activities. In future work, we hope to bolster this hypothesis by extending our approach in this paper
to more realistic settings and by developing new type extensions addressing security and privacy concerns.

\section{Conclusion}


Composable analyses which complement existing approaches constitute a promising approach toward the integration of security concerns into programming languages.
In this paper, we presented a system with both of these properties and defined a security-preserving transformation.
Unlike other approaches, our solution complements existing, familiar solutions while providing a strong guarantee that traditional library and framework-based approaches are implemented and utilized correctly.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% END SECTION TWO -- THIS IS THE CONFLICT LINE
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%\newcommand{\F}[1]{\textsf{#1}~}
%\newcommand{\FF}[1]{\textsf{#1}}
%\newcommand{\Q}{\FF{Arg}}
%\newcommand{\xlA}[1]{\lfloor #1 \rfloor_{\lambda}}
%\newcommand{\xA}[1]{$\lfloor #1 \rfloor_{\text{Ace}}$}
%\newcommand{\rtotau}[1]{\lfloor #1 \rfloor}
%
%\newcommand{\tremp}{{\tt tremp}}
%\newcommand{\trdot}{{\tt trdot}}
%\newcommand{\trchar}[1]{{\tt trchar}[#1]}
%\newcommand{\trseq}[2]{{\tt trseq}(#1; #2)}
%\newcommand{\tror}[2]{{\tt tror}(#1; #2)}
%\newcommand{\tlstr}[1]{{\tt tstr}[#1]}
%\begin{table*}[t]
%\centering
%\begin{tabular}{ l l l }
%$r$ & $\xlA{r}$ & \xA{r}\\
%\hline
%$\epsilon$ & $\tremp$ & \verb|""|\\
%$.$ & $\trdot$ & \verb|"."|\\
%$a$ & $\trchar{a}$ & \verb|"|$a$\verb|"|\\
%$r_1 \cdot r_2$ & $\trseq{\xlA{r_1}}{\xlA{r_2}}$ & \xA{r_1}\verb| + |\xA{r_2}\\
%$r_1 + r_2$ & $\tror{\xlA{r_1}}{\xlA{r_2}}$ & \verb|"(" + |\xA{r_1}\verb! + "|" + !\xA{r_2}\verb| + ")"|\\
%\\
%$\sigma$ & $\xlA{\sigma}$ & \xA{\sigma}\\
%\hline
%${\tt string\_in}[r]$ & $\fvar{stringin}[\xlA{r}]$ & \verb|string_in[|\xA{r}\verb|]|\\
%\\
%  $S$ & $\xlA{S}$ & \xA{S} \\
%  \hline
%  ${\tt str\_in}[s]$ & $\FF{intro}[\FF{str}[s]]()$ & \verb|"|$s$\verb|"|\\
%  ${\tt concat}(S_1; S_2)$  & $\xlA{S_1}\cdot\FF{elim}[\tvar{concat}](\xlA{S_2})$ & \xA{S_1}\verb| + |\xA{S_2} \\
%  ${\tt subst}[r](S_1; S_2)$  & $\xlA{S_1}\cdot\FF{elim}[\tvar{subst}~\xlA{r}](\xlA{S_2})$ & \xA{S_1}\verb|.subst(|\xA{r}\verb|, |\xA{S_2}\verb|)|\\
%  ${\tt coerce}[r](S)$  & $\xlA{S}\cdot\FF{elim}[\tvar{coerce}~\xlA{r}]()$ & \xA{S}\verb|.coerce(|\xA{r}\verb|)|
%\end{tabular}
%\caption{Embeddings of the ${\tt string\_in}$ fragment into $\lamAce$ and Ace.}
%\end{table*}
%%
%\newcommand{\atjsynX}[3]{\Gamma \vdash_\fvalCtx #1 \Rightarrow #2 \leadsto #3}
%\newcommand{\atjanaX}[3]{\Gamma \vdash_\fvalCtx #1 \Leftarrow #2 \leadsto #3}
%\newcommand{\atjerrX}[1]{\Gamma \vdash_\fvalCtx #1~ \mathtt{error}}
%\begin{figure*}[t]
%\small
%$\fbox{\inferrule{}{\atjsynX{e}{\tau}{i}}}$~~~~
%$\fbox{\inferrule{}{\atjanaX{e}{\tau}{i}}}$~~~~
%%$\fbox{\inferrule{}{\atjerrX{e}}}$
%\begin{mathpar}
%\inferrule[att-flip]{
%	\atjsynX{e}{\tau}{i}
%}{
%	\atjanaX{e}{\tau}{i}
%}
%
%%\inferrule[att-var]{
%%	x \Rightarrow \tau \in \Gamma
%%}{
%%	\atjsynX{x}{\tau}{x}
%%}
%%
%%\inferrule[att-asc]{
%%    \tau \Downarrow_\fvalCtx \tau'\\
%%	\atjanaX{e}{\tau'}{i}
%%}{
%%	\atjsynX{e : \tau}{\tau'}{i}
%%}
%%
%%\inferrule[att-let-syn]{
%%	\atjsynX{e_1}{\tau_1}{i_1}\\
%%	\Gamma, x \Rightarrow \tau_1 \vdash_\fvalCtx e_2 \Rightarrow \tau_2 \leadsto i_2\\
%%	\trepof{\tau_1} \Downarrow_\fvalCtx \titype{\sigma_1}
%%}{
%%	\atjsynX{\F{let}x = e_1~\F{in}e_2}{\tau_2}{(\ilam{x}{\sigma_1}{i_2})~i_1}
%%}
%%
%%\inferrule[att-lam-ana]{
%%	\Gamma, x \Rightarrow \tau_1 \vdash_\fvalCtx e \Leftarrow \tau_2 \leadsto i\\
%%	\trepof{\tau_1} \Downarrow_\fvalCtx \titype{\sigma_1}
%%}{
%%	\atjanaX{\lambda x.e}{\ttype{arrow}{(\tau_1, \tau_2)}}{\ilam{x}{\sigma_1}{i}}
%%}
%%
%%\inferrule[att-lam]{
%%	\tau_1 \Downarrow_\fvalCtx \tau_1'\\
%%		\trepof{\tau_1'} \Downarrow_\fvalCtx \titype{\sigma}\\\\
%%	\Gamma, x \Rightarrow \tau_1' \vdash_\fvalCtx e \Rightarrow \tau_2 \leadsto i
%%%	i \hookrightarrow_\fvalCtx i'\\
%%%		\sigma \hookrightarrow_\fvalCtx \sigma'
%%%	\ddbar{\fvar{Arrow}}{\fvalCtx}{\trepof{\tau_1'}}{\sbar_1}\\
%%	%\delfromtau{$\Xi_0$}{\fvalCtx}{\tau_1'}{\sabs}\\\\
%%}{
%%	\atjsynX{\elam{x}{\tau_1}{e}}{\ttype{arrow}{(\tau_1', \tau_2)}}{\ilam{x}{\sigma'}{i}}
%%}
%%
%\inferrule[att-intro-ana]{
%	\vdash_\fvalCtx \FF{iana}(\fvar{tycon})=\taudef\\
%	\taudef~\taut{opidx}~\taut{tyidx}~((\Gamma; e_1)? :: \ldots :: (\Gamma; e_n)? :: []) \Downarrow_\fvalCtx \titerm{i}\\\\
%%	\trepof{\ttype{tycon}{\tauidx'}} \Downarrow_\fvalCtx \titype{\sigma}\\
%		\trepof{\ttype{tycon}{\taut{tyidx}}} \Downarrow_\fvalCtx \titype{\sigma}\\
%		\Gamma \vdash_\fvalCtx i : \sigma
%}{
%	\atjanaX{\FF{intro}[\taut{opidx}](e_1; \ldots; e_n)}{\ttype{tycon}{\taut{tyidx}}}{i}
%}
%
%%\inferrule[att-i-asc-ty]{
%%	\atjanaX{I}{\tau}{i}
%%}{
%%	\atjsynX{I : \tau}{\tau}{i}
%%}
%%
%%\inferrule[att-i-asc-tycon]{
%%	\vdash_\fvalCtx \FF{isyn}(\fvar{tycon})=\taudef\\\\
%%	\taudef~\tauidx~((\Gamma; e_1)? {::}{\ldots}{::}(\Gamma; e_n)? {::} []) \Downarrow_\fvalCtx \tden{\titerm{i}}{\ttype{tycon}{\tauidx'}}\\
%%			\trepof{\tau_1'} \Downarrow_\fvalCtx \titype{\sigma}\\
%%	\Gamma \vdash_\fvalCtx i : \sigma
%%}{
%%	\atjsynX{\FF{intro}[\tauidx](e_1; \ldots; e_n)] :: \fvar{tycon}}{\ttype{tycon}{\tauidx'}}{i'}
%%}
%%
%\inferrule[att-elim-syn]{
%	\atjsynX{e}{\ttype{tycon}{\taut{tyidx}}}{i}\\
%	\vdash_\fvalCtx \FF{esyn}(\fvar{tycon})=\taudef\\\\
%	\taudef~\taut{opidx}~\taut{tyidx}~\titerm{i}~((\Gamma; e)? :: (\Gamma; e_1)? :: \ldots :: (\Gamma; e_n)? :: []) \Downarrow_\fvalCtx (\tau, \titerm{i'})\\\\
%			\trepof{\tau} \Downarrow_\fvalCtx \titype{\sigma}\\
%	\Gamma \vdash_\fvalCtx i' : \sigma
%}{
%	\atjsynX{e\cdot\FF{elim}[\taut{opidx}](e_1; \ldots; e_n)}{\tau}{i'}
%}
%\end{mathpar}
%%\vspace{-10px}
%\caption{The bidirectional active typechecking and translation judgements.}
%\label{atj}
%\end{figure*}
%\newcommand{\tlevalX}[2]{#1 \Downarrow_\fvalCtx #2}
%\begin{figure*}[t]
%\small
%$\fbox{\inferrule{}{\tau \Downarrow_\fvalCtx \tau'}}$~~~~
%\begin{mathpar}
%\inferrule[trstr-eval]{ }{\tlevalX{\tlstr{s}}{\tlstr{s}}}
%
%\inferrule[tremp-eval]{ }{\tremp \Downarrow_\fvalCtx \tremp}
%
%\cdots
%
%\inferrule[tror-eval]{
%	\tlevalX{\tau_1}{\tau_1'}\\
%	\tlevalX{\tau_2}{\tau_2'}
%}{
%	\tlevalX{\tror{\tau_1}{\tau_2}}{\tror{\tau_1'}{\tau_2'}}
%}
%
%trmatch
%
%trlsubst
%
%trsublang
%
%
%%\inferrule[repof]{
%%	\tau \Downarrow_\fvalCtx \ttype{tycon}{\tauidx}\\
%%	\vdash_\fvalCtx \FF{rep}(\fvar{tycon}) = \taurep\\
%%	\taurep~\tauidx \Downarrow_\fvalCtx \titype{\sigma}
%%}{
%%	\FF{repof}(\tau) \Downarrow_\fvalCtx \titype{\sigma}
%%}
%%
%\inferrule[syn]{
%    \tau \Downarrow_\fvalCtx (\Gamma; e)?\\
%	\atjsynX{e}{\tau}{\iota}\\\\
%    [\tau/\tvar{t}_{ty}, \titerm{\iota}/\tvar{t}_{trans}]\tau_2 \Downarrow_\fvalCtx \tau_2'
%}{
%	\FF{syn}(\tau_1; \tvar{t}_{ty}, \tvar{t}_{trans}.\tau_2) \Downarrow_\fvalCtx \tau_2'
%}
%
%\inferrule[ana]{
%	\tau_1 \Downarrow_\fvalCtx (\Gamma; e)?\\
%	\tau_2 \Downarrow_\fvalCtx \tau_2'\\
%	\atjanaX{e}{\tau_2'}{\iota}\\\\
%	[\titerm{\iota}/\tvar{t}_{trans}]\tau_3 \Downarrow_\fvalCtx \tau_3'
%}{
%	\FF{ana}(\tau_1; \tau_2; \tvar{t}_{trans}.\tau_3) \Downarrow_\fvalCtx \tau_3'
%}
%
%TODO: add rx, str stuff
%\end{mathpar}
%\caption{\small Normalization semantics for the type-level language. Missing rules (including error propagation rules and normalization of quoted internal terms and types) are unsurprising and will be given later.}
%\label{tleval}
%\end{figure*}
%\begin{figure}[t]
%\small\begin{flalign}
%& \F{tycon}\fvar{stringin}~\F{of}\FF{R}~\{\\
%& \quad \F{iana}\{\tlam{opidx}{\FF{String}}{
%	\tlam{tyidx}{\FF{R}}{
%	\tlam{a}{\klist{\Q}}{\\
%& \quad\quad \tvar{arity0}~\tvar{a}~(\tvar{check}~\tvar{opidx}~\tvar{tyidx}~\titerm{\iup{\tvar{opidx}}})
%	}}
%}\}\\
%& \quad \F{esyn}\{\tlam{opidx}{\kunit+(\FF{R}+\FF{R})}{
%	\tlam{a}{\klist{\Q}}{\\
%& \quad\quad \tsumcase{\tvar{opidx}}{\_}{\\
%& \quad\quad\quad \tvar{arity2}~\tvar{a}~\tlam{a1}{\Q}{\tlam{a2}{\Q}{\\
%& \quad\quad\quad\quad \tvar{rsyn}~\tvar{a1}~\tlam{r1}{\FF{R}}{\tlam{i1}{\kITerm}{~}}\\
%& \quad\quad\quad\quad \tvar{rsyn}~\tvar{a2}~\tlam{r2}{\FF{R}}{\tlam{i2}{\kITerm}{~}}\\
%& \quad\quad\quad\quad\quad (\ttype{stringin}{\FF{rseq}(\tvar{r1}; \tvar{r2})}, \\
%& \quad\quad\quad\quad\quad\titerm{{\tt iconcat}(\iup{\tvar{i1}}; \iup{\tvar{i2}})})
%}}\\
%& \quad\quad}{opidx'}{d}}
%}\}
%\};\\
%& \F{def}\tvar{concat} = \tinl{\kunit, \FF{R}+\FF{R}}{\tunit};\\
%& \F{def}\tvar{subst} = \tlam{r}{\FF{R}}{\tinr{\kunit, \FF{R}+\FF{R}}{\tinl{\FF{R},\FF{R}}{\tvar{r}}}};\\
%& \F{def}\tvar{coerce} = \tlam{r}{\FF{R}}{\tinr{\kunit, \FF{R}+\FF{R}}{\tinr{\FF{R},\FF{R}}{\tvar{r}}}}
%\end{flalign}
%\caption{Definition of $\phi_S$, which enables the embedding of fragment $S$ into $\lamAce$.}
%\end{figure}
%%\begin{figure}
%%\[
%%\begin{array}{lcl}
%%% & & Definition & Kind\\
%%\tvar{concat} & := & \tinl{\kunit, \FF{R}+\FF{R}}{\tunit}\\%& \kunit + (R + R)\\
%%\tvar{replace} & := & \tlam{r}{\FF{R}}{\tinr{\kunit, \FF{R}+\FF{R}}{\tinl{\FF{R},\FF{R}}{\tvar{r}}}}\\% & \karrow{a}{b}\\
%%\tvar{coerce} & := & \tlam{r}{\FF{R}}{\tinr{\kunit, \FF{R}+\FF{R}}{\tinr{\FF{R},\FF{R}}{\tvar{r}}}}\\
%%\end{array}
%%\]
%%\caption{Definitions}
%%\end{figure}
%
%\subsection{Background: Ace}
%TODO: Make a TR out of the OOPSLA submission.
%\subsection{Explicit Conversions}
%\subsection{Adding Subtyping to Ace}
%\subsection{Theory}
%
%\section{Related Work}
%
%\section{Discussion}
%
%
\bibliographystyle{abbrv}

\bibliography{research}

% The bibliography should be embedded for final submission.


%\begin{thebibliography}
%
%\bibitem{lamport94}
%Leslie Lamport,
%\emph{\LaTeX: a document preparation system}.
%Addison Wesley, Massachusetts,
%2nd edition,
%1994.
%
%\end{thebibliography}
\end{document}
