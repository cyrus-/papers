% !TEX root = omar-thesis.tex
\chapter{Introduction}
\section{Motivation}
Functional programming language designers often turn to minimal typed lambda calculi to develop a principled understanding of  fundamental metatheoretic issues, like type safety, and to examine the essential character of various primitives of interest. To design a ``full-scale''\footnote{Throughout this work, colloquialisms that should be read as having an intuitive meaning, rather than a strict mathematical meaning, will be first introduced with quotation marks.}  language, language designers must carefully ``combine'' such primitives and develop various generalizations and primitive ``embellishments'' motivated by human factors. 
For example, major functional programming languages like Standard ML (SML) \cite{mthm97-for-dart,harper1997programming}, OCaml \cite{ocaml-manual} and Haskell \cite{jones2003haskell} all primitively build in record types (generalizing the nullary and binary product types that suffice in simpler settings) because explicitly labeled components are cognitively useful to human programmers. Similarly, they all build in derived syntax (colloquially, ``syntactic sugar'') that decreases the syntactic cost of  common idioms, like list construction.% concision and readability. 

%
%Minimal typed lambda calculi play a central role in the study of programming languages, and serve as direct inspiration for  functional programming languages like ML. to be useful in practice, it must present a decidedly more elaborate concrete syntax and type structure to programmers, designed considering various human factors in addition to fundamental metatheoretic issues. For example, while it is quite common to study minimal calculi that build in only nullary and binary product types, Standard ML (SML) builds in record types, because labels are cognitively useful. %syntactic and semantic primitives that capture common idioms naturally and precisely.

 %The community around this language should, ideally, then be able to direct its efforts almost exclusively toward the development of useful libraries, rather than further modifications to the language itself.
One might hope that a limited number of semantic primitives and  primitive ``embellishments'' like these will suffice to go from minimal calculi to a broadly useful (or ``general-purpose'') programming language.  But a stable language design that fully achieves this ideal has yet to emerge, as evidenced by the diverse array of ``dialects'' that continue to proliferate around all major contemporary languages. % For example, let us consider the many dialects of ML. Though they generally agree on the importance of a powerful module system atop a core language based conceptually on the   polymorphic lambda calculus with recursive sum and product types, they all introduce various primitive syntactic and semantic extensions and tweaks of their own design (we cover several examples below). 
%Tools for  constructing new ``domain-specific'' dialects also continue to proliferate. % The situation is similar across all major language lineages. 
Indeed, tools that aid in the construction of so-called  ``domain-specific'' language dialects (DSLs)\footnote{Such dialects are also sometimes called ``external DSLs'', to distinguish them from  ``internal'' or ``embedded DSLs'', which are actually  library interfaces that  ``resemble'' distinct dialects \cite{fowler2010domain}.} are becoming increasingly prominent.
{This calls for an investigation}: why is it that programmers and researchers are still so often unable to satisfyingly express the constructs that they need in libraries, as modes of use of the ``general-purpose'' primitives already available in major languages today?
%Let us investigate why this is.
%What kinds of constructs are not expressible in languages like SML?

% Unlike libraries organized by a module system, language dialects are not trivially composable.%Constructing a software system using libraries written in different dialects is difficult because they cannot always be composed. %This suggests that library-based mechanisms are still not general enough to encompass many desirable modes of expression.   %Library implementations are not yet satisfying.
\subsection*{Why are there so many dialects?}
Perhaps the most common reason for this ongoing proliferation of dialects may simply be that the \emph{syntactic cost} of expressing a construct of interest using contemporary general-purpose primitives is not always ideal. In response, library providers construct \emph{syntactic dialects}, i.e. dialects that can be specified by purely syntactic (i.e. context-independent) elaboration to the existing language. In other words, they introduce only new derived forms. For example, Ur/Web is a syntactic dialect of Ur (a language that itself descends from ML) that builds in derived syntax for SQL queries, HTML elements and other datatypes used in the domain of web programming \cite{conf/popl/Chlipala15}. %Syntactic cost is often assessed qualitatively \cite{green1996usability}, though quantitative metrics can be defined. 
These are far from the only types of data that could similarly benefit from the availability of specialized derived syntax. As another example, we will consider regular expression patterns expressed using abstract data types (as a mode of use of the ML module system) in Sec. \ref{sec:syntax}. %We will be able to express precisely the semantics that we seek, but existing approaches for approximating the concrete syntax of patterns, e.g. using dynamic string parsing,  will leave something to be desired. 
% An extension of Moscow ML provided syntax for monads encoded using the module system, inspired by the  syntax built in to Haskell.\todo{asked for reference, if not found will say that "Harper reports..."} %In fact, nearly all major programming languages primitively build in derived syntax for constructs that can otherwise be expressed in the standard library, e.g. derived list syntax in SML \cite{harper1997programming,mthm97-for-dart}. 
Tools like Camlp4 \cite{ocaml-manual}, Sugar* \cite{erdweg2011sugarj,erdweg2013framework} and Racket \cite{Flatt:2012:CLR:2063176.2063195} have lowered the engineering costs of constructing syntactic dialects in such situations, contributing to their proliferation. %(we will consider them further in Sec. \ref{sec:syntax}). % contributing to their proliferation. 

%Many other data structures can similarly benefit from a decrease in syntactic cost. For example, we  will consider {regular expression patterns} encoded using abstract data types in Sec. \ref{sec:syntax}. 
%The syntactic cost of  such encodings, considered in several ways, can be reduced by using a dialect that builds in {syntactic sugar}  for regular expression patterns, and there are many tools that make constructing such syntactic dialects simple, e.g. Camlp4 \cite{OCaml-manual} and Sugar* \cite{erdweg2011sugarj,erdweg2013framework} (though as we will see, they come with costs of their own).   %Put another way, such embeddings may not preserve the cognitive cost associated with a construct (qualitative criteria are generally used to establish this \cite{green1996usability}). 

More advanced dialects introduce new type structure, going beyond what is possible with derived syntax. As a simple example, the static and dynamic semantics of records cannot be expressed by context-independent elaboration to a language with only nullary and binary products. Various  languages have explored ``record-like'' primitives that go still further, supporting ``functional update'' operators, width and depth coercions (sometimes implicit)%\cite{Cardelli:1984:SMI:1096.1098}
, methods, prototypic dispatch and other such ``semantic embellishments'' that cannot be expressed by context-independent expansion to a language with only standard record types (we will detail an  example in Sec. \ref{sec:metamodules}). OCaml primitively builds in the type structure of polymorphic variants, open datatypes and  operations that use format strings like $\mathtt{sprintf}$ \cite{ocaml-manual}. ReactiveML builds in primitives for functional reactive programming \cite{mandel2005reactiveml}. ML5 builds in high-level primitives for distributed programming based on a modal lambda calculus \cite{Murphy:2007:TDP:1793574.1793585}. Manticore \cite{conf/popl/FluetRRSX07} and AliceML  \cite{AliceLookingGlass} build in parallel programming primitives with a more elaborate type structure than is found in simpler accounts of parallelism. 
MLj builds in the type structure of the Java object system (motivated by a desire to interface safely and naturally with Java libraries) \cite{Benton:1999:IWW:317636.317791}. Other dialects do the same for other foreign languages, e.g. Furr and Foster describe a dialect of OCaml that builds in the type structure of C \cite{Furr:2005:CTS:1065010.1065019}. Tools like proof assistants and logical frameworks are used to specify and reason metatheoretically about dialects like these, and tools like compiler generators and language frameworks \cite{erdweg2013state} lower their implementation cost, again contributing to their proliferation. 

%We will also discuss labeled products, which unlike records maintain a row ordering (this makes it possible to introduce them without explicit labels, but eliminate them using labels). 

\subsection*{Dialects Considered Harmful}
% express record types as syntactic sugar over the simply-typed lambda calculus with  binary product types.\footnote{Pairs can of course be expressed as syntactic sugar atop records, though one could argue that using binary products as the more primitive concept is simpler.} The static semantics need to be extended with new type and term operators. However, the simplest way to express the dynamic semantics of the newly introduced term operators is by translation to nested binary products, so we can leave the operational semantics alone. \todo{fill this out} %For example, there are dozens of constructs that go by the name of ``records'' in various languages, each defined by a slightly different collection of primitive operations. \todo{examples} %, encouraged  historically  by the availability of tools like compiler generators and,  more recently, language workbenches \cite{workbenches} and DSL frameworks \cite{dsl}. Unfortunately, taking this approach makes it substantially more difficult for clients to import high-level abstractions orthogonally. 
% test 
The reason why this proliferation of language dialects should be considered alarming is that it is, in an important sense, anti-modular: a library written in one dialect cannot, in general, safely and idiomatically interface with a library written in another dialect. %At best, one can hope that the compilers for the decidedlytwo languages target a common intermediate language,  
As MLj demonstrates, addressing this interoperability problem requires somehow ``combining'' the  dialects into a single language. However, in the most general setting where the dialects in question might be specified by judgements of arbitrary form, this is not a well-defined notion. Even if we restrict our interest to dialects specified using formalisms that do operationalize the notion of dialect combination, there is generally no guarantee that the combined dialect will conserve important syntactic and semantic properties that can be established about the dialects in isolation. %In other words, any putative ``combined language'' must formally be considered a  distinct system for which one must derive essentially all metatheorems of interest anew, guided only informally by those derived for the dialects individually. %There is no well-defined mechanism for constructing such a ``combined language'' in general. 
For example, consider two syntactic dialects, one specifying derived syntax for finite mappings, the other specifying a similar syntax for ordered finite mappings. Though each dialect can be shown to have an unambiguous concrete syntax in isolation, when their grammars are na\"ively  combined by, for example, Camlp4,  ambiguities  arise.  % would generally attempt to combine their semantics, particularly when they are specified in very different ways. %the ideas housed in one dialect are often only available to programmers willing to do without ideas housed in other dialects. 
%It is thus infeasible to simply allow different contributors to a software system to choose their own favorite dialect for each component they are responsible for. %A complex software system written in multiple distinct language dialects is far too unwieldy for it to be viable. 
%It it clear that dialects are better rhetorical devices than practical engineering artifacts. 
Due to this paucity of modular reasoning principles, the ``dialect-oriented'' approach (also called the ``language-oriented approach'' \cite{journals/stp/Ward94}) is not sensible for software development ``in the large''. %Large software projects and software ecosystems must pick a single language that does provide powerful modular reasoning principles and, to benefit from them, stay inside it.

%\subsection{Reducing the Need For Dialects}
Dialect designers must instead take a less direct approach to have an impact on large-scale software development: they must convince the designers in control of comparatively popular languages, like OCaml and Scala, to include some suitable variant of the primitives they espouse into backwards compatible language revisions. %These decisions are increasingly influenced by community processes, e.g. the Scala Improvement Process.  %This approach concentrates power as well as responsibility over maintaining metatheoretic guarantees in the hands of a small group of language designers, though increasingly influenced by various community processes (e.g. the Scala Improvement Process). 
%Dialects thus serve the role of rhetorical vehicles for new ideas, rather than direct artifacts. 
%Over time, accepting such extensions has caused these languages to balloon in size. 
This \emph{ad hoc} approach is not sustainable, for three main reasons. First, as suggested by the diversity of examples given above, there are simply too  many potentially useful such primitives, and many of these are only relevant in relatively narrow application domains (for derived syntax, our group has  gathered initial data speaking to this \cite{TSLs}). Second, primitives introduced earlier in a language's lifespan end up monopolizing finite ``syntactic resources'', forcing subsequent primitives to use ever more esoteric forms. And third, primitives that prove to be flawed in some way cannot be removed or changed without breaking backwards compatibility. %rimitives that are only situationally useful, or that trigger aesthetic disagreements between different factions of the community, are still quite often left languishing in impractical ``toy'' dialects. 
%Recalling the words of  Reynolds, which are clearly as relevant today as they were almost half a century ago \cite{Reynolds70}:%Because there is no data about how useful a construct is in practice until it is included in a language like this, decisions about which constructs to include are often informed by little more than intuition. %This approach is antithetical to the ideal of a truly \emph{general-purpose language} described at the beginning of this section.
%\newpage
%\begin{quote}\textit{The recent development of programming languages suggests that the simul\-taneous achievement of simplicity 
%and generality in language design is a serious unsolved 
%problem.}\begin{flushright}--- John Reynolds (1970)\end{flushright}
%\end{quote}

%A measured approach to incorporating new primitives into a general-purpose programming language is  sensible because once a primitive is introduced, it becomes entrenched as-is and monopolizes ``syntactic resources'', as we will discuss below. 
This leaves the subset of the  language design community interested in keeping general-purpose languages small and free of \emph{ad hoc} primitives with two possible paths forward. One, exemplified (arguably) by SML, is to simply eschew the introduction of specialized syntax and type structure and settle on the existing primitives, which can be said to sit at a ``sweet spot'' in the overall language design space (accepting that in some circumstances, this trades away expressive power or leads to  high syntactic cost). % that this implies.  
The other is to search for more general primitives that reduce the primitives found in dialects today to modularly composable library constructs. % so that they can be evaluated on their individual merits by programmers and used together without the possibility of conflict. % This should render the construction of new dialects increasingly unnecessary. 
Encouragingly, primitives of this sort do occasionally arise. For example, a recent revision of OCaml added support for  ``generalized algebraic data types'' (GADTs), based on research on guarded recursive datatype constructors \cite{XiCheChe03}. Using GADTs, OCaml was able to move some of the \emph{ad hoc} machinery for typechecking operations that use format strings, like \texttt{sprintf}, out of the language and into a library (however, syntactic machinery remains primitively built in). 

%Similarly, it recently introduced ``open datatypes'', which subsume its previous more specialized exception type, and captures many use cases for .

%Viewed ``dually'', one might equivalently ask for a language that builds in a core that is as small as possible, but provides expressive power comparable to languages with much larger cores. This is our goal in the work being proposed. 

%\vspace{-10px}
\section{Contributions}
%Our broad aim in the work being proposed is to introduce primitive language mechanisms that give library providers the ability to  express new syntactic expansions as well as new types and operators in a safe and modularly composable manner. 
Our aim in the work being proposed is to introduce primitive language constructs that take further steps down the second path just described. In particular, we plan to introduce the following constructs:
% By supporting the primitives that we introduce, 1) Verse will be smaller than comparable languages like ML and Scala, and 2) dialect formation will be less frequently necessary. In other words, these primitives reduce the need for many others:%This eliminates the needs to build in fewer \emph{ad hoc} constructs and dialects are less frequently necessary. %thereby reducing the need for language dialects and revisions. 

%Verse features a module system taken directly from SML. Unlike SML, the Verse core language is split into a \emph{typed external language} (EL) specified by {type-directed translation} to a minimal \emph{typed internal language} (IL). 
\begin{enumerate}
\item \textbf{Typed syntax macros} (TSMs), introduced in Sec. \ref{sec:syntax}, reduce the need to primitively build in derived concrete syntax specific to library constructs, e.g. list syntax as in SML or XML syntax as in Scala and Ur/Web, by giving library providers static control over the parsing and expansion of delimited segments of concrete syntax (at a specified type or parameterized family of types). %We show how TSMs can be invoked explicitly by clients, or, implicitly based on local type inference.
\item \textbf{Metamodules}, introduced in Sec. \ref{sec:metamodules}, reduce the need to primitively build in the type structure of constructs like records (and variants thereof),  labeled sums and other more esoteric constructs that we will introduce later by giving library providers programmatic hooks directly into the semantics. %For example, a library provider can implement the type structure of records with a metamodule that:
%\begin{enumerate}
%\item introduces a type constructor, \lstinline{record}, parameterized by finite mappings from labels to types, and defines, programmatically, a translation to unary and binary product types (which are built in to the internal language); and 
%\item introduces operators used to work with records, minimally record introduction and elimination (but perhaps also various functional update operators), and directly implements the logic governing their typechecking and translation to the IL (which builds in only nullary and binary products). 
%\end{enumerate}
We will see direct analogies between ML-style modules and metamodules in Sec. \ref{sec:metamodules}.
\end{enumerate} 
Both TSMs and metamodules involve \emph{static code generation} (also called \emph{static} or \emph{compile-time metaprogramming}), meaning that the relevant rules in the static semantics of the language call for the evaluation of \emph{static functions} that generate static representations of expressions and types. %Library providers write these static functions using the Verse \emph{static language} (SL). 
This design has conceptual roots in earlier work on \emph{active libraries}, which similarly envisioned using compile-time computation to give library providers more control over aspects of the language and compilation process \cite{active-libraries-thesis}. %Maintaining a separation between the static (or ``compile-time'') phase and the dynamic (or ``run-time'') phase is an important facet of Verse's design. % static code generation. %We will  also introduce a simple variant of each of these primitives that leverages Verse's support for local type inference to further reduce syntactic cost in certain common situations. 

The main challenge in the design of these primitives will come in ensuring that they are metatheoretically well-behaved. If we are not careful, many of the problems  that arise when combining language dialects, discussed earlier, could simply shift into the semantics of these primitives.\footnote{This is why languages  like Verse are often called \emph{extensible languages}, though this is somewhat of a misnomer. The defining characteristic of an extensible language is that it \emph{doesn't} need to be extended in situations where other languages would need to be extended. We will avoid this somewhat confusing terminology.} Our main technical contributions will be in rigorously showing how to address these problems in a principled manner. In particular, syntactic conflicts will be impossible by construction and the semantics will validate code statically generated by TSMs and metamodules to maintain a strong \emph{hygienic type discipline} and, most uniquely, powerful \emph{modular reasoning principles}. In other words, library providers will have the ability to reason about the constructs that they have defined in isolation, and clients will be able to use them safely in any program context and in any combination, without the possibility of conflict.\footnote{This is not quite true -- simple naming conflicts can arise. We will tacitly assume that they are being avoided extrinsically, e.g. by using a URI-based naming scheme as in the Java ecosystem.} We will make these notions completely precise as we continue.

As vehicles for this work, we plan to formally specify typed lambda calculi that capture each of the novel primitives that we introduce ``minimally''. We will also describe (but not formally specify) a new ``full-scale'' functional language called Verse.\footnote{We distinguish Verse from Wyvern, which is the language referred to in prior publications about some of the work being proposed here, because Wyvern is a group effort evolving independently in some important ways.} The reason we will not follow Standard ML \cite{mthm97-for-dart} in giving a complete formal specification of Verse is both to emphasize that the primitives we introduce can be considered for inclusion in a variety of language designs, and to avoid distracting the reader with specifications for ``orthogonal'' primitives that are already well-understood in the literature. %We anticipate that future full-scale language specifications will be able to combine the ideas  in the proposed work without trouble. %The purpose of the work being proposed is to serve as a reference for those interested in the new constructs we introduce, not to serve as a language specification. 
We will give a brief overview covering how these languages are organized in Sec. \ref{sec:verse}.

\subsubsection*{Thesis Statement}
In summary, we propose a thesis defending the following statement:
\begin{quote}
A functional programming language can give library providers the ability to %meta\-pro\-gram\-matic\-ally 
express new syntactic expansions and new type structure atop a minimal type-theoretic internal language while maintaining a hygienic type discipline and modular reasoning principles. %These  primitives are  expressive enough to subsume the need for a variety of primitives that are, or would need to be, built in to comparable contemporary languages.
\end{quote}

\subsubsection*{Disclaimers}
Before we continue, it may be useful to explicitly acknowledge that completely eliminating the need for dialects would indeed be asking for too much: certain design decisions are fundamentally incompatible with others or require coordination across a language design. We aim only to decrease the need for dialects.% out a larger design space within a single language, Verse.%a subset of constructs that can be specified by a semantics of a certain ``shape'' specified by Verse (we will make this more specific later). %There is nothing ``universal'' about Verse.

It may also be useful to explicitly acknowledge that library providers could leverage the primitives we introduce   to define constructs that are in ``poor taste''. We  expect that in practice, Verse will come with a standard library defining a carefully curated collection of standard constructs, as well as guidelines for advanced users regarding when it would be sensible to use the mechanisms we introduce (following the example of languages that support operator overloading or type classes \cite{Hall:1996:TCH:227699.227700}, which also have the potential for such ``abuse''). For most programmers, using Verse should not be substantially different from using a language like ML or one of its dialects.%The vast majority of programmers should not use the primitives that we introduce directly.

Finally, Verse intentionally is not a dependently-typed language like Coq, Agda or Idris, because these languages do not maintain a phase separation between ``compile-time'' and ``run-time.'' This phase separation is useful for programming tasks (where one would like to be able to discover errors before running a program, particularly programs that may have an effect) but less so for theorem proving tasks (where it is mainly the fact that a pure expression is well-typed that is of interest, by the propositions-as-types principle). Verse is designed to be used for programming tasks where SML, OCaml, Haskell or Scala would be used today, not for advanced theorem proving tasks. That said, we conjecture that the primitives we describe could be added to languages like Gallina (the ``external language'' of the Coq proof assistant  \cite{Coq:manual}) or to the program extraction mechanisms of proof assistants like Coq with  modifications, but do not plan to pursue this line of research in this dissertation. %Our interest is in making sure that the standard library is no more privileged than any other library. % Our interest is not in creating a universal language, only one that is as expressive as reasonably possible. %only in a subset of all constructs that can be specified in a mutually orthogonal manner by a semantics of a certain prototypic ``shape''. We will make this more specific later. 
