
%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************

% *** Authors should verify (and, if needed, correct) their LaTeX system  ***
% *** with the testflow diagnostic prior to trusting their LaTeX platform ***
% *** with production work. IEEE's font choices can trigger bugs that do  ***
% *** not appear when using other class files.                            ***
% The testflow support page is at:
% http://www.michaelshell.org/tex/testflow/



% Note that the a4paper option is mainly intended so that authors in
% countries using A4 can easily print to A4 and see how their papers will
% look in print - the typesetting of the document will not typically be
% affected with changes in paper size (but the bottom and side margins will).
% Use the testflow package mentioned above to verify correct handling of
% both paper sizes by the user's LaTeX system.
%
% Also note that the "draftcls" or "draftclsnofoot", not "draft", option
% should be used if it is desired that the figures are to be displayed in
% draft mode.
%
\documentclass[10pt, conference, compsocconf]{IEEEtran}
% Add the compsocconf option for Computer Society conferences.
%
% If IEEEtran.cls has not been installed into the LaTeX system files,
% manually specify the path to it like:
% \documentclass[conference]{../sty/IEEEtran}


\usepackage{cite}
% IEEE wants to use ],\,[ for this
% but that looks dumb...
\renewcommand{\citepunct}{,\,}


%\usepackage{alltt}
\renewcommand{\ttdefault}{txtt}
% Some very useful LaTeX packages include:
% (uncomment the ones you want to load)


% *** MISC UTILITY PACKAGES ***
%
%\usepackage{ifpdf}
% Heiko Oberdiek's ifpdf.sty is very useful if you need conditional
% compilation based on whether the output is pdf or dvi.
% usage:
% \ifpdf
%   % pdf code
% \else
%   % dvi code
% \fi
% The latest version of ifpdf.sty can be obtained from:
% http://www.ctan.org/tex-archive/macros/latex/contrib/oberdiek/
% Also, note that IEEEtran.cls V1.7 and later provides a builtin
% \ifCLASSINFOpdf conditional that works the same way.
% When switching from latex to pdflatex and vice-versa, the compiler may
% have to be run twice to clear warning/error messages.






% *** CITATION PACKAGES ***
%
% cite.sty was written by Donald Arseneau
% V1.6 and later of IEEEtran pre-defines the format of the cite.sty package
% \cite{} output to follow that of IEEE. Loading the cite package will
% result in citation numbers being automatically sorted and properly
% "compressed/ranged". e.g., [1], [9], [2], [7], [5], [6] without using
% cite.sty will become [1], [2], [5]--[7], [9] using cite.sty. cite.sty's
% \cite will automatically add leading space, if needed. Use cite.sty's
% noadjust option (cite.sty V3.8 and later) if you want to turn this off.
% cite.sty is already installed on most LaTeX systems. Be sure and use
% version 4.0 (2003-05-27) and later if using hyperref.sty. cite.sty does
% not currently provide for hyperlinked citations.
% The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/cite/
% The documentation is contained in the cite.sty file itself.






% *** GRAPHICS RELATED PACKAGES ***
%
\ifCLASSINFOpdf
  % \usepackage[pdftex]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../pdf/}{../jpeg/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.pdf,.jpeg,.png}
\else
  % or other class option (dvipsone, dvipdf, if not using dvips). graphicx
  % will default to the driver specified in the system graphics.cfg if no
  % driver is specified.
  % \usepackage[dvips]{graphicx}
  % declare the path(s) where your graphic files are
  % \graphicspath{{../eps/}}
  % and their extensions so you won't have to specify these with
  % every instance of \includegraphics
  % \DeclareGraphicsExtensions{.eps}
\fi
% graphicx was written by David Carlisle and Sebastian Rahtz. It is
% required if you want graphics, photos, etc. graphicx.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at: 
% http://www.ctan.org/tex-archive/macros/latex/required/graphics/
% Another good source of documentation is "Using Imported Graphics in
% LaTeX2e" by Keith Reckdahl which can be found as epslatex.ps or
% epslatex.pdf at: http://www.ctan.org/tex-archive/info/
%
% latex, and pdflatex in dvi mode, support graphics in encapsulated
% postscript (.eps) format. pdflatex in pdf mode supports graphics
% in .pdf, .jpeg, .png and .mps (metapost) formats. Users should ensure
% that all non-photo figures use a vector format (.eps, .pdf, .mps) and
% not a bitmapped formats (.jpeg, .png). IEEE frowns on bitmapped formats
% which can result in "jaggedy"/blurry rendering of lines and letters as
% well as large increases in file sizes.
%
% You can find documentation about the pdfTeX application at:
% http://www.tug.org/applications/pdftex





% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/





% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/




% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/


%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/


% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.


%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/





% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.



%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/




% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/



%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.





% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.

\usepackage{color}



% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\input{macros}

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{\Ace: An Actively-Typed Compilation Environment\\for High-Performance Computing}


% author names and affiliations
% use a multiple column layout for up to two different
% affiliations

\author{\IEEEauthorblockN{Cyrus Omar, Nathan Fulton, Sharschchandra Bidargaddi and Jonathan Aldrich}
\IEEEauthorblockA{School of Computer Science\\
Carnegie Mellon University\\
Pittsburgh, PA, USA\\
\url{http://www.acelang.org/}
}}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

\begin{abstract}
We introduce the Ace compilation environment and demonstrate its practicality as a foundational tool for both high-performance computing research and in practice. 
Ace consists of a statically-typed programming language with user-extensible semantics controlled by a compile-time meta\-language, Python. Users specify new primitive types and their operations by equipping type definitions, which are first-class objects in the metalanguage, with  methods that the compiler selectively invokes when type checking and translating expressions, a mechanism we call {\em active type-checking and translation (\ATT)}. This mechanism allowed us to express the primitives of the C99 and OpenCL languages as simple modules within Ace. We then give examples of several first-class parallel abstractions that can be defined and used alongside these basic primitives, demonstrating the foundational role that an actively-typed system like Ace can play for researchers and domain experts developing first-class language abstractions, as well as practitioners wishing to use multiple such abstractions within a single program. Active library support in Ace also supports more general forms of type-aware metaprogramming, and Ace functions can be compiled and launched directly from Python, taking its standard numeric data structures as arguments.
Using active library support in Ace, we designed a scientific simulation framework that allows users to modularly specify, compile and orchestrate the execution of parameterized families of scientific simulations on clusters of GPUs. This framework has been used to successfully conduct large-scale, high-performance neuroscience simulations, providing initial evidence that Ace can be used, at scale, in practice today.
\end{abstract}

%\begin{IEEEkeywords}
%programming languages, heterogeneous computing, metaprogramming, code generation
%\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
\IEEEpeerreviewmaketitle



\section{Introduction}

Computer-aided simulation and data analysis techniques have transformed science and engineering. Surveys show that scientists and engineers now spend up to 40\% of their time writing software \cite{howison2011scientific, hannay2009scientists}. Most of this software targets desktop hardware and about 20\% of scientists target either local clusters or super\-computers for more numerically-intensive computations as well \cite{hannay2009scientists}. To fully harness the power of this modern hardware, however, these {\em professional end-user developers} \cite{segal2007some} must write parallel programs.

Professional end-users today generally use high-level scripting languages like MATLAB, Python, R or Perl for tasks that are not performance-intensive, such as small-scale data analysis and plotting \cite{nguyen2010survey}. For tasks where these interpretted languages are too slow, they generally call into code written in a statically-typed, low-level language like C and Fortran and use low-level parallel abstractions like pthreads and MPI \cite{4222616,basili2008understanding}. Unfortunately, these low-level languages and abstractions are notoriously error-prone and difficult to use, even for expert programmers. {\color{red} CITATION?}

The research community has proposed dozens of novel language features and parallel programming abstractions that aim to  more equitably balance important concerns relating to performance, portability, verifiability and ease-of-use. Unfortunately, professional end-users have not commonly adopted these approaches, and many have become generally skeptical of new approaches originating in the research community. This viewpoint was perhaps most succinctly expressed by a participant interviewed in a recent study by Basili et al. \cite{basili2008understanding}, who stated ``I hate MPI, I hate C++. [But] if I had to choose again, I would probably choose the same.'' Although this sentiment is easy to dismiss as paradoxical, we believe that it demands direct examination by researchers working to advance the practice of scientific and high-performance computing. 

One reason for this gap between research and practice is because new features and abstractions are often developed and distributed together with a new programming language. Some prominent examples include:
\begin{itemize}
\item UPC, Fortress, X10 and Chapel, each featuring some form of first-class partitioned global address space (PGAS) support;
\item Erlang, Charm++, Occam and Axum, featuring some form of first-class support for message-passing; 
\item Cilk and NESL, featuring nested data parallelism
\item {\color{red} should I flesh this out more? less?}
\end{itemize}

Unfortunately, using a domain-specific research language comes with a host of challenges. {\color{red} List challenges here?} Indeed, the most widely adopted parallel programming abstractions have been those that are distributed as libraries, such as MapReduce, or as simple, conservative language extensions available in existing compilers, such as OpenMP. 

Ace is a language-integrated compilation environment that aims to make it easier for researchers to introduce new first-class language constructs as libraries. A {\em compilation environment} is a framework that allows users to programmatically control the compilation of programs. In Ace, users can interleave two kinds of program logic: compile-time and run-time. The compile-time logic, written in the {\em metalanguage}, is the top-level code in each file. Here, users can define and import new primitive types and operators, generate functions programmatically, perform arbitrary code transformations and emit functions for later execution. Ace also permits an interactive mode of use whereby the functions can also be executed immediately after being defined, a common usage scenario for professional end-users.

Ace is an {\it actively-typed} compilation environment. This means that types are first-class objects in the metalanguage, and that the logic needed to typecheck and compile the operators associated with a type is defined alongside the type itself. The process by which this occurs is called {\em active typechecking and translation (\ATT)}, and we discuss it in detail in Section \ref{att}. \ATT~is flexible enough that we are able to define the entirety of the C99 and OpenCL languages   with it, demonstrating its practicality and providing a foundation for higher-level abstractions that we discuss in Section \ref{abstractions}. Notably, these abstractions can be imported piecemeal as libraries -- they are not defined as new languages, nor as extensions for particular compilers.

Although the \ATT~mechanism is designed for use by researchers and domain experts, Ace is designed to be practical for professional end-user developers as well. It is based on the Python programming language, which is among the most broadly adopted languages in these communities. Indeed, the language itself is implemented entirely as a Python library -- no new executables need to be installed. Extension writers can target arbitrary backend languages and use existing compilers for back-end optimization. In this paper, we demonstrate the use of the flexible OpenCL platform for this purpose. Using these capabilities, we developed a 

In addition to the general introduction of Ace as a foundational tool for research and practice and generalizable lessons relating to language design that we note below, we highlight several individual contributions in this paper: 

\begin{itemize}
\item \ATT, a generalization of active libraries, where types are metalanguage objects and programs are given semantics by type-associated methods called by the compiler.
\item A method for eliminating type annotations by using a form of type inference within functions and type propagation between functions.
\item A method to check the correctness of generated code, by checking for satisfaction of representational consistency constraints associated with types, defined in Section \ref{repcon}. 
\item Several type-aware code generation and simulation orchestration techniques used in the clegans library, described in Section \ref{clegans}.
\end{itemize}

%Researchers design and implement novel parallel programming abstractions\- on a regular basis. Each abstraction aims to make some class of developers more productive by making appropriate trade-offs between performance, portability, verifiability and ease-of-use. It can be observed that the most widely-adopted abstractions to date are those that been implemented as libraries that can be easily deployed within existing, widely-used languages. Abstractions that require introducing new primitive constructs, changing the semantics of existing constructs in particular contexts, or controlling compilation in a fine-grained manner cannot take this approach. This has led to a proliferation of specialized programming languages, each designed around a few privileged abstractions. Unfortunately, such languages have not been widely adopted by practitioners.
%
%slash
%
%Although researchers often propose higher-level language features and parallel programming abstractions that aim to strike a better balance between raw performance, productivity, code portability and verifiability (see Section 2), end-users remain skeptical of new approaches. This viewpoint was perhaps most succinctly expressed by a participant interviewed in a recent study \cite{basili2008understanding}, who stated ``I hate MPI, I hate C++. [But] if I had to choose again, I would probably choose the same.'' Although this sentiment is easy to dismiss as paradoxical, we believe that it demands direct examination by those in the research community working to advance the practice of scientific and high-performance computing. We begin in Section 2 by developing a set of design and adoption criteria for new languages and abstractions based on prior empirical studies of these {\it professional end-user developers} as well as our observations of characteristics common to successful projects in the past. 

%
% Two types of languages see widespread use: productivity-oriented and performance-oriented
% Significant diversity in productivity-oriented languages. Valued for clean syntax and high-level abstractions. Usually very slow. Have a FFI to call into a performance-oriented language.
% Performance-oriented languages -- C or Fortran and their derivatives. Direct memory access, low-level abstractions, more verbose. Portable (though often need to include platform-specific optimizations, which can lead to messy code). Not easily extended with new abstractions and primitives (witness: lots of derivative languages that are not composable because no way to implement these abstractions cleanly)
% Generally don't support verifiability very well (performance-oriented languages have simple type systems); only exception is functional languages.
% 

% Simplicity (Errors, Syntax, Core Semantics)
% Extensibility (New Abstractions, Domain-Specific Things, Domain- and Platform-Specific Optimizations)
% Performance (Need to allow control over data layout and movement, perhaps optionally)
% Portability (Architectures and operating systems; support new optimizations)
% Backwards-Compatibility (Existing codebases)
% Verifiability (type systems, metaprogramming-based, formal semantics, small TCB)
% Tool Support (syntax highlighting, editors, debuggers, etc.)
% Social Proof (Will not disappear - open source, significant projects have been developed, community)

%We then introduce a new programming language named $\cloquence$ (pronounced ``C eloquence'') in Section 3. $\cloquence$ initially targets code paths where low-level languages, particularly OpenCL, would be used today. By employing a collection of powerful front-end language and compiler design techniques, making pragmatic design choices, and building on top of established infrastructure, we argue that $\cloquence$ may uniquely satisfy many of the criteria established in Section 2, particularly those related to ease of use, familiarity, performance and tool support.
%
%Unlike many existing languages, $\cloquence$ is designed to be highly extensible from inception, employing a powerful compile-time language extension and code generation mechanism based around the concept of {\it active libraries} \cite{activelibraries}. We argue that this feature may make $\cloquence$ particularly suitable as a platform for researchers developing new parallel abstractions and other specialized, high-level language features, as well as  development tools.
%
%In Section 4 we briefly describe a case study where the language was used to conduct large-scale spiking neural circuit simulations on GPU hardware, demonstrating the feasibility of this approach on a non-trivial problem. Finally, conclude in Section 6 with future directions for both the $\cloquence$ language and the research community.
%

\section{ACE: An \underline{A}ctively-Typed \underline{C}ompilation \underline{E}nvironment}
Ace is based on the Python programming language and implemented entirely as a Python package. The metalanguage is Python itself, the object language uses Python's grammar directly, and the compiler is implemented in Python as well. Write some more here. Why Python? Popularity and to aid in adoption: can be installed just like any other Python module, uses Python's module system and distribution infrastructure, piggybacks on existing Python toolchain. 

We now describe a programming language designed with many of the criteria described in the previous sections in mind, $\cloquence$. $\cloquence$ is built around a minimal core and nearly every construct in the language is implemented as a library. Rather than beginning directly with this extension mechanism, however, let us begin with a concrete example of the language in use.

\subsection{Example: Higher-Order Map for OpenCL}
Figure \ref{map} shows the standard data-parallel map function written using an extension that implements the full OpenCL language as a library. Each thread, indexed by \verb|gid|, applies the transfer function, \verb|fn|, to the  corresponding element of the input array, \verb|in|, writing the result into the corresponding location in the output array, \verb|out|.

\subsection{Syntax}
Readers familiar with the Python programming language will recognize the style of syntax used in Figure \ref{map}. In fact, $\cloquence$ uses the Python grammar and parsing facilities directly. Several factors motivated this design decision. First, Python's syntax is widely credited as being particularly simple and readable, due to its use of significant whitespace and conventional mathematical notation. Python is one of the most widely-used languages in scientific computing, so its syntax is already familiar to much of the field. And significantly, a large ecosystem of tools already exist that work with Python files, such as code editors, syntax highlighters, style checkers and documentation generators. These can be used without modification to work with $\cloquence$ files. Therefore, by re-using an existing, widely-used grammar, we are able to satisfy many of the design criteria described in Section \ref{syntax} and the adoption criteria described in Section \ref{tools} without significant development effort.

\begin{figure}
\small{
\begin{verbatim}
from ace.OpenCL import OpenCL, get_global_id

@OpenCL.fn
def map(in, out, fn):
    gid = get_global_id(0)
    out[gid] = fn(in[gid])
\end{verbatim}
}
\vspace{-10pt}
\caption{A generic data-parallel map function written using the user-defined Ace OpenCL module.}
\label{map}
\end{figure}
\begin{figure}
\small{
\begin{verbatim}
from figure1 import map
from ace.OpenCL import global_ptr, double, sin
    
T = global_ptr(double)
map_sin_dbl = map.compile(T, T, sin.cl_type)
\end{verbatim}
}
\vspace{-10pt}
\caption{The generic map function compiled to map the sin function over global arrays of double-precision floating-point numbers. The \texttt{get\_global\_id} and \texttt{sin} functions are OpenCL primitives.}
\label{mapsindblace}
\end{figure}
\begin{figure}
\small{\begin{verbatim}
#pragma OPENCL EXTENSION cl_khr_fp64 : enable

__kernel void map_sin_dbl(
  __global double* in, 
  __global double* out) 
{
    size_t gid;
    gid = get_global_id(0);
    out[gid] = sin(in[gid]);
}\end{verbatim}
}
\vspace{-10pt}
\caption{The OpenCL kernel function generated by running \texttt{acecc figure2.py}, or by executing the  \texttt{print map\_sin\_dbl.code} statement.}
\label{mapsinint}
\vspace{-10pt}
\end{figure}

\subsection{Semantics}
$\cloquence$ is a compiled, statically-typed language. The extension used in Figure \ref{map} implements the full OpenCL type system, which includes features inherited from C99 like pointer arithmetic and OpenCL-specific constructs like vector types. In fact, compilation of Figure \ref{map} will produce code semantically equivalent, and with the same performance profile, as manually-written OpenCL code. Compilation produces OpenCL source code, so $\cloquence$, when used with this extension, inherits OpenCL's portability profile as well, as described in Section \ref{portability}.

In OpenCL itself, however, there is no way to write a function like \verb|map|. As described in Section \ref{hof}, OpenCL lacks support for higher-order functions or polymorphism (over the types of \verb|in| and \verb|out| in this case.) To map a function over an array, developers must create a separate function for every combination of argument types and for every transfer function. Figure 2 shows an OpenCL kernel that implements a map specifically for the \verb|sin| function applied to arrays of doubles in global memory. Note that because OpenCL does not support templates or function pointers, this is the most general solution possible without explicit code generation. However, even in CUDA, which does support templates, there is greater syntactic overhead for specializing a function with particular types than in $\cloquence$, where it happens implicitly.

To support this much more concise form for specifying kernels, $\cloquence$ uses techniques pioneered by functional programming languages. We briefly describe these below.

\subsubsection{Type, Kernel and Extension Inference}
As described in Section \ref{syntax}, professional end-users tend to prefer languages that do not require explicit type annotations for variables. These languages accomplish this by using dynamic typing, so that types are associated with values instead. Statically-typed functional programming languages have also eliminated type annotations in many cases, however, using a technique known as {\it type inference} \cite{tapl}. 

Type inference is a technique for giving types to variables by examining how these variables are being used. As a simple example, in Figure \ref{map}, the variable \verb|gid| is being used to hold the result of calling the \verb|get_global_id| function so the type of \verb|gid| must be consistent with the return type of that function, \verb|size_t| (a device-dependent integer type.) Note, however, that in C99, many possible integer types can be given to \verb|gid| (in practice, a 32-bit integer is often used.) Picking a specific type may require further examining how \verb|gid| is used in the remainder of the function. 
To deal with this non-locality, type inference is typically cast as a constraint solving problem -- the type of each program variable is treated as an unknown and each use of the variable introduces a new constraint. A constraint-solving algorithm, generally a variant of unification, can be used to find a type assignment that satisfying all constraints.

$\cloquence$ uses a variant of this approach (modified to admit extensions to the type system, as we will discuss shortly) to conduct whole-function type inference. This approach differs from the HM algorithm, however, which conducts whole-program (or whole-file) inference and assigns a single type to function arguments. In $\cloquence$, types are {\it propagated} to functions from their calling sites (to enable structural polymorphism, described below) and inference occurs only within a function body.

In addition to type annotations, OpenCL introduces additional syntactic burdens. Developers must annotate functions that meet the requirements to be called from the host with the \verb|__kernel| attribute, and several types (notably, \verb|double|) and specialized functions require that an OpenCL extension be enabled with a \verb|#pragma| (as  can be seen in Figure \ref{mapsinint}.) The OpenCL extension we have developed automatically infers many of these annotations as well, consistent with the principle of conciseness described in Section \ref{syntax}.

\subsubsection{Structural Polymorphism}
In Section \ref{hof}, we discussed several strategies for achieving {\it polymorphism} -- the ability to create functions and data structures that operate over more than a single type. In $\cloquence$, all functions are implicitly polymorphic and can be called with arguments of {\it any type that supports the operations used by the function}. For example, in Figure \ref{map}, \verb|in| can be any type that supports indexing by a variable of type \verb|size_t| to produce a value of a type that can be passed into \verb|fn|, which must then produce a value consistent with indexing into \verb|out|. OpenCL pointer types are consistent with these constraints, for example. Although powerful, this also demonstrates a caveat of this approach -- that it is more difficult to give a function a concise signature, because arguments are constrained by capability, rather than to a single type \cite{malayeri2009structural}.

Structural typing can be compared to the approach taken by dynamically-typed languages that rely on ``duck typing''. It is more flexible than the parametric polymorphism found in many functional languages and in languages like Java (which only allow polymorphic functions that are valid for {\it all} possible types), but is of comparable strength to the template system found in C++. It can be helpful to think of each function as being preceded by an implicit template header that assigns each argument its own unique type parameter. At function call sites, these parameters are implicitly specialized with the types of the provided arguments. This choice is again motivated by the criteria of conciseness given in Section \ref{syntax}.

\subsubsection{Higher-Order Functions}
Section \ref{hof} also discusses the value of higher-order functions. The OpenCL extension supports higher-order functions, despite the absence of function pointers from OpenCL itself, by explicitly passing functions as constants at compile-time. In other words, each function {\it uniquely inhabits} a type corresponding to it.

Functions are not, however, {\it first-class} -- references to functions cannot be stored in memory, for example. Most use cases that we have considered thus far have never needed to do so, however. Compared to the function pointer approach used in other C-based languages, this approach is more efficient. It can, however, result in ``code bloat'', since a new copy of the higher-order function is created for each unique function argument passed to it. First-class functions can theoretically be simulated using an auxiliary lookup function in OpenCL, and we leave clean support for this in $\cloquence$ as open future work.

\subsection{Active Libraries in $\cloquence$}
In addition to adopting Python's grammar, $\cloquence$ uses the Python language itself as a {\it compile-time metalanguage}. Every $\cloquence$ file is, at the top-level, a Python script. This script is executed during compilation and has access to a number of powerful capabilities that allow developers to influence the compilation process and manipulate programs directly. Libraries that have such capabilities has been called {\it active libraries} in prior proposals \cite{activelibraries}. A number of  projects, such as Blitz++, have taken advantage of the C++ preprocessor and template-based metaprogramming system to implement domain-specific optimizations. In $\cloquence$, we replace these brittle mini-languages with a general-purpose language. This allows for several interesting uses that we discuss in the following sections.

\subsection{Module System}
In Figure \ref{map}, the only compile-time operations are library imports and a declaration of a $\cloquence$ function. However, this already demonstrates an important benefit of this approach: $\cloquence$ uses Python's simple but flexible module system. As a consequence, libraries written using $\cloquence$ can directly utilize the module distribution infrastructure available for Python, partially relieving the issues discussed in Section \ref{modularity}.

\subsection{Compilation and Invocation}
$\cloquence$ functions can be invoked in one of two ways: from any host language supporting OpenCL by using the standalone compiler, or directly from Python itself. 
\begin{figure}\small{\begin{verbatim}
from figure1 import map
from clq.backends.opencl import double, sin

map_sin_double = map.specialize(
    double.global_ptr, double.global_ptr, 
    sin.clq_type)
\end{verbatim}}
\caption{Programmatically specializing the \texttt{map} function from Figure \ref{map} for use by the standalone compiler to produce code equivalent to Figure \ref{mapsinint}.}
\label{specialization}
\end{figure}


\subsubsection{Programmatic Specialization and Compilation}
The standalone $\cloquence$ compiler, \verb|clqcc|, generates source code from $\cloquence$ source files. To do so, however, users must {\it specialize} any {\it externally callable} functions with their specific types. Figure \ref{specialization} shows how the specific OpenCL function given in Figure \ref{mapsinint} can be recovered from the generic specification of \verb|map| given in Figure \ref{map}. The \verb|specialize| method of a generic function like \verb|map| creates a new function that is concrete -- that is, with concrete argument types.

The standalone compiler operates by first executing the module, then iterating over the externally available variables in the module's environment to extract the OpenCL functions and any other functions and constructs that they depend on. This allows developers who wish to use the host language of their choice, rather than Python, to continue writing library functions generically, in one place, only writing small stub modules to specialize them as needed.

\subsubsection{Direct Invocation from Python}\label{direct}
As discussed in the introduction, a common usage scenario in scientific computing involves the use of a dynamic, high-level language for workflow orchestration and exploratory visualization and analysis, paired with a low-level language for performance-critical sections. Although the extension mechanism we describe shortly will permit the development of a broad array high-level language features in the future, current extensions, such as the OpenCL extension we have been describing, have been designed to make low-level programming simpler. For this reason, the OpenCL extension includes support for directly invoking $\cloquence$ functions from Python scripts with minimal overhead.

This feature builds on top of an established library, \verb|pyopencl|, that wraps the OpenCL host API and integrates it with the popular \verb|numpy| numerics library in Python. Buffers (arrays) in \verb|pyopencl| do not retain type information, so the $\cloquence$ extension adds type information, mirroring the API of \verb|numpy| arrays. It also hides many of the most verbose components of the OpenCL interface by providing reasonable defaults, such as an implicit global context and a default queue associated with each context. 

Using these simplifications, generic $\cloquence$ OpenCL functions like \verb|map| can be called directly, without specialization as in the previous section. Figure \ref{py} shows a full OpenCL program written using these bindings. By way of comparison, the same program written using OpenCL directly is two orders of magnitude larger and correspondingly more complex. Not shown are several additional conveniences, such as delegated kernel sizing and In and Out constructs that can reduce the size and improve the clarity of this code further -- due to space constraints, the reader is referred to the language documentation for additional details.

\begin{figure}
\small{\begin{verbatim}
from figure1 import map
import numpy as np
import clq.opencl.pyopencl as cl

ctx = cl.Context.for_device(0, 0)
d_in = ctx.to_device(np.ones(1024))
d_out = ctx.alloc(like=d_x)
map(d_in, d_out, clq.opencl.sin, 
    global_size=d_in.shape, local_size=(128,))
out = ctx.from_device(d_out)
\end{verbatim}}
\caption{A full OpenCL program using the $\cloquence$ Python bindings, including data transfer and kernel invocation.}
\label{py}
\end{figure}

\subsection{Code Generation in $\cloquence$}
Metaprogramming refers to the practice of writing programs that manipulate other programs. There are a number of use cases for this technique, including domain-specific optimizations and code generation for programs with a repetitive structure that cannot easily be packaged using available abstractions. OpenCL in particular relies on code generation as a fundamental mechanism, partially justifying the lack of support for higher-order programming.

$\cloquence$ supports code generation from directly within the metalanguage. A cl.oquence function can be constructed from a string containing its source using the \verb|clq.from_source| function. It can also be constructed directly from a Python abstract syntax tree, available via the standard \verb|ast| package, using the \verb|clq.from_ast| function. We discuss a use case for code generation for simulation orchestration in $\cloquence$ in Section 4.

\subsection{Active Language Extensions}
We now turn our attention to the extension mechanism used by $\cloquence$, as motivated by section \ref{extensions}. The $\cloquence$ type checker and compiler interacts directly with active libraries over an interface that gives substantial control over type checking and translation of an operation to a {\it type definition} associated with one of its operands according to a fixed dispatch protocol.

\subsubsection{Dispatch Protocol}
\begin{figure}\small{
\begin{verbatim}
class PtrType(Type):
  def __init__(self, target_type, addr_space):
    self.target_type = target_type
    self.addr_space = addr_space
        
  def verify_Subscript(self, context, node):
    slice_type = context.validate(node.slice)
    if isinstance(slice_type, IntegerType):
      return self.target_type
    else: 
      raise TypeError('<error message here>')
       
  def translate_Subscript(self, context, node):
    value = context.translate(node.value)
    slice = context.translate(node.slice)
    return copy_node(node, 
      value = value,
      slice = slice,    
      code = value.code + '['+slice.code+']')
\end{verbatim}}
\caption{A portion of the implementation of OpenCL pointer types implementing subscripting logic using the $\cloquence$ extension mechanism.}
\label{pointers}
\end{figure}

When the compiler encounters an expression, it must first verify that it type checks, then generate code for it. Rather than containing fixed logic for this, however, the compiler defers this responsibility to the {\it type} of a subexpression whenever possible. Below are example from the $\cloquence$ dispatch protocol. Due to space constraints, we do not list the entire dispatch protocol.
\begin{itemize}
\item Responsibility over a {\bf unary operation} like \verb|-x| is handed to the type assigned to the operand, \verb|x|.
\item Responsibility over {\bf binary operations} is first handed to the type assigned to the left operand. If it indicates that it does not understand the operation, the type assigned to the right operand is handed responsibility, with a different method call\footnote{Note that this operates similarly to Python's operator overloading protocol.}.
\item Responsibility over {\bf attribute access}, \texttt{obj.attr}, and {\bf subscript access}, \texttt{obj[idx]}, is handed to the type assigned to \texttt{obj}.
\end{itemize}

\subsubsection{Verification and Translation}
A type in $\cloquence$ is a metalanguage {\it instance} of a Python class deriving from \verb|clq.Type|. The compiler hands control over an expression to a type by calling a method corresponding to the syntactic form of the expression according to the above dispatch protocol. Figure \ref{pointers} gives the verification and translation logic governing subscript access for pointer types in OpenCL.

During the verification phase, the type of the primary operand, as determined by the dispatch protocol, is responsible for assigning a type to the expression as a whole. In this case, it recursively assigns a type to the slice operand. If it is assigned an integer type, the pointer's target type is assigned to the expression as a whole. Otherwise, a type error is raised with the provided error message (an ability that can be used by extension authors to satisfy the error message criteria described in Section \ref{errors}.) 

If verification succeeds, the compiler must subsequently translate the $\cloquence$ expression into an expression in the output language, here OpenCL. It does so by again applying the dispatch protocol to call a method prefixed with \verb|translate_|. This method is responsible for returning a copy of the expression's ast node with an additional attribute, \verb|code|, containing the source code of the translation. In this case, it is simply a direct translation to the corresponding OpenCL attribute access, using the recursively-determined translations of the operands. More sophisticated abstractions may insert arbitrarily complex statements and expressions. The context also provides some support for non-local effects, such as new top-level declarations (not shown.)

\subsubsection{Modular Backends}\label{backends}
Thus far, we have discussed using OpenCL as a backend with $\cloquence$. The OpenCL extension is the most mature as of this writing. However, $\cloquence$ supports the introduction of new backends in a manner similar to the introduction of new types, by extending the \verb|clq.Backend| base class. Backends are provided as the first argument to the \verb|@clq.fn| decorator, as can be seen in Figure \ref{map}. 
Backends are responsible for some aspects of the grammar that do not admit simple dispatch to the type of a subterm, such as number and string literals or basic statements like \verb|while|.

In addition to the OpenCL backend, preliminary C99 and CUDA backends are available (with the caveat that they have not been as fully developed or tested as of this writing.) Backends not based on the C family are also possible, but we leave such developments for future work.


\subsubsection{Use Cases}
The development of the full OpenCL language using only the extension mechanisms described above provides evidence of the power of this approach. Nothing about the core language was designed specifically for OpenCL. However, to be truly useful, as described in Sections \ref{multiparadigm} and  \ref{extensions}, the language must be able to support a wide array of primitive abstractions. We briefly describe a number of other abstractions that may be possible using this mechanism. Many of these are currently available either via inconvenient libraries or in standalone languages. With the $\cloquence$ extension mechanism, we hope to achieve robust, natural implementations of many of these mechanisms within the same language.

\paragraph{Partitioned Global Address Spaces}
A number of recent languages in high-performance computing have been centered around a partitioned global address space model, including UPC, Chapel, X10 and others. These languages provide first-class support for accessing data transparently across a massively parallel cluster, which is verbose and poorly supported by standard C. The extension mechanism of $\cloquence$ allows inelegant library-based approaches such as the Global Arrays library to be hidden behind natural wrappers that can use compile-time information to optimize performance and verify correctness. We have developed a prototype of this approach using the C backend and hope to expand upon it in future work.

\paragraph{Other Parallel Abstractions}
A number of other parallel abstractions, some of which are listed in \ref{multiparadigm}, also suffer from inelegant C-based implementations that spurred the creation of standalone languages. A study comparing a language-based concurrency solution for Java with an equivalent, though less clean, library-based solution found that language support is preferable but leads to many of the issues we have described \cite{cave2010comparing}. The extension mechanism is designed to enable library-based solutions that operate as first-class language-based solutions, barring the need for particularly exotic syntactic extensions.

\paragraph{Domain-Specific Type Systems}
$\cloquence$ is a statically-typed language, so a number of domain-specific abstractions that promise to improve verifiability using types, as discussed in Section \ref{verifiability}, can be implemented using the extension mechanism. We hope that this will allow advances from the functional programming community to make their way into the professional end-user community more quickly, particularly those focused on scientific domains (e.g. \cite{conf/cefp/Kennedy09}).

\paragraph{Specialized Optimizations}
In many cases, code optimization requires domain-specific knowledge or sophisticated, parametrizable heuristics. Existing compilers make implementing and distribution such optimizations difficult. With active libraries in $\cloquence$, optimizations can be distributed directly with the libraries that they work with. For instance, we have implemented substantial portions of the NVidia GPU-specific optimizations described in \cite{yang2010gpgpu} as a library that uses the extension mechanism to track affine transformations of the thread index used to access arrays, in order to construct a summary of the memory access patterns of the kernel, which can be used both for single-kernel optimization (as in \cite{yang2010gpgpu}) and for future research on cross-kernel fusion and other optimizations.

\paragraph{Instrumentation}
Several sophisticated feedback-directed optimizations and adaptive run-time protocols require instrumenting code in other ways. The extension mechanism enables granular instrumentation based on the form of an operation as well as its constituent types, easing the implementation of such tools. This ability could also be used to collect data useful for more rigorous usability and usage studies of languages and abstractions, and we plan on following up on this line of research going forward.

\subsection{Availability}
$\cloquence$ is available under the LGPL license and is developed openly and collaboratively using the popular Github platform\footnote{https://github.com/cyrus-/cl.oquence}. Documentation and other learning material is being made available at http://cl.oquence.org/.

\section{Case Study: Neurobiological Circuit Simulation}
An important criteria that practitioners use to evaluate a language or abstraction, as discussed in Section \ref{social}, is whether significant case studies have been conducted with it. In this section, we briefly (due to space limitations) discuss an application of the $\cloquence$ OpenCL library, Python host bindings and code generation features for developing a modular, high-performance scientific simulation library used to simulate  thousands of parallel realizations of a spiking neurobiological circuit on a GPU.

\subsection{Background}
A neural circuit can be modeled as a network of coupled differential equations, where each node corresponds to a single neuron. Each neuron is modeled using one or more ordinary differential equations. These equations capture the dynamics of physically important quantities like the cell's membrane potential or the conductance across various kinds of ion channels and can take many forms \cite{neurobook}. Single simulations can contain from hundreds to tens of millions of neurons each, depending on the specific problem being studied. In some cases, such as when studying the effects of noise on network dynamics or to sweep a parameter space, hundreds or thousands of realizations must be generated. In these cases, care must be taken to only probe the simulation for relevant data and process portions of it as the simulation progresses, because the amount of data generated is often too large to store in its entirety for later analysis.

The research group we discuss here (of which the first author was a member) was studying a problem that required running up to 1,000 realizations of a network of between 4,000 and 10,000 neurons each. An initial solution to this problem used the Brian framework, written in Python, to conduct these simulations on a CPU. Brian was selected because it allowed the structure of the  simulation to be specified in modular and straightforward manner. This solution required between 60 and 70 minutes to conduct the simulations and up to 8 hours to analyze the data each time a parameter of the simulation was modified.

Unsatisfied with the performance of this approach, the group developed an accelerated variant of the simulation using C++ and CUDA. Although this produced significant speedups, reducing the time for a simulation by a factor of 40 and the runtime of the slowest analyses by a factor of 200, the overall workflow was also significantly disrupted. In order to support the many variants of models, parameter sets, and probing protocols, C preprocessor flags were necessary to selectively include or exclude code snippets. This quickly led to an incomprehensible and difficult to maintain file structure. Moreover, much of the simpler data analysis and visualization was conducted using Python, so marshalling the relevant data between processes also became an issue. 

\subsection{The {\sf cl.egans} Simulation Library}
In order to eliminate these issues while retaining the performance profile of the GPU-accelerated code, the project was ported to $\cloquence$. Rather than using preprocessor directives to control the code contained in the final GPU kernels used to execute the simulation and data analyses, the group was able to develop a more modular  library called {\sf cl.egans}\footnote{...after {\it c. elegans}, a model organism in neuroscience} based on the language's compile-time code generation mechanism and Python and OpenCL bindings.

{\sf cl.egans} leverages Python's object-oriented features to enable modular, hierarchical simulation specifications. For example, Figure \ref{spec} shows an example where a neuron model (\verb|ReducedLIF|) is added to the root of the simulation, a synapse model (\verb|ExponentialSynapse|) is then added to it, and its conductance is probed in the same way, by adding a probe model as a child of the synapse model. If interleaved analysis needed to be conducted as well, it would be specified in the same way.

Implementations of these classes do not evaluate the simulation logic directly, but rather contain methods that generate $\cloquence$ source code for insertion at various points, called {\it hooks}, in the final simulation kernel. The hook that code is inserted into is determined by the method name, and code can be inserted into any hook defined anywhere upstream in the simulation tree. New hooks can also be defined in these methods and these become available for use by child nodes. Figure \ref{impl} shows an example of a class that inserts code in the \verb|model_code| hook and defines several new hooks. This protocol is closely related to the notion of {\it frame-oriented programming}. Although highly modular, this strategy avoids the performance penalties associated with standard object-oriented methodologies via code generation.

Compared to a similar protocol targeting OpenCL directly, the required code generation logic is significantly simpler because it enables classes like \verb|StateVariable| to be written generically for all types of state variables, without carrying extra parameters and {\it ad hoc} logic to extract and compute the result types of generated expressions. Moreover, because types are first-class objects in the metalanguage, they can be examined during the memory allocation step to enable features like fully-automatic parallelization of multiple realizations across one or more devices, a major feature of {\sf cl.egans} that competing frameworks cannot easily offer.


Once the kernel has been generated and memory has been allocated, the simulation can be executed directly from Python using the bindings described in Section \ref{direct}. The results of this simulation are immediately available to the Python code following the simulation and can be visualized and further analyzed using standard tools. Once the computations are complete, the Python garbage collector is able to handle deallocation of GPU memory automatically (a feature of the underlying \verb|pyopencl| library \cite{klockner2011pycuda}.)

Using this $\cloquence$-based framework, the benefits of the Brian-based workflow were recovered without the  corresponding decrease in performance relative to the previous CUDA-based solution, leading ultimately to a satisfying solution for the group conducting this research.

\begin{figure}
\small{
\begin{verbatim}
# Create the root node of the simulation
sim = Simulation(ctx, n_timesteps=10000)
neurons = ReducedLIF(sim, count=N, tau=20.0)
e_synapse = ExponentialSynapse(neurons, 'ge',
    tau=5.0, reversal=60.0)
probe = StateVariableProbeCopyback(e_synapse)
\end{verbatim}}
\caption{An example of a nested simulation tree, showing that specifying a simulation is both simple and modular.}
\label{spec}
\end{figure}

\begin{figure}\small{
\begin{verbatim}
class SpikingModel(Model):
  """Base class for spiking neuron models."""
  def in_model_code(self, g):
    """
    idx_state = idx_model + (realization_num - 
        realization_start)*count
    """ << g  # << appends to code generator, g
    self.insert_cg_hook("read_incoming", g)
    self.insert_cg_hook("read_state", g)
    self.insert_cg_hook("calculate_inputs", g)
    self.insert_cg_hook("state_calculations", g)
    self.insert_cg_hook("spike_processing", g)
  # ...
\end{verbatim}}
\caption{An example of a hook that inserts code and also inserts new, nested hooks for downstream simulation nodes  below that.}
\label{impl}
\end{figure}

\section{Related Work}

\section{Conclusion}
Professional end-users demand much from new languages and abstractions. In this paper, we began by generating a concrete, detailed set of design and adoption criteria that we hope will be of broad interest and utility to the research community. Based on these constraints, we designed a new language, $\cloquence$, making several pragmatic design decisions and utilizing advanced techniques, including type inference, structural typing, compile-time metaprogramming and active libraries, to uniquely satisfy many of the criteria we discuss, particularly those related to extensibility. We validated the extension mechanism with a mature implementation of  the entirety of the OpenCL type system, as well as preliminary implementations of some other features. Finally, we demonstrated that this language was useful in practice, drastically improving performance without negatively impacting the high-level scientific workflow of a large-scale neurobiological circuit simulation project. Going forward, we hope that $\cloquence$ (or simply the key techniques it proposes, by some other vehicle) will be developed further by the community to strengthen the foundations upon which new abstractions are implemented and deployed into professional end-user development communities.

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.



% conference papers do not normally have an appendix


% use section* for acknowledgement
% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\bibliographystyle{IEEEtran}
\bibliography{../research}
%
%\begin{thebibliography}{1}
%
%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
%
%\end{thebibliography}




% that's all folks
\end{document}


