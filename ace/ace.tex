
%% bare_conf.tex
%% V1.3
%% 2007/01/11
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.7 or later) with an IEEE conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/tex-archive/macros/latex/contrib/IEEEtran/
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%
%% File list of work: IEEEtran.cls, IEEEtran_HOWTO.pdf, bare_adv.tex,
%%                    bare_conf.tex, bare_jrnl.tex, bare_jrnl_compsoc.tex
%%*************************************************************************
\documentclass{sig-alternate}

%\usepackage{cite}
%\renewcommand{\citepunct}{,\,} % IEEEtran wants to use ],\,[ for this but that looks dumb...

\usepackage{alltt}
\renewcommand{\ttdefault}{txtt}
\usepackage{color}
\usepackage[usenames,dvipsnames,svgnames,table]{xcolor}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\definecolor{light-gray}{gray}{0.75}
\usepackage{listings}
\lstset{
  language=Python,
  showstringspaces=false,
  formfeed=\newpage,
  tabsize=4,
  commentstyle=\itshape,
  basicstyle=\ttfamily\scriptsize,
  morekeywords={lambda, self, assert, as},
  numbers=left,
  numberstyle=\scriptsize\color{light-gray}\textsf,
  xleftmargin=2em,
  stringstyle=\color{mauve}
}
\lstdefinestyle{Bash}{
    language={}, 
    moredelim=**[is][\color{blue}\bf\ttfamily]{`}{`},
}
\lstdefinestyle{OpenCL}{
	language=C++,
	morekeywords={kernel, __kernel, global, __global, size_t, get_global_id, sin}
}

\usepackage{float}
\floatstyle{ruled}
\newfloat{codelisting}{tp}{lop}
\floatname{codelisting}{Listing}

% *** GRAPHICS RELATED PACKAGES ***
%
% *** MATH PACKAGES ***
%
%\usepackage[cmex10]{amsmath}
% A popular package from the American Mathematical Society that provides
% many useful and powerful commands for dealing with mathematics. If using
% it, be sure to load this package with the cmex10 option to ensure that
% only type 1 fonts will utilized at all point sizes. Without this option,
% it is possible that some math symbols, particularly those within
% footnotes, will be rendered in bitmap form which will result in a
% document that can not be IEEE Xplore compliant!
%
% Also, note that the amsmath package sets \interdisplaylinepenalty to 10000
% thus preventing page breaks from occurring within multiline equations. Use:
%\interdisplaylinepenalty=2500
% after loading amsmath to restore such page breaks as IEEEtran.cls normally
% does. amsmath.sty is already installed on most LaTeX systems. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/

% *** SPECIALIZED LIST PACKAGES ***
%
%\usepackage{algorithmic}
% algorithmic.sty was written by Peter Williams and Rogerio Brito.
% This package provides an algorithmic environment fo describing algorithms.
% You can use the algorithmic environment in-text or within a figure
% environment to provide for a floating algorithm. Do NOT use the algorithm
% floating environment provided by algorithm.sty (by the same authors) or
% algorithm2e.sty (by Christophe Fiorio) as IEEE does not use dedicated
% algorithm float types and packages that provide these will not provide
% correct IEEE style captions. The latest version and documentation of
% algorithmic.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithms/
% There is also a support site at:
% http://algorithms.berlios.de/index.html
% Also of interest may be the (relatively newer and more customizable)
% algorithmicx.sty package by Szasz Janos:
% http://www.ctan.org/tex-archive/macros/latex/contrib/algorithmicx/

% *** ALIGNMENT PACKAGES ***
%
%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty patches and improves
% the standard LaTeX2e array and tabular environments to provide better
% appearance and additional user controls. As the default LaTeX2e table
% generation code is lacking to the point of almost being broken with
% respect to the quality of the end results, all users are strongly
% advised to use an enhanced (at the very least that provided by array.sty)
% set of table tools. array.sty is already installed on most systems. The
% latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/

%\usepackage{mdwmath}
%\usepackage{mdwtab}
% Also highly recommended is Mark Wooding's extremely powerful MDW tools,
% especially mdwmath.sty and mdwtab.sty which are used to format equations
% and tables, respectively. The MDWtools set is already installed on most
% LaTeX systems. The lastest version and documentation is available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/mdwtools/

% IEEEtran contains the IEEEeqnarray family of commands that can be used to
% generate multiline equations as well as matrices, tables, etc., of high
% quality.

%\usepackage{eqparbox}
% Also of notable interest is Scott Pakin's eqparbox package for creating
% (automatically sized) equal width boxes - aka "natural width parboxes".
% Available at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/eqparbox/

% *** SUBFIGURE PACKAGES ***
%\usepackage[tight,footnotesize]{subfigure}
% subfigure.sty was written by Steven Douglas Cochran. This package makes it
% easy to put subfigures in your figures. e.g., "Figure 1a and 1b". For IEEE
% work, it is a good idea to load it with the tight package option to reduce
% the amount of white space around the subfigures. subfigure.sty is already
% installed on most LaTeX systems. The latest version and documentation can
% be obtained at:
% http://www.ctan.org/tex-archive/obsolete/macros/latex/contrib/subfigure/
% subfigure.sty has been superceeded by subfig.sty.

%\usepackage[caption=false]{caption}
%\usepackage[font=footnotesize]{subfig}
% subfig.sty, also written by Steven Douglas Cochran, is the modern
% replacement for subfigure.sty. However, subfig.sty requires and
% automatically loads Axel Sommerfeldt's caption.sty which will override
% IEEEtran.cls handling of captions and this will result in nonIEEE style
% figure/table captions. To prevent this problem, be sure and preload
% caption.sty with its "caption=false" package option. This is will preserve
% IEEEtran.cls handing of captions. Version 1.3 (2005/06/28) and later 
% (recommended due to many improvements over 1.2) of subfig.sty supports
% the caption=false option directly:
%\usepackage[caption=false,font=footnotesize]{subfig}
%
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/subfig/
% The latest version and documentation of caption.sty can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/caption/

% *** FLOAT PACKAGES ***
%
%\usepackage{fixltx2e}
% fixltx2e, the successor to the earlier fix2col.sty, was written by
% Frank Mittelbach and David Carlisle. This package corrects a few problems
% in the LaTeX2e kernel, the most notable of which is that in current
% LaTeX2e releases, the ordering of single and double column floats is not
% guaranteed to be preserved. Thus, an unpatched LaTeX2e can allow a
% single column figure to be placed prior to an earlier double column
% figure. The latest version and documentation can be found at:
% http://www.ctan.org/tex-archive/macros/latex/base/

%\usepackage{stfloats}
% stfloats.sty was written by Sigitas Tolusis. This package gives LaTeX2e
% the ability to do double column floats at the bottom of the page as well
% as the top. (e.g., "\begin{figure*}[!b]" is not normally possible in
% LaTeX2e). It also provides a command:
%\fnbelowfloat
% to enable the placement of footnotes below bottom floats (the standard
% LaTeX2e kernel puts them above bottom floats). This is an invasive package
% which rewrites many portions of the LaTeX2e float routines. It may not work
% with other packages that modify the LaTeX2e float routines. The latest
% version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/sttools/
% Documentation is contained in the stfloats.sty comments as well as in the
% presfull.pdf file. Do not use the stfloats baselinefloat ability as IEEE
% does not allow \baselineskip to stretch. Authors submitting work to the
% IEEE should note that IEEE rarely uses double column equations and
% that authors should try to avoid such use. Do not be tempted to use the
% cuted.sty or midfloat.sty packages (also by Sigitas Tolusis) as IEEE does
% not format its papers in such ways.

% *** PDF, URL AND HYPERLINK PACKAGES ***
%
\usepackage{url}
% url.sty was written by Donald Arseneau. It provides better support for
% handling and breaking URLs. url.sty is already installed on most LaTeX
% systems. The latest version can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/contrib/misc/
% Read the url.sty source comments for usage information. Basically,
% \url{my_url_here}.

\usepackage{placeins}

% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
% (Unless specifically asked to do so by the journal or conference you plan
% to submit to, of course. )


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\input{macros}

\begin{document}
%
% paper title
% can use linebreaks \\ within to get better formatting as desired
\title{Ace: An Actively-Typed Language and Compilation Environment for High-Performance Computing}


% author names and affiliations
% use a multiple column layout for up to two different
% affiliations
\author{\alignauthor
Cyrus Omar and Jonathan Aldrich\\
       \affaddr{Carnegie Mellon University, Pittsburgh, PA}\\
       \email{\{comar,aldrich\}@cs.cmu.edu}
}

% conference papers do not typically use \thanks and this command
% is locked out in conference mode. If really needed, such as for
% the acknowledgment of grants, issue a \IEEEoverridecommandlockouts
% after \documentclass

% for over three affiliations, or if they all won't fit within the width
% of the page, use this alternative format:
% 
%\author{\IEEEauthorblockN{Michael Shell\IEEEauthorrefmark{1},
%Homer Simpson\IEEEauthorrefmark{2},
%James Kirk\IEEEauthorrefmark{3}, 
%Montgomery Scott\IEEEauthorrefmark{3} and
%Eldon Tyrell\IEEEauthorrefmark{4}}
%\IEEEauthorblockA{\IEEEauthorrefmark{1}School of Electrical and Computer Engineering\\
%Georgia Institute of Technology,
%Atlanta, Georgia 30332--0250\\ Email: see http://www.michaelshell.org/contact.html}
%\IEEEauthorblockA{\IEEEauthorrefmark{2}Twentieth Century Fox, Springfield, USA\\
%Email: homer@thesimpsons.com}
%\IEEEauthorblockA{\IEEEauthorrefmark{3}Starfleet Academy, San Francisco, California 96678-2391\\
%Telephone: (800) 555--1212, Fax: (888) 555--1212}
%\IEEEauthorblockA{\IEEEauthorrefmark{4}Tyrell Inc., 123 Replicant Street, Los Angeles, California 90210--4321}}




% use for special paper notices
%\IEEEspecialpapernotice{(Invited Paper)}




% make the title area
\maketitle

\begin{abstract}
Researchers developing languages and abstractions for high-performance computing must consider a number of design criteria, including performance, verifiability, portability and ease-of-use. Despite the deficiencies of legacy tools and the availability of seemingly superior options, end-users have been reluctant to adopt new language-based abstractions. We argue that this can be largely attributed to a failure to consider three additional criteria: continuity, extensibility\- and interoperability. This paper introduces Ace, a language that aims to satisfy this more comprehensive set of design criteria. To do so, Ace introduces several novel compile-time mechanisms, makes principled design choices, and builds upon existing standards in HPC, particularly Python and OpenCL. OpenCL support, rather than being built into the language, is implemented atop an extensibility mechanism that also admits abstractions drawn from other seemingly disparate paradigms. The core innovation underlying this and other features of Ace is a novel reification of types as first-class objects at compile-time, representing a refinement to the concept of active libraries that we call \emph{active types}. We validate our overall design by considering a case study of a simulation framework enabling the modular specification and efficient execution of ensembles of neural simulations across clusters of GPUs.

%in the context of the applications and architectures that the language may need to target.
%
%Programming languages targeted toward end-users in high-performance computing must consider a number of issues in addition to performance. Typically, researchers have focused verifiability, portability and ease-of-use, and the right balance often depends on the particular uses that they are put toward.
%
%Ace %, evaluates it against several design and adoption criteria, and describes several use cases as well as a realistic case study involving parallelizing neurobiological circuit simulations on clusters of GPUs. 
%is an extensible statically-typed programming language embedded within the ubiquitous scripting language Python. Python serves as a {metalanguage}, enabling programmatic control over several aspects of language specification and compilation. 
%We demonstrate the power of this design for HPC by defining all of the primitives of the OpenCL kernel language as a library of user-defined types in Ace, then extending this core with several higher-level first-class abstractions. The target of translation, called the \emph{backend}, is user-defined as well, allowing us to implement the semantics of these primitives by direct translation to OpenCL, CUDA or C99.
%
%Although Ace is built around a static type discipline, it supports a novel form of generic programming based on type propagation that, together with a form of extensible local type inference, eliminates most of the syntactic overhead usually associated with statically-typed languages. A companion host API allows type information from \verb|numpy| arrays to directly propagate into Ace kernels, supporting seamless adoption of Ace into current scientific workflows.
%
\end{abstract}

%\begin{IEEEkeywords}
%extensible programming languages, heterogeneous computing, type systems
%\end{IEEEkeywords}


% For peer review papers, you can put extra information on the cover
% page as needed:
% \ifCLASSOPTIONpeerreview
% \begin{center} \bfseries EDICS Category: 3-BBND \end{center}
% \fi
%
% For peerreview papers, this IEEEtran command inserts a page break and
% creates the second title. It will be ignored for other modes.
%\IEEEpeerreviewmaketitle



\section{Introduction}

Computer-aided simulation and data analysis techniques have transformed science and engineering. Surveys show that scientists and engineers now spend up to 40\% of their time writing software \cite{howison2011scientific, hannay2009scientists}. Most of this software targets desktop hardware, while about 20\% of scientists also target either local clusters or super\-computers for more numerically-intensive computations \cite{hannay2009scientists}. To fully harness the power of these platforms, however, these so-called {\em professional end-user developers} \cite{segal2007some} must increasingly write parallel programs.

Professional end-users today generally use dynamically-typed high-level languages like MATLAB, Python, R or Perl for tasks that are not performance-sensitive, such as small-scale data analysis and plotting \cite{nguyen2010survey}. For portions of their analyses where the performance overhead of dynamic type checking and automatic memory management is too high, they will typically call into code written in a statically-typed, low-level language, most commonly C or Fortran, that uses low-level parallel abstractions like pthreads and MPI \cite{4222616,basili2008understanding}. Unfortunately, these low-level languages and abstractions are notoriously difficult to use and automatic verification is intractable in general.

Researchers and domain experts often respond to these challenges by proposing novel language features that aim to strike an intermediate balance between \textbf{performance}, \textbf{verifiability\-}, \textbf{portability} and \textbf{ease-of-use}.
Unfortunately, professional end-users rarely adopt new languages. Indeed, many end-users have become skeptical that novel approaches that originate in the research community can be  practical. This viewpoint was perhaps most succinctly expressed by a participant in a recent study by Basili et al. \cite{basili2008understanding} who stated ``I hate MPI, I hate C++. [But] if I had to choose again, I would probably choose the same.'' Although it may seem paradoxical, the ubiquity of this sentiment demands direct examination by researchers proposing novel abstractions and languages for eventual use by professional end-users in HPC.

We suggest three mutually-related {design criteria} that, unlike those in bold above, many languages and language-integrated abstractions have failed to adequately consider: \textbf{continuity}, \textbf{extensibility} and \textbf{interoperability}. These criteria encompass the intuitions that new abstractions will not be adopted in a vacuum, that programming systems must  support change, and that interacting components of an application or workflow should be able to make use of different abstractions naturally and without the possibility of conflict arising at their interface boundaries.
%that this is far from being a superfluous issue. These criteria can influence the core design of a language or abstraction.

In this paper, we introduce Ace, a programming language targeting professional end-users as well as researchers across high-performance computing and related domains. Ace has followed a principled design methodology guided by this more comprehensive set of design criteria in order to avoid many of the issues that have hindered previous language-based approaches in high-performance computing. These criteria, this design methodology, and the novel mechanisms and designs developed to satisfy these criteria constitute the generalizable contributions of this paper. We also hope that Ace itself will be useful to the HPC community\footnote{\small Ace is openly available at http://acelang.org/.}, and we describe several use cases and an initial case study in order to preliminarily validate it's utility. 

 We begin in Section \ref{usage} with simple examples that show how Ace can be used for low-level GPU programming and introduce the fundamental decisions made in its design. We discuss the motivations, based on the criteria above, behind key design decisions, including the use of static typing, a fixed syntax based on Python, a novel type propagation and inference scheme, and an explicit phase separation between compile-time and run-time logic. Each of these can be seen in Listings 1 and 2, which we will discuss further below.
 
All examples in Section \ref{usage} are based on an internalization of the OpenCL kernel programming language as a library. This library is built atop a novel extensibility mechanism that we call \emph{active typechecking and translation} (AT\&T) and detail in Section \ref{att}. This mechanism relies on the core idea of representing types as first-class objects at compile-time. We refer to these objects as \emph{active types} by analogy with \emph{active libraries} \cite{activelibraries} (see Section \ref{related}). Unlike prior approaches to extensibility where users globally modify the grammar or semantics of a language, and thus introduce conflicts between extensions, AT\&T guarantees that extensions are composable by construction by pairing new rules with new types and limiting their scope to expressions of that type.

%Despite its simplicity and safety, this mechanism is flexible enough to define the entirety of the OpenCL kernel language (which is derived directly from C99) and, combined with Ace's type propagation scheme, substantially enhance it's ease-of-use. 
To demonstrate the flexibility of this mechanism beyond OpenCL, we continue in Section \ref{usecases} by outlining examples of other, higher-level parallel abstractions that can be cleanly implemented using AT\&T, including global address spaces, message passing and functional data parallelism. First-class support for each of these has required a new language in the past. AT\&T allows compile-time logic to be safely included within libraries, and thus these first-class abstractions can be coexist naturally within a single program or workflow.


Ace can be used as a standalone language via the \verb|acec| compiler and also as an interactive compilation environment. This mode of use, described in Section \ref{compenv}, uses just-in-time specialization to  integrate the widely-adopted \verb|numpy| library (including its internal type system) and OpenCL's host API (by a mechanism also available to other host APIs, such as CUDA's) with the Ace compiler itself to enable the direct invocation of Ace functions from within Python scripts with minimal overhead. Achieving this deep level of integration makes use of Ace's novel type representation as well.
 
To demonstrate the utility of Ace for scientific workloads, we describe in Section \ref{casestudy} a case study where Ace was used in this mode to develop a scientific simulation framework. This framework has been used to  specify and efficiently execute thousands of realizations of a large stochastic neural circuit model on clusters of GPUs, achieving the same performance as raw OpenCL code while being more modular and concise than was feasible before.

We conclude in Sections \ref{related} and \ref{discussion} with related work and a discussion of the limitations of Ace at the time of writing, as well as a discussion of planned future work further validating Ace and building upon the concept of active typing.

% a programming language intended to be used by professional end-users as well as researchers in areas related to high-performance computing and computational science. The primary contribution of this paper consists of describing several novel language mechanisms and novel combinations of existing mechanisms that Ace uses to cohesively address the design criteria above. We anticipate that many of these mechanisms and choices will also influence other languages in the future. 
%Following a principled design methodology, we justify each design decision by appeal to this full set of design criteria and citations to relevant literature. These criteria and methodology constitute another contribution of this work that we hope  will lead to fewer \emph{ad hoc} designs and serve as a foundation for evaluating competing designs in HPC and related domains in the future.

\section{Language Design and Usage}\label{usage}
\begin{codelisting}
\lstinputlisting{hello.py}
\caption{\texttt{[hello.py]} A basic Ace program demonstrating the two-phase structure of Ace programs and libraries.}
\label{hello}
\end{codelisting}
\begin{codelisting}
\begin{lstlisting}[style=Bash]
$ `acec hello.py`
Hello, compile-time world!
Goodbye, compile-time world!
$ `cat hello.cl`
__kernel void main() {
    char* hello = "Hello, run-time world!";
    printf(hello);
}\end{lstlisting}
\caption{Compiling \texttt{hello.py} using the \texttt{acec} compiler.}
\label{helloout}
\end{codelisting}
A variant of the standard ``Hello, World!'' example written in Ace is shown in Listing \ref{hello} and its compilation to statically-typed OpenCL kernel code is demonstrated in Listing \ref{helloout}. The OpenCL kernel language is a variant of C99 with some additions and restrictions to facilitate execution on GPUs and other accelerators, in addition to conventional CPUs \cite{opencl}. We will discuss it further in subsequent examples.
We emphasize that this module, which we use throughout the paper, is simply a library like any other. The core of Ace gives no special treatment to it; it is distributed together with Ace for convenience. Aspects of its implementation will be described  in Section \ref{att}.

This example demonstrates several key design decisions that characterize Ace: static typing of run-time behavior, a Python-based syntax, a phase distinction between compile-time and run-time logic, and programmatic compilation. We discuss each of these in the next three sections. 
\subsection{Static Typing and Syntax}
Static type systems are powerful tools for programming language design and implementation. By tracking the type of a value statically, a typechecker can verify the absence of many kinds of errors over all inputs. This simplifies and increases the performance of the run-time system, as errors need not be detected dynamically using tag checks and other kinds of assertions. Many parallel programming abstractions are defined in terms of, or benefit from, a type system that enforces a communication protocol, ensures the consistency of data and simplifies the dynamics of the run-time system (see Section \ref{usecases} for examples). Because \textbf{verifiability} and \textbf{performance} are key criteria and static typing is a core technique, Ace is fundamentally statically-typed.

It is legitimate to ask, however, why dynamically-typed languages are so widely-used in HPC. Although slow and difficult to reason about, these languages generally excel at satisfying the criteria of \textbf{ease-of-use}. More specifically, Cordy identified the principle of \emph{conciseness} as elimination of
redundancy and the availability of reasonable defaults \cite{cordy1992hints}. Statically-typed languages, particularly those that HPC programmers are exposed to, are verbose, requiring explicit and often redundant type annotations on each function and variable declaration, separate header files, explicit template headers and  instantiation and other sorts of annotations.  The dynamically-typed languages used in HPC, on the other hand, avoid most of this overhead by relying on support from the run-time system. Ace was first conceived to explore the question: does conciseness require run-time mechanisms, or can one develop a statically-typed language with the same low-level memory and execution model of C but syntactic overhead comparable to a high-level scripting language? 

Rather than designing a new syntax, or modifying the syntax of C, we chose to utilize, \emph{without modification}, the syntax of an existing language, Python. This choice was not arbitrary, but rather a key means by which Ace achieves both \textbf{ease-of-use} and \textbf{continuity}. Python's whitespace-delimited syntax is widely regarded as both concise and readable, and Python is amongst the most widely-adopted languages in computational science \cite{pythonhpc}. By directly adopting Python's syntax, Ace's syntax is immediately \emph{familiar} and \emph{acceptable} to a significant segment of the intended audience. Moreover, a key benefit of adopting it without modifications is that any {tools} that handle Python source code, including parsers, editors, style checkers and documentation generators, can be used on Ace code without modification.

\subsection{Phase Separation}
\begin{codelisting}
\lstinputlisting{listing3.py}
\caption{[\texttt{listing\ref{map}.py}] A generic data-parallel higher-order map function written using the OpenCL user module.}
\label{map}
\end{codelisting}
\begin{codelisting}
\lstinputlisting{listing4.py}
\caption{[\texttt{listing\ref{mapadd5dbl}.py}] The generic \texttt{map} function compiled to map the \texttt{add5} function over two  types of input.}
\label{mapadd5dbl}
\end{codelisting}
\begin{codelisting}
\lstinputlisting[style=OpenCL]{listing5.cl}
\caption{[\texttt{listing\ref{mapadd5dbl}.cl}] The OpenCL code generated by running \texttt{acec listing\ref{mapadd5dbl}.py}.}
\label{mapout}
\end{codelisting}


%To demonstrate the somewhat unconventional structure of Ace programs and libraries, we begin in Listing \ref{hello} with a variant of the canonical ``Hello, World!'' example written using the \verb|OpenCL| module. 


Ace's \textbf{continuity} with Python does not stop at its syntax. 
Perhaps the most immediately apparent departure from the standard ``Hello, World!'' example comes on lines 3 and 10 of Listing \ref{hello}, which contain Python \verb|print| statements that are executed at {\em compile-time}.  Ace programs and libraries are Python scripts at the top-level, rather than a list of declarations as in most conventional languages. In other words, Python is the {\em compile-time metalanguage} of Ace. 

A consequence of this choice is that Ace can leverage Python's well-developed package system and associated distribution infrastructure directly (e.g. Line 1). This serves to address another key \textbf{ease-of-use} issue often associated with C-based languages: the fragility of the preprocessor-based packaging system they historically have relied upon. 

Ace functions defining run-time logic are introduced by a decorator. The \verb|@OpenCL.fn| decorator on Line 5 indicates that the \verb|main| function is a statically-typed Ace function targeting the OpenCL backend for code generation (Section \ref{backend}). Without this decorator, the function would simply be a conventional Python function that could be called only at compile-time. Doing so would fail here: \verb|printf| is not a Python function. Rather, it is a compile-time Python object representing an OpenCL primitive residing in the \verb|OpenCL| module. It has an associated Ace type that controls what types of input it can receive and the type of its output given its input type (see Section \ref{att}).

\subsection{Programmatic Compilation}
As defined on Lines 5-7, \verb|main| is a \emph{generic function}. This terminology in Ace is used to indicate a function for which types have not yet been assigned to arguments. Invoking the \verb|compile| method on a generic function with a sequence of argument types invokes the active typechecking and translation mechanism we will describe in Section 3 to produce a \emph{concrete function} -- one with a single type for each argument, internal variable (such as \verb|hello|) and the return value. In Listing \ref{hello}, we name this concrete function \verb|main|, overwriting the generic function of the same name that it is derived from. The compiler does nothing apparently interesting: there are no arguments, the single internal variable takes the OpenCL string type \verb|char*| from its value and the return type is \verb|void|. 

Before moving on to more interesting examples, let us discuss the \verb|acec| compiler shown operating at the shell in Listing \ref{helloout}. The \verb|acec| compiler operates in two steps:
\begin{enumerate}
\item Executes the provided Python file (\verb|hello.py|) which contains Ace functions and (in future examples) types and compile-time code generation logic.
\item Produces source code for concrete functions (produced using the \verb|compile| method) in the top-level Python environment and any other concrete functions, type declarations and other program items required by or generated by these functions. This may produce one or more files (here, just \verb|hello.cl|).
\end{enumerate}

We will show in Section \ref{pyopencl} that for backends with Python bindings, such as OpenCL, CUDA and C, generic functions can be executed directly, without this explicit compilation step to concrete functions, if desired.

\subsection{Example 2: Higher-Order Map}
The ``Hello, World!'' example demonstrates the structure of Ace programs, but it does not require working with types. Listing \ref{map} shows an imperative, data-parallel map primitive written using the OpenCL library introduced above. To review, in OpenCL users can define functions, called {\em kernels}, that execute across thousands of threads. Each kernel has access to a unique index, called its {\em global id}, which can be to ensure that each thread operates on different parts of the input data (Line 5). The \verb|map| kernel defined in Listing \ref{map} applies a transfer function, \verb|f|, to the element of the input array, \verb|input|, corresponding to its global id. It writes the result of this call into the corresponding location in the provided output array, \verb|output|.

As above, \verb|map| is a {\em generic function} (specifically, it is an instance of the class \verb|ace.GenericFn|). This means that its arguments have not been assigned types. The functionality given by the \verb|map| definition is in fact applicable to many combinations of types for \verb|input| and \verb|output| and functions, \verb|f|. In this sense, \verb|map| is actually a \emph{family} of functions defined for all types assignments for \verb|input|, \verb|output| and \verb|f| such that the operations in the function's body are well-defined.

Running \verb|acec listing3.py| would produce no output. To create a {\em concrete function} (that is, an instance of the class \verb|ace.ConcreteFn|) that can be emitted by the compiler, types must be assigned to each of the arguments. Listing \ref{mapadd5dbl} shows how to use the \verb|compile| method to specialize \verb|map| in \emph{two} different ways to apply the \verb|add5| function, defined on Lines 4-6, to arrays  that reside in global memory (OpenCL associates a memory space with pointer types). Line 9 results in a version specialized for arrays of \verb|double|s and Line 10 results in a version for arrays of \verb|int|s. The output of compilation is shown in Listing \ref{mapout}.

\subsection{Types as Metalanguage Objects}
The \verb|compile| method assigns types to the arguments of a generic function. In Listing \ref{mapadd5dbl}, the types we are using are given shoter names, for convenience, on Line 8 (that is, variables in the metalanguage can be used like \verb|typedef| is used in a C-like language). The types \verb|int| and \verb|double| imported from the \verb|OpenCL| module correspond to the OpenCL types of the same name. The types \verb|gptr(int)| and \verb|gptr(double)| correspond to \verb|__global int*| and \verb|__global double*|. That is, \verb|gptr| can be understood as a type-indexed family of types.

These types are \emph{objects in the metalanguage}, Python. More specifically, types are {instances} of user-defined classes that inherit from the Ace-provided \verb|ace.Type| class. For example, \verb|gptr(double)| is an instance of \verb|OpenCL.GlobalPtrType| instantiated with the target type, \verb|double|, as a constructor argument. The types \verb|double| and \verb|int| are instances of \verb|OpenCL.FloatType| and \verb|OpenCL.IntegerType|, respectively. This notion of types as metalanguage objects is key to the Ace compilation model and also enables other mechanisms that we will discuss in subsequent sections.

\subsection{Type Propagation}
\begin{codelisting}
\lstinputlisting{listing6.py}
\caption{\texttt{[listing6.py]} A function demonstrating whole-function type inference when multiple values with differing types are assigned to a single variable.}
\label{inference}
\end{codelisting}
The type assigned to the third argument, \verb|f|, on both Lines 4.9 and 4.10, is \verb|add5.ace_type|. The \verb|ace_type| attribute of a generic function is an instance of \verb|ace.GenericFnType|, the type of Ace generic functions. Ace generic functions are compiled to concrete functions automatically at all internal call sites. That is, when the compiler encounters the call to \verb|f| inside \verb|map| when compiling \verb|map_add5_double|, it compiles a version of \verb|add5| specialized to the \verb|double| type (seen on Line 5.3), and similarly when compiling \verb|map_add5_int| (on Line 5.16, automatically given a unique name to avoid conflicts). This mechanism is called {\em type propagation}. We did not need to use \verb|add5.compile(double)| before compiling \verb|map_add5_dbl| because only functions that are never called in the process of compiling other functions in a module need type information explicitly provided, supporting \textbf{ease-of-use} by increasing conciseness.

In effect, this scheme allows for a form of higher-order functional programming even when targeting languages, like OpenCL, that have no support for higher-order functions (OpenCL, unlike C99, does not support function pointers). This works because the \verb|ace.GenericFnType| for one function, such as \verb|add5|, is not equal to  the \verb|ace.GenericFnType| for a superficially similar function, such as \verb|add6| (defined as one would expect). To put it in type theoretic terms, \verb|ace.GenericFnType|s are singleton types, {\em uniquely inhabited} by a single generic function. A consequence of this is that they cannot be used as first-class values (i.e. they cannot written into an array). This is often valuable, particularly in parallel programming where compile-time specialization is valuable to avoid the \textbf{performance} and \textbf{ease-of-use} issues that occur if using function pointers.
Concrete functions, on the other hand, can be given a true function type (e.g. \verb|add5| could be compiled to a concrete function with type \verb|int| $\rightarrow$ \verb|int|) if targeting a backend that supports them, such as C99, or by using an integer-indexed jump table in OpenCL (we have not implemented this mechanism using Ace as of the time of writing, but do not anticipate difficulties).

Type propagation via generic functions can be compared to template specialization in C++, where both the necessary template headers (containing nested template parameters to support function passing) and template specializations are inferred automatically from usage. This significantly simplifies a sophisticated feature of C++ and introduces it to OpenCL and C, which do not support templates.
% Is this really any more concise than using C + templates? Etc. relation to types. Conciseness.

\subsection{Type Inference}
On Line 5 in the generic \verb|map| function in Listing \ref{map}, the variable \verb|gid| is initialized with the result of calling the \verb|get_global_id| primitive (the argument, \verb|0|, is not important for our purposes.)  Note that the type for the \verb|gid| variable is never listed explicitly. This is because Ace supports a form of {\em whole-function type inference}. In this case, \verb|gid| will be assigned type \verb|size_t| because that is the return type of \verb|get_global_id| (as defined in the OpenCL specification \cite{opencl}, which the \verb|ace.OpenCL| module follows.) The result can be observed on Lines 11 and 24 in Listing \ref{mapout}. 

Inference is not restricted within single assignments, as in the \verb|map| example. Multiple assignments to the same variable with values of differing types, or multiple return statements, can be unified such that the variable or return type is given a common supertype. For example, in the \verb|threshold_scale| function defined in Listing \ref{inference}, the variable \verb|y| in the first branch of the conditional is assigned the \verb|int| literal \verb|0|. However, in the second branch of the loop, its type depends on the types of \verb|x| and \verb|scale|. We show two choices for these types on Lines 10 and 11. However, type inference correctly unifies these two types according to OpenCL's C99-derived rules governing numeric types (which are defined by the user in the \verb|OpenCL| module, as we will describe in Section \ref{att}). We test this programmatically on Lines 12 and 13. Note that this example would also work correctly if the assignments to \verb|y| were replaced with \verb|return| statements (in other words, the return value of a function is treated as an assignable for the purpose of type inference).

\subsection{Annotation and Extension Inference}
In addition to type annotations, OpenCL normally asks for additional annotations in a number of other situations.  Users can annotate functions that meet certain requirements to be callable from the host with the \verb|__kernel| attribute. The \verb|Ace.OpenCL.OpenCL| backend is able to check these requirements and add this annotation automatically. Several types (notably, \verb|double|) and specialized functions require that an OpenCL extension be enabled with a \verb|#pragma| when used. The OpenCL backend automatically detects many of these cases as well and adds the appropriate \verb|#pragma| declaration. An example of this feature can be seen on Line 5.1, where the use of the \verb|double| type triggers the insertion of an appropriate \verb|#pragma| automatically. Ace is designed to allow backends to observe the results of the type checking process to support this form of inference.

\subsection{Metaprogramming in Ace}
\begin{codelisting}
\lstinputlisting[commentstyle=\color{mauve}]{listing7.py}
\caption{[\texttt{listing7.py}] Metaprogramming with Ace, showing how to construct generic functions from both strings and abstract syntax trees, and how to manipulate syntax trees at compile-time.}
\label{metaprogramming}
\end{codelisting}
Metaprogramming refers to the practice of writing programs that manipulate other programs. There are a number of use cases for this technique, including domain-specific optimizations and code generation for programs with a repetitive structure that cannot easily be captured using available abstractions \cite{pyopencl}. OpenCL in particular relies on code generation as a fundamental mechanism, which is cited as justification for its lack of support for higher-order programming. Ace supports programmatic compilation and higher-order constructs, as described above, and a flexible language extension mechanism, which we describe below, so several use cases for metaprogramming have been eliminated. However, cases where this form of metaprogramming include programmatic function specialization (Listing \ref{metaprogramming}) and modular simulation orchestration, described in Section \ref{clegans}.

On Lines 4-7 of Listing \ref{metaprogramming}, an Ace function is constructed from a string containing its source using the \verb|from_source| variant of the \verb|OpenCL.fn| method. It can also be constructed directly from an abstract syntax tree (AST), as implemented by the Python standard \verb|ast| package, using the \verb|from_ast| variant of \verb|fn|, demonstrated on Line 10. The AST here is generated programmatically by calling the \verb|specialize| function, which produces a copy of the syntax tree of the \verb|plus| function with the argument, \verb|b|, eliminated and its uses replaced with a constant, \verb|5|. This transformation as well as some others are distributed in \verb|ace.astx| for convenience.
\subsection{Direct Invocation from Python}\label{direct}

\begin{codelisting}
\lstinputlisting{listing8.py}
\caption{[\texttt{listing\ref{py}.py}] A full OpenCL program using the \texttt{Ace.OpenCL} Python bindings, including data transfer to and from a device and direct invocation of a generic function, \texttt{map}, as a kernel without explicit compilation.}
\label{py}
\end{codelisting}

As discussed in the Introduction, a common workflow for professional end-users involves the use of a high-level scripting language for overall workflow orchestration and small-scale data analysis and visualization, paired with a low-level language for performance-critical sections. Python is already widely used by professional end-users as a high-level scripting language and also features mature support for calling into code written in low-level languages. Developers can call into native libraries using its foreign function interface (FFI),  or by using a wrapper library like \verb|pycuda| for code compiled with CUDA, a proprietary language similar to OpenCL  specifically targeting nVidia GPU hardware. 
Although CUDA's compilers are separate executables on the system, the OpenCL language was designed for this workflow, in that it exposes the compiler directly as an API. The \verb|pyopencl| module exposes this API as well as the OpenCL memory management API to Python. With both \verb|pyopencl| and \verb|pycuda|, developers generate source code as strings, compile it programmatically, then execute it using the run-time APIs that each library provides \cite{pyopencl}.

Ace supports this workflow as an alternative to using the \verb|acec| compiler as described above to generate  source code directly from the shell. For the OpenCL backend, these bindings are exposed as a wrapper on top of \verb|pyopencl| called \verb|Ace.OpenCL.bindings|. Both generic functions and concrete functions written for a backend that supports the direct execution interface (thus far, \verb|OpenCL| and \verb|C99|) can be called like regular Python functions. An example of this for the generic \verb|map| function defined in Listing \ref{map} is shown in Listing \ref{py}, with the call itself on Lines 9-10. The first two arguments to \verb|map| are OpenCL buffers, generated using a simplified wrapper to the \verb|pyopencl| APIs on Lines 7-8. This wrapper associates type information with each buffer, similarly to \verb|numpy|, and this is used to implicitly compile \verb|map| as appropriate the first time it is called for any given combination of input types. Explicit calls to the \verb|compile| method, as we have been showing thusfar, are unnecessary if using this method of invocation. The final two keyword arguments on Line 10 are parameters that OpenCL requires for execution that determine the number of threads (called the {\em global size}) and thread grouping (the {\em local size}). 

By way of comparison, the same program written using the OpenCL C API directly is an order of magnitude larger and correspondingly more complex. A full implementation of the logic of \verb|map| written using the \verb|pyopencl| bindings and metaprogramming techniques as described in \cite{pyopencl} is twice as large and significantly more difficult to comprehend than the code we have shown thus far. Not shown are several additional conveniences, such as delegated kernel sizing and \verb|In| and \verb|Out| constructs that can reduce the size and improve the clarity of this code further; due to a lack of space, the reader is referred to the language documentation for additional details on these features.


\section{Active Typechecking and\\Translation (AT\&T)}\label{att}
\subsection{Active Translation}\label{translation}
\subsection{Use Cases}\label{usecases}
\section{Ace: A Compilation Environment}\label{compenv}
\section{Case Study}\label{casestudy}
\section{Related Work}\label{related}
\section{Discussion}\label{discussion}
%We argue that many of the barriers to adoption faced by new abstractions stem from the fact that new abstractions are too-often developed and distributed together with a new programming language. Some prominent cases where such a {\em language-oriented approach} \cite{languageoriented} has been followed include:
%\begin{itemize}
%\item UPC, CAF, X10 and Chapel, built around first-class support for a partitioned global address space (PGAS) programming model; 
%\item Go, Erlang, Charm++, Occam and Axum, built around first-class support for message passing; and
%\item CUDA, OpenCL, Cilk and NESL, built around first-class support for data parallelism.
%\end{itemize}
%
%The benefits of taking this approach are clear: first-class language, compiler and run-time support for a programming abstraction can improve performance and enable a more natural programming style. Empirical evidence also supports this notion that developers prefer first-class support for a parallel abstraction over a library-based solution, if other factors are held constant \cite{ppfirstclass}. 
%
%Unfortunately, adopting a specialized research language comes with a host of ancillary challenges  \cite{adoptionTR,socioplt}. These are significant enough that programming abstractions that are distributed as libraries for a well-established language, such as MapReduce, Global Arrays and MPI, have prevailed in practice, despite the limited expressivity of library-based abstractions. This is balanced by several factors: developers can progressively introduce parallelism into existing programs, leverage a familiar and well-developed general-purpose programming language when not directly invoking parallel primitives, and utilize arbitrary combinations of  abstractions within a single program without needing to navigate the friction inherent to language boundaries. 
%
%Ace aims to bridge the language-oriented and library-oriented approaches by allowing developers to define and distribute a broad range of new {\em first-class} types and their operations directly within user libraries, using a mechanism called {\em active typechecking and translation (\ATT)}. Based on the notion of active libraries \cite{activelibraries}, \ATT~is designed to allow developers to  extend the semantics, but not the syntax, of a language. The Ace grammar is a nearly-complete subset of Python's  and we show that it is flexible enough to support all of the primitives of the C99 and OpenCL languages in a natural manner, when aided by a form of type inference that we describe. We further supplement these primitives with higher-level user-defined primitives, examples of which we discuss in Section \ref{abstractions}. Notably, all of these primitives are imported via the normal library loading mechanism; they are not defined within domain-specific languages, nor as extensions for a particular compiler implementation.
%
%Although the \ATT~mechanism, a key feature of Ace, is designed primarily for use by researchers and domain experts, Ace is intended to be highly practical and ready for adoption by professional end-user developers today. It is based on the Python programming language, which enjoys broad adoption in this community. Indeed, the language itself is implemented entirely as a Python library, and many existing tools, such as editor modes, documentation tools and style checkers, can be used without modification.
%Ace functions are generated programmatically and can be called directly from Python, with numeric arrays as arguments, so developers can integrate Ace immediately within their existing workflows for portions of code that may benefit from static compilation and support for parallelism.
%We demonstrate the practicality of Ace in Section \ref{clegans} by describing an Ace-based framework that supports specifying and orchestrating families of large-scale neurobiological circuit simulations on clusters of GPUs.

\section{Structure and Usage}
%Ace is an {\em actively-typed, language-integrated compilation environment}. Let us begin by defining each of these terms. 
%A {\em compilation environment} is a system that allows developers to programmatically control aspects of compilation directly. The language used to do so is called the {\em metalanguage} while the grammar that programs themselves are written in is called the {\em source grammar}. The metalanguage of Ace is Python and the source grammar is a significant subset of Python's own grammar. Programs and metalanguage code can be interleaved within the same file, so Ace is {\em language-integrated}. Ace programs are statically-typed, and types themselves are objects in the metalanguage. They can be equipped by developers with methods that control how operators associated with them are typechecked and compiled. Because of the relationship between this mechanism and the idea of {\em active libraries} \cite{activelibraries}, discussed further in Section \ref{related}, we call them {\em active types}, and thus Ace is {\em actively-typed}.
\section{Ace for Researchers}
Thus far, we have been largely discussing the OpenCL module in our examples. However, Ace gives no preferential treatment to this module; it is implemented entirely using the user-facing mechanisms described in this section. A C99 module has also been developed (which, due to its similarity to OpenCL, shares many of its implementation details), but we do not discuss it further in this paper. Extensions complementing these are described in Section C below.

Most programming languages are {\em monolithic} -- the set of available primitives is determined by the language designers, and users must combine these primitives to produce any desired run-time behavior. Although many very general primitives have been developed (e.g. object systems and algebraic datatypes), these can be insufficient in specialized domains where developers and researchers need fine control over how certain operations are type checked and translated. High-performance computing is an example of such a field, since both correctness and performance have been difficult to achieve in general, and are topics of active research. As discussed in the Introduction, the proliferation of parallel programming languages, rather than library-based abstractions, indicates that researchers often find the abstractions available in existing languages insufficient for their needs.

To address these use cases, Ace has been designed to be fundamentally {\em extensible}, rather than monolithic. Users can introduce new primitive types and operations and fully control how they are typechecked and translated. The backend target of translation can also be specified modularly by the user. Because Ace libraries can contain compile-time logic, written in the metalanguage as described in the previous section, these primitive definitions can be distributed as modules, rather than as extensions to particular compilers or domain-specific languages.

\subsection{Active Typechecking and Translation (\ATT)}
We now explain how new primitive types and operators can be defined in Ace. When the compiler encounters an expression, such as \verb|input[gid]|, it must first verify its validity by assigning it a type, then translate the expression to produce an expression in a target language. Rather than containing fixed logic for this, however, the Ace compiler defers this responsibility to the {\it type} of a subexpression, such as \verb|input|, whenever possible, according to a fixed {\em dispatch protocol} for each syntactic form. Below are examples of the rules that comprise the Ace dispatch protocol. Due to space constraints, we do not list the entire dispatch protocol, which contains a rule for each possible syntactic form in the language.
\begin{itemize}
\item Responsibility over a {\bf unary operation} like \verb|-x| is handed to the type assigned to the operand, \verb|x|.
\item Responsibility over {\bf binary operations} is first handed to the type assigned to the left operand. If it indicates that it does not understand the operation, the type assigned to the right operand is handed responsibility, with a different method call\footnote{Note that this operates similarly to the Python run-time operator overloading protocol; see Related Work.}.
\item Responsibility over {\bf attribute access} (\texttt{obj.attr}) and {\bf subscript access}, (\texttt{obj[idx]}) is handed to the type assigned to \texttt{obj}.
\item {\color{red} Talk about multiple assignment here I think}
\end{itemize}
\begin{codelisting}
\lstinputlisting{listing9.py}
\caption{\texttt{[listing9.py]} A portion of the implementation of OpenCL pointer types implementing subscripting logic using the Ace extension mechanism.}
\label{pointers}
\end{codelisting}


\subsubsection{Active Typechecking}
During the typechecking phase, the type of the primary operand, as determined by this dispatch protocol, is responsible for assigning a type to the expression as a whole. Let us consider the \verb|map| function from Listing \ref{map} once again. When it is compiled on Line 9 of Listing \ref{mapadd5dbl}, its first two argument types are given as \verb|global_ptr(double)|. As described in Section \ref{types}, this type, abbreviated \verb|A|, is an instance of \verb|ace.OpenCL.GlobalPtrType| which inherits from \verb|ace.OpenCL.PtrType| and ultimately from \verb|ace.Type|. So when the compiler encounters the expression \verb|input[gid]| on Line 6, it follows the dispatch protocol just described and assigns responsibility over typechecking it to \verb|A|. This is done by calling the \verb|resolve_|$X$ method of the responsible type, where $X$ is the syntactic form of the expression. In this case, the expression is of the \verb|Subscript| form, so the compiler calls \verb|A.resolve_Subscript|.

The relevant portion of \verb|ace.OpenCL.GlobalPtrType| is shown in Listing \ref{pointers}. The \verb|verify_Subscript| method on Line 8 receives a context and the syntax tree of the node itself as input. The context contains information about other variables in scope, as well as other potentially relevant information, and also contains a method, \verb|resolve_type|, that can be used recursively resolve the types of subexpressions. On Line 9, this method is used to resolve the type of the slice subexpression, \verb|gid|, which is the machine-dependent integer type \verb|size_t| as discussed in Section II.E. On Line 10, it confirms that this type is an instance of an integer type. Thus, it assigns the whole expression, \verb|input[gid]|, the target type of the pointer, \verb|double|. Had a user attempted to index \verb|input| using a non-integer value, the method would take the other branch of the conditional and raise a type error with a relevant user-defined error message on Line 13.

\subsubsection{Active Translation}
Once typechecking a method is complete, the compiler must subsequently translate each Ace source expression into an expression in the target language, OpenCL in the examples thus far. It does so by again applying the dispatch protocol and calling a method of the form \verb|translate_|$X$, where $X$ is the syntactic form of the expression. This method is responsible for returning a copy of the expression's ast node with an additional attribute, \verb|code|, containing the source code of the translation. In this case, it is simply a direct translation to the corresponding OpenCL attribute access (Line 20), using the recursively-determined translations of the operands (Lines 16-17).  More sophisticated abstractions may insert arbitrarily complex statements and expressions during this phase. The context also provides some support for non-local effects, such as new top-level declarations (not shown.)

\subsection{Active Backends}\label{backends}
Thus far, we have discussed using OpenCL as a backend with Ace. The OpenCL extension is the most mature as of this writing. However, Ace supports the introduction of new backends in a manner similar to the introduction of new types, by extending the \verb|clq.Backend| base class. Backends are provided as the first argument to the \verb|@clq.fn| decorator, as can be seen in Figure \ref{map}. 
Backends are responsible for some aspects of the grammar that do not admit simple dispatch to the type of a subterm, such as number and string literals or basic statements like \verb|while|.

In addition to the OpenCL backend, preliminary C99 and CUDA backends are available (with the caveat that they have not been as fully developed or tested as of this writing.) Backends not based on the C family are also possible, but we leave such developments for future work.

\subsection{Use Cases}
The development of the full OpenCL language using only the extension mechanisms described above provides evidence of the power of this approach. Nothing about the core language was designed specifically for OpenCL. However, to be truly useful, as described in Sections \ref{multiparadigm} and  \ref{extensions}, the language must be able to support a wide array of primitive abstractions. We briefly describe a number of other abstractions that may be possible using this mechanism. Many of these are currently available either via inconvenient libraries or in standalone languages. With the Ace extension mechanism, we hope to achieve robust, natural implementations of many of these mechanisms within the same language.

\paragraph{Partitioned Global Address Spaces}
A number of recent languages in high-performance computing have been centered around a partitioned global address space model, including UPC, Chapel, X10 and others. These languages provide first-class support for accessing data transparently across a massively parallel cluster, which is verbose and poorly supported by standard C. The extension mechanism of Ace allows inelegant library-based approaches such as the Global Arrays library to be hidden behind natural wrappers that can use compile-time information to optimize performance and verify correctness. We have developed a prototype of this approach using the C backend and hope to expand upon it in future work.

\paragraph{Other Parallel Abstractions}
A number of other parallel abstractions, some of which are listed in \ref{multiparadigm}, also suffer from inelegant C-based implementations that spurred the creation of standalone languages. A study comparing a language-based concurrency solution for Java with an equivalent, though less clean, library-based solution found that language support is preferable but leads to many of the issues we have described \cite{cave2010comparing}. The extension mechanism is designed to enable library-based solutions that operate as first-class language-based solutions, barring the need for particularly exotic syntactic extensions.

\paragraph{Domain-Specific Type Systems}
Ace is a statically-typed language, so a number of domain-specific abstractions that promise to improve verifiability using types, as discussed in Section \ref{verifiability}, can be implemented using the extension mechanism. We hope that this will allow advances from the functional programming community to make their way into the professional end-user community more quickly, particularly those focused on scientific domains (e.g. \cite{conf/cefp/Kennedy09}).

\paragraph{Specialized Optimizations}
In many cases, code optimization requires domain-specific knowledge or sophisticated, parametrizable heuristics. Existing compilers make implementing and distribution such optimizations difficult. With active libraries in Ace, optimizations can be distributed directly with the libraries that they work with. For instance, we have implemented substantial portions of the NVidia GPU-specific optimizations described in \cite{yang2010gpgpu} as a library that uses the extension mechanism to track affine transformations of the thread index used to access arrays, in order to construct a summary of the memory access patterns of the kernel, which can be used both for single-kernel optimization (as in \cite{yang2010gpgpu}) and for future research on cross-kernel fusion and other optimizations.

\paragraph{Instrumentation}
Several sophisticated feedback-directed optimizations and adaptive run-time protocols require instrumenting code in other ways. The extension mechanism enables granular instrumentation based on the form of an operation as well as its constituent types, easing the implementation of such tools. This ability could also be used to collect data useful for more rigorous usability and usage studies of languages and abstractions, and we plan on following up on this line of research going forward.


\section{Case Study: Neurobiological Circuit Simulation}
An important criteria that practitioners use to evaluate a language or abstraction, as discussed in Section \ref{social}, is whether significant case studies have been conducted with it. In this section, we briefly (due to space limitations) discuss an application of the Ace OpenCL library, Python host bindings and code generation features for developing a modular, high-performance scientific simulation library used to simulate  thousands of parallel realizations of a spiking neurobiological circuit on a GPU.

\subsection{Background}
A neural circuit can be modeled as a network of coupled differential equations, where each node corresponds to a single neuron. Each neuron is modeled using one or more ordinary differential equations. These equations capture the dynamics of physically important quantities like the cell's membrane potential or the conductance across various kinds of ion channels and can take many forms \cite{neurobook}. Single simulations can contain from hundreds to tens of millions of neurons each, depending on the specific problem being studied. In some cases, such as when studying the effects of noise on network dynamics or to sweep a parameter space, hundreds or thousands of realizations must be generated. In these cases, care must be taken to only probe the simulation for relevant data and process portions of it as the simulation progresses, because the amount of data generated is often too large to store in its entirety for later analysis.

The research group we discuss here (of which the first author was a member) was studying a problem that required running up to 1,000 realizations of a network of between 4,000 and 10,000 neurons each. An initial solution to this problem used the Brian framework, written in Python, to conduct these simulations on a CPU. Brian was selected because it allowed the structure of the  simulation to be specified in modular and straightforward manner. This solution required between 60 and 70 minutes to conduct the simulations and up to 8 hours to analyze the data each time a parameter of the simulation was modified.

Unsatisfied with the performance of this approach, the group developed an accelerated variant of the simulation using C++ and CUDA. Although this produced significant speedups, reducing the time for a simulation by a factor of 40 and the runtime of the slowest analyses by a factor of 200, the overall workflow was also significantly disrupted. In order to support the many variants of models, parameter sets, and probing protocols, C preprocessor flags were necessary to selectively include or exclude code snippets. This quickly led to an incomprehensible and difficult to maintain file structure. Moreover, much of the simpler data analysis and visualization was conducted using Python, so marshalling the relevant data between processes also became an issue. 

\subsection{The {\sf cl.egans} Simulation Library}
In order to eliminate these issues while retaining the performance profile of the GPU-accelerated code, the project was ported to Ace. Rather than using preprocessor directives to control the code contained in the final GPU kernels used to execute the simulation and data analyses, the group was able to develop a more modular  library called {\sf cl.egans}\footnote{...after {\it c. elegans}, a model organism in neuroscience} based on the language's compile-time code generation mechanism and Python and OpenCL bindings.

{\sf cl.egans} leverages Python's object-oriented features to enable modular, hierarchical simulation specifications. For example, Figure \ref{spec} shows an example where a neuron model (\verb|ReducedLIF|) is added to the root of the simulation, a synapse model (\verb|ExponentialSynapse|) is then added to it, and its conductance is probed in the same way, by adding a probe model as a child of the synapse model. If interleaved analysis needed to be conducted as well, it would be specified in the same way.

Implementations of these classes do not evaluate the simulation logic directly, but rather contain methods that generate Ace source code for insertion at various points, called {\it hooks}, in the final simulation kernel. The hook that code is inserted into is determined by the method name, and code can be inserted into any hook defined anywhere upstream in the simulation tree. New hooks can also be defined in these methods and these become available for use by child nodes. Figure \ref{impl} shows an example of a class that inserts code in the \verb|model_code| hook and defines several new hooks. This protocol is closely related to the notion of {\it frame-oriented programming}. Although highly modular, this strategy avoids the performance penalties associated with standard object-oriented methodologies via code generation.

Compared to a similar protocol targeting OpenCL directly, the required code generation logic is significantly simpler because it enables classes like \verb|StateVariable| to be written generically for all types of state variables, without carrying extra parameters and {\it ad hoc} logic to extract and compute the result types of generated expressions. Moreover, because types are first-class objects in the metalanguage, they can be examined during the memory allocation step to enable features like fully-automatic parallelization of multiple realizations across one or more devices, a major feature of {\sf cl.egans} that competing frameworks cannot easily offer.


Once the kernel has been generated and memory has been allocated, the simulation can be executed directly from Python using the bindings described in Section \ref{direct}. The results of this simulation are immediately available to the Python code following the simulation and can be visualized and further analyzed using standard tools. Once the computations are complete, the Python garbage collector is able to handle deallocation of GPU memory automatically (a feature of the underlying \verb|pyopencl| library \cite{klockner2011pycuda}.)

Using this Ace-based framework, the benefits of the Brian-based workflow were recovered without the  corresponding decrease in performance relative to the previous CUDA-based solution, leading ultimately to a satisfying solution for the group conducting this research.

\begin{codelisting}
\lstinputlisting{listing10.py}
\caption{\texttt{[listing10.py]} An example of a nested simulation tree, showing that specifying a simulation is both simple and modular. The first argument to the constructor specifies each node's parent.}
\label{spec}
\end{codelisting}

\begin{codelisting}
\lstinputlisting{listing11.py}
\caption{\texttt{[listing11.py]} An example of a hook that inserts code and also inserts new, nested hooks for downstream simulation nodes  below that.}
\label{impl}
\end{codelisting}

\section{Related Work}
\subsection{Active Libraries in Ace}
Libraries that have such capabilities has been called {\it active libraries} in prior proposals \cite{activelibraries}. A number of  projects, such as Blitz++, have taken advantage of the C++ preprocessor and template-based metaprogramming system to implement domain-specific optimizations. In Ace, we replace these brittle mini-languages with a general-purpose language. This allows for several interesting uses that we discuss in the following sections.


\subsubsection{Structural Polymorphism}
In Section \ref{hof}, we discussed several strategies for achieving {\it polymorphism} -- the ability to create functions and data structures that operate over more than a single type. In Ace, all functions are implicitly polymorphic and can be called with arguments of {\it any type that supports the operations used by the function}. For example, in Figure \ref{map}, \verb|in| can be any type that supports indexing by a variable of type \verb|size_t| to produce a value of a type that can be passed into \verb|fn|, which must then produce a value consistent with indexing into \verb|out|. OpenCL pointer types are consistent with these constraints, for example. Although powerful, this also demonstrates a caveat of this approach -- that it is more difficult to give a function a concise signature, because arguments are constrained by capability, rather than to a single type \cite{malayeri2009structural}.

Structural typing can be compared to the approach taken by dynamically-typed languages that rely on ``duck typing''. It is more flexible than the parametric polymorphism found in many functional languages and in languages like Java (which only allow polymorphic functions that are valid for {\it all} possible types), but is of comparable strength to the template system found in C++. It can be helpful to think of each function as being preceded by an implicit template header that assigns each argument its own unique type parameter. At function call sites, these parameters are implicitly specialized with the types of the provided arguments. This choice is again motivated by the criteria of conciseness given in Section \ref{syntax}.

\subsection{Type-Level Computation} %Haskell, Ur and $\Omega$mega
System XX with simple case analysis provides the basis of type-level computation in Haskell (where type-level functions are called type families \cite{Chakravarty:2005:ATC}). Ur uses type-level records and names to support typesafe metaprogramming, with applications to web programming \cite{conf/pldi/Chlipala10}. $\Omega$mega adds algebraic data types at the type-level, using these to increase the expressive power of algebraic data types at the expression level \cite{conf/cefp/SheardL07}. Dependently-typed languages blur the traditional phase separation between types and expressions, so type-level computation is often implicitly used (though not always in its most general form, e.g. Deputy \cite{conf/icfp/ChenX05}, ATS \cite{conf/esop/ConditHAGN07}.)

\subsection{Run-Time Indirection}
{\it Operator overloading} \cite{vanWijngaarden:Mailloux:Peck:Koster:Sintzoff:Lindsey:Meertens:Fisker:acta:1975} and {\it metaobject dispatch} \cite{Kiczales91} are run-time protocols that translate operator invocations into function calls. The function is typically selected according to the type or value of one or more operands. These protocols share the notion of {\it inversion of control} with type-level specification. However, type-level specification is a {\it compile-time} protocol focused on enabling specialized verification and implementation strategies, rather than simply enabling run-time indirection.

\subsection{Term Rewriting Systems}
Many languages and tools allow developers to rewrite expressions according to custom rules. These can broadly be classified as {\it term rewriting systems}. Macro systems, such as those characteristic of the LISP family of languages \cite{mccarthy1978history}, are the most prominent example. Some compile-time metaprogramming systems also allow users to manipulate syntax trees (e.g. MetaML \cite{Sheard:1999:UMS}), and external rewrite systems also exist for many languages.
These facilities differ from type-level specification in one or more of the following ways:

\begin{enumerate}
\item In type-level specification, the type of a value is determined separately from its representation; in fact, the same representation may be generated by multiple types. 
\item We draw a distinction between the metalanguage, used to specify types and compile-time logic, the source grammar, used to describe run-time behavior, and the internal language, used to implement this behavior. Term rewriting systems generally do not draw this distinction. By doing so, each component language can be structured and constrained as appropriate for its distinct role, as we show.
%\item With type-level specification, dispatch to a type-level function occurs implicitly on the basis of the structure of an expression. In contrast, most term-rewriting systems operate by  explicit invocation of a macro or specialized syntax. Some LISP macro systems have explored pattern-based dispatch (e.g. A*\cite{fowler2010domain}, EPP\cite{fowler2010domain}) and macro systems for object-oriented languages, like OpenC++ \cite{fowler2010domain} and OpenJava \cite{fowler2010domain}, do offer a somewhat limited form of operation-based dispatch.
\item Many common macro systems and metaprogramming facilities operate at run-time. Compilers for some forms of LISP employ aggressive compile-time specialization techniques to attempt to minimize this overhead. Static and staged term-rewriting systems also exist (e.g. OpenJava\cite{TatM:OpenJCBMSJ}, Template Haskell\cite{SheardPeytonJones:Haskell-02}, MetaML \cite{Sheard:1999:UMS} and others). 
\end{enumerate}

\subsection{Language Frameworks}
When the mechanisms available in an existing language prove insufficient, researchers and domain experts must design a new language. A number of tools have been developed to assist with this task, including compiler generators, language workbenches and domain-specific language frameworks (cf \cite{fowler2010domain}).

A major barrier to adoption is the fact that interoperability is intrinsically problematic. Even languages which target a common platform, such as the Java Virtual Machine, can only interact using its limited set of primitives. Specialized typing rules are not checked at language boundaries, performance often suffers, and the syntax can be unnatural, particularly for languages which differ significantly from the platform's native language (e.g. Java).

Instead of focusing on defining standalone languages, type-level specification gives greater responsibility in a granular manner to libraries. In this way, a range of constructs can coexist within the same program and, assuming that it can be shown by some method that various constructs are safely composable, be mixed and matched. The main limitation is that the protocol requires defining a fixed source grammar, whereas a specialized language has considerable flexibility in that regard. Nevertheless, as Ace shows, a simple grammar can be used quite flexibly.
\subsection{Extensible Compilers}
An alternative methodology is to implement language features granularly as compiler extensions. As discussed in Section 1, existing designs suffer from the same problems related to composability, modularity\-, safety and security as extensible languages, while also adding the issue of language fragmentation.

Type-level specification can in fact be implemented within a compiler, rather than provided as a core language feature. This would resolve some of the issues, as described in this paper. However, by leveraging type-level computation to integrate the protocol directly into the language, we benefit from common module systems and other shared infrastructure. We also avoid the fragmentation issue.
\subsection{Specification Languages}
Several {\it specification languages} (or {\it logical frameworks}) based on these theoretical formulations exist, including the OBJ family of languages (e.g. CafeOBJ \cite{Diaconescu-Futatsugi01}). They provide support for verifying a program against a language specification, and can automatically execute these programs as well in some cases. The  language itself specifies which verification and execution strategies are used.

Type-determined compilation takes a more concrete approach to the problem, focusing on combining {\it implementations} of different\- logics, rather than simply their specifications. In other words, it focuses on combining {\it type checkers} and {\it implementation strategies} rather than more abstract representations of a language's type system and dynamic semantics. In Section 4, we outlined a preliminary approach based on proof assistant available for the type-level language to unify these approaches, and we hope to continue this line of research in future work.


\section{Conclusion}
In addition to the novel architecture of Ace as a whole, we note several individually novel features introduced here: %in this paper: 

\begin{itemize}
\item The \ATT~mechanism, which is a generalization of the concept of active libraries \cite{activelibraries}  where types are metalanguage objects.
\item The method Ace uses to eliminate the need for type annotations in most cases, which combines a form of type inference with type propagation.
\item The method Ace uses check correctness of generated code by checking representational consistency constraints associated with types, detailed in Section \ref{repcon}. 
\item The type-aware simulation orchestration techniques used in the \texttt{cl\_egans} library, described in Section \ref{clegans}.
\end{itemize}

Readers familiar with the Python programming language will recognize the style of syntax used in Figure \ref{map}. In fact, Ace uses the Python grammar and parsing facilities directly. Several factors motivated this design decision. First, Python's syntax is widely credited as being particularly simple and readable, due to its use of significant whitespace and conventional mathematical notation. Python is one of the most widely-used languages in scientific computing, so its syntax is already familiar to much of the field. And significantly, a large ecosystem of tools already exist that work with Python files, such as code editors, syntax highlighters, style checkers and documentation generators. These can be used without modification to work with Ace files. Therefore, by re-using an existing, widely-used grammar, we are able to satisfy many of the design criteria described in Section \ref{syntax} and the adoption criteria described in Section \ref{tools} without significant development effort.


Professional end-users demand much from new languages and abstractions. In this paper, we began by generating a concrete, detailed set of design and adoption criteria that we hope will be of broad interest and utility to the research community. Based on these constraints, we designed a new language, Ace, making several pragmatic design decisions and utilizing advanced techniques, including type inference, structural typing, compile-time metaprogramming and active libraries, to uniquely satisfy many of the criteria we discuss, particularly those related to extensibility. We validated the extension mechanism with a mature implementation of  the entirety of the OpenCL type system, as well as preliminary implementations of some other features. Finally, we demonstrated that this language was useful in practice, drastically improving performance without negatively impacting the high-level scientific workflow of a large-scale neurobiological circuit simulation project. Going forward, we hope that Ace (or simply the key techniques it proposes, by some other vehicle) will be developed further by the community to strengthen the foundations upon which new abstractions are implemented and deployed into professional end-user development communities.

\section{Availability}
Ace is available under the LGPL license and is developed openly and collaboratively using the popular Github platform at \url{https://github.com/cyrus-/ace}. Documentation, examples and other learning materials will be available at \url{http://acelang.org/}. {\color{red}(by the time of the conference)}

\section{Acknowledgments}
CO was funded by the DOE Computational Science Graduate Fellowship under grant number DE-FG02-97ER25308. NF was funded by ...

% An example of a floating figure using the graphicx package.
% Note that \label must occur AFTER (or within) \caption.
% For figures, \caption should occur after the \includegraphics.
% Note that IEEEtran v1.7 and later has special internal code that
% is designed to preserve the operation of \label within \caption
% even when the captionsoff option is in effect. However, because
% of issues like this, it may be the safest practice to put all your
% \label just after \caption rather than within \caption{}.
%
% Reminder: the "draftcls" or "draftclsnofoot", not "draft", class
% option should be used if it is desired that the figures are to be
% displayed while in draft mode.
%
%\begin{figure}[!t]
%\centering
%\includegraphics[width=2.5in]{myfigure}
% where an .eps filename suffix will be assumed under latex, 
% and a .pdf suffix will be assumed for pdflatex; or what has been declared
% via \DeclareGraphicsExtensions.
%\caption{Simulation Results}
%\label{fig_sim}
%\end{figure}

% Note that IEEE typically puts floats only at the top, even when this
% results in a large percentage of a column being occupied by floats.


% An example of a double column floating figure using two subfigures.
% (The subfig.sty package must be loaded for this to work.)
% The subfigure \label commands are set within each subfloat command, the
% \label for the overall figure must come after \caption.
% \hfil must be used as a separator to get equal spacing.
% The subfigure.sty package works much the same way, except \subfigure is
% used instead of \subfloat.
%
%\begin{figure*}[!t]
%\centerline{\subfloat[Case I]\includegraphics[width=2.5in]{subfigcase1}%
%\label{fig_first_case}}
%\hfil
%\subfloat[Case II]{\includegraphics[width=2.5in]{subfigcase2}%
%\label{fig_second_case}}}
%\caption{Simulation results}
%\label{fig_sim}
%\end{figure*}
%
% Note that often IEEE papers with subfigures do not employ subfigure
% captions (using the optional argument to \subfloat), but instead will
% reference/describe all of them (a), (b), etc., within the main caption.


% An example of a floating table. Note that, for IEEE style tables, the 
% \caption command should come BEFORE the table. Table text will default to
% \footnotesize as IEEE normally uses this smaller font for tables.
% The \label must come after \caption as always.
%
%\begin{table}[!t]
%% increase table row spacing, adjust to taste
%\renewcommand{\arraystretch}{1.3}
% if using array.sty, it might be a good idea to tweak the value of
% \extrarowheight as needed to properly center the text within the cells
%\caption{An Example of a Table}
%\label{table_example}
%\centering
%% Some packages, such as MDW tools, offer better commands for making tables
%% than the plain LaTeX2e tabular which is used here.
%\begin{tabular}{|c||c|}
%\hline
%One & Two\\
%\hline
%Three & Four\\
%\hline
%\end{tabular}
%\end{table}


% Note that IEEE does not put floats in the very first column - or typically
% anywhere on the first page for that matter. Also, in-text middle ("here")
% positioning is not used. Most IEEE journals/conferences use top floats
% exclusively. Note that, LaTeX2e, unlike IEEE journals/conferences, places
% footnotes above bottom floats. This can be corrected via the \fnbelowfloat
% command of the stfloats package.



% conference papers do not normally have an appendix


% use section* for acknowledgement
% trigger a \newpage just before the given reference
% number - used to balance the columns on the last page
% adjust value as needed - may need to be readjusted if
% the document is modified later
%\IEEEtriggeratref{8}
% The "triggered" command can be changed if desired:
%\IEEEtriggercmd{\enlargethispage{-5in}}

% references section

% can use a bibliography generated by BibTeX as a .bbl file
% BibTeX documentation can be easily obtained at:
% http://www.ctan.org/tex-archive/biblio/bibtex/contrib/doc/
% The IEEEtran BibTeX style support page is at:
% http://www.michaelshell.org/tex/ieeetran/bibtex/
%\bibliographystyle{IEEEtran}
% argument is your BibTeX string definitions and bibliography database(s)
%\bibliography{IEEEabrv,../bib/paper}
%
% <OR> manually copy in the resultant .bbl file
% set second argument of \begin to the number of references
% (used to reserve space for the reference number labels box)
\bibliographystyle{IEEEtran}
\bibliography{../research}
%
%\begin{thebibliography}{1}
%
%\bibitem{IEEEhowto:kopka}
%H.~Kopka and P.~W. Daly, \emph{A Guide to \LaTeX}, 3rd~ed.\hskip 1em plus
%  0.5em minus 0.4em\relax Harlow, England: Addison-Wesley, 1999.
%
%\end{thebibliography}




% that's all folks
\end{document}


